[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Guide to Whole Transcriptome CosMx¬Æ SMI Analysis",
    "section": "",
    "text": "Preface\nSomeone once described the analysis of spatial transcriptomics as ‚Äúrocket science,‚Äù and I remember balking at the comparison. In some ways, I thought, it‚Äôs far more complex. Humanity‚Äôs first steps on the moon were guided by software engineering that was itself a new frontier, yet it was built upon a foundation of physics understood for centuries. Even the first draft of the human genome, a monumental achievement from nearly a generation ago1, was a challenge of reading a single, linear code. Our task today is to interpret an entire library of those codes being read simultaneously across a bustling city of cells. This is the distinctly 21st-century frontier we now face.\nThis guide is the resource I wish I had when I first faced that frontier. It was born from my own journey of piecing together workflows from open-sourced code and gradually building an intuition for what this beautiful and complex data was revealing. My goal is not simply to provide a set of computational recipes, but to walk alongside you through a complete, end-to-end analysis of CosMx SMI Whole Transcriptome data. We will start with the raw files and move step-by-step through quality control, cell typing, and downstream analysis.\nAlong the way, we will move beyond static figures. This guide is designed to be an active learning experience, encouraging you to engage directly with the dataset to develop your own tactile feel for the analysis. This work is also dynamic in the approaches and content that is presented. New tertiary analyses are already in the works including ligand-receptor and trajectory analyeses. My hope is that by the end, you will have not only a robust workflow but also the confidence to adapt it to answer your own unique biological questions. That confidence is essential, because this is the landscape that Whole Transcriptome CosMx SMI data invites us into: a territory of discovery where the rules are still being written. Our challenge is not one of engineering known forces, but of interpreting a biological language we are only beginning to understand. This guide provides the tools to begin that translation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Lander, E. S. et al. Initial sequencing and analysis of the human genome. Nature 409, 860‚Äì921 (2001).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "how-to-use.html",
    "href": "how-to-use.html",
    "title": "How to Use This Book",
    "section": "",
    "text": "Who This Book Is For üî¨\nThis guide is for any scientist or bioinformatician interested in analyzing CosMx¬Æ Spatial Molecular Imager (SMI) data. It is designed to be accessible for newcomers while also providing a robust, reproducible workflow for experienced users.\nWhile our primary focus will be on a single-slide, subcellular Whole Transcriptome (WTX) dataset, the principles and code are broadly applicable to other RNA panels (like the 1K or 6K panels). Larger, multi-slide experiments have additional considerations that will be a topic for another day. While this book demonstrates a complete analysis from start to finish, its chapters are also designed to be modular. This structure allows you to either follow the entire workflow linearly or to treat it as a ‚Äúchoose your own adventure‚Äù guide‚Äîjumping directly to the sections most relevant to your specific questions and data.",
    "crumbs": [
      "How to Use This Book"
    ]
  },
  {
    "objectID": "how-to-use.html#navigating-this-guide",
    "href": "how-to-use.html#navigating-this-guide",
    "title": "How to Use This Book",
    "section": "Navigating This Guide üó∫Ô∏è",
    "text": "Navigating This Guide üó∫Ô∏è\nThis content is structured as a Quarto Book, with several features to help you find information:\n\nLeft Sidebar: Provides navigation between the main chapters of the book.\nRight Sidebar: Shows a table of contents for the sections within the current chapter.\n&lt;/&gt; Code Button: Located in the top-right corner of many pages, this button will show or hide the source code used to generate the outputs in a given section, programmatic formatting of tabs of plots, Observable JS code blocks of interactive plots that are not otherwise shown directly, etc.",
    "crumbs": [
      "How to Use This Book"
    ]
  },
  {
    "objectID": "how-to-use.html#the-analytical-philosophy",
    "href": "how-to-use.html#the-analytical-philosophy",
    "title": "How to Use This Book",
    "section": "The Analytical Philosophy üß†",
    "text": "The Analytical Philosophy üß†\nThere is no single ‚Äúcorrect‚Äù way to analyze spatial data, just as there is no single, linear path that individual cells interact. The most powerful analysis is always driven by the specific biological questions and hypotheses of your study and even then there are multiple statistical approaches that can work. This book does not present a rigid, one-size-fits-all pipeline. Instead, it provides a comprehensive and adaptable foundation. The goal is to equip you with the tools and intuition needed to confidently explore your own data and tailor the analysis to your unique research goals.\n\n\n\n\n\n\n\nAlternative Approach\n\n\nThere are so many ways to analyze CosMx SMI data. While this book shows a few such solutions, there are some other methods that may be worth considering. I‚Äôll make use of these Alternative Approach boxes like this to suggest additional ways to tackle a given problem. If there are two approaches that are helpful to show side-by-side I‚Äôll show those in the main text.\n\n\n\n\n\n\n\nDeep Dives\n\n\n\n\n\nReaders who are interested in learning additional details about a particular topic, such as how certian function parameters effect a result, can learn more in boxes with the gear icon. These sections can be expanded or collapsed by clicking on the arrow on the top right of the box.\n\n\nIf an interactive visualization is needed to help us understand a particular topic, I may make use of serverless webassembly techniques such as those found in the fantastic quarto-live1 quarto extension. In a nutshell, the quarto-live extension provide instructions to your browser on how to run R or python content. This integrates well with Observable JS and quarto. For more information on quarto-live, see their online documentation.\n\n\n\n\n\n\n\n\n\nfeel free to adjust the code and run it.",
    "crumbs": [
      "How to Use This Book"
    ]
  },
  {
    "objectID": "how-to-use.html#technical-approach-and-reproducibility",
    "href": "how-to-use.html#technical-approach-and-reproducibility",
    "title": "How to Use This Book",
    "section": "Technical Approach and Reproducibility üõ†Ô∏è",
    "text": "Technical Approach and Reproducibility üõ†Ô∏è\nThis guide uniquely leverages the combined strengths of both R and Python, as both languages offer exceptional, complementary ecosystems for spatial analysis. I primarily use Python‚Äôs AnnData2 and scanpy3 packages for their performance and scalability, while relying on R‚Äôs tidyverse4 for specific statistical methods, data wrangling, and visualization. RStudio‚Äôs integrated support for both languages via reticulate5 makes this hybrid approach surprisingly seamless. To ensure a fully reproducible analysis environment, the project repository for this book includes:\n\nrenv.lock: A file to restore the exact R package library using the renv package.\nrequirements.txt: A file to recreate the Python environment using pip. Instructions for setting up the complete, combined environment can be found in the project‚Äôs README file on GitHub.\n\nSince this book was written in the Quarto book format, individual chapters are executed ‚Äúin isolation‚Äù from one another. This means its necessary to write data to disk in order for a subsequent chapter to be able to use it. Certain computations can take hours as well and so it‚Äôs not ideal to try to unnecessarily re-compute these each time I ‚Äúbuild‚Äù (render) this book. My technical approach here ‚Äì and indeed in most of my daily analyses ‚Äì is to analyze code blocks interactively and then only evaluate code blocks that are absolutely necessary for rendering the documnet such as including and formatting a pre-computed image. More information about this analysis system can be found in the Introduction.\nThroughout this book I work with a particular dataset to show an end-to-end analysis. There are some asides that are not part of the analysis but rather to illustrate an idea or provide supporting materal. For code blocks that are not part of the main analysis, I‚Äôll mark the a ‚ÄúPython - supporting‚Äù tag like so:\n\n\nPython - supporting\n# Code used for supporting material\n\n\nIf you are interested in adapating this environment to your own workflow, please see more information Setting up Your Own Analysis Environment.\nI should note that CosMx SMI data analysis can be quite resource demanding. The analysis within this book was created on Amazon g6.16xlarge EC2 instance equipped with one L4 NVIDIA GPU (24 GB RAM) and 64 vCPUs (256 GB RAM). The operating system that was used was Ubuntu 24.04.1 LTS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. The R-WASM Team. quarto-live: WebAssembly powered code blocks and exercises for R and Python in Quarto. (2024).\n\n\n2. Virshup, I., Rybakov, S., Theis, F. J., Angerer, P. & Wolf, F. A. Anndata: Access and store annotated data matrices. Journal of Open Source Software 9, 4371 (2024).\n\n\n3. Wolf, F. A., Angerer, P. & Theis, F. J. SCANPY: Large-scale single-cell gene expression data analysis. Genome Biol. 19, (2018).\n\n\n4. Wickham, H. et al. Welcome to the tidyverse. Journal of Open Source Software 4, 1686 (2019).\n\n\n5. Ushey, K., Allaire, J. & Tang, Y. Reticulate: Interface to ‚ÄôPython‚Äô. (2025).",
    "crumbs": [
      "How to Use This Book"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1¬† Introduction",
    "section": "",
    "text": "1.1 What is the CosMx¬Æ Spatial Molecular Imager?\nOur journey into the frontier of spatial biology begins! But before we jump right into the code, it‚Äôs important to build a foundational understanding of the technology that we‚Äôre analyzing data from, how to access data, and the biological context of the sample we‚Äôll be analyzing throughout this guide.\nTraditional methods like bulk and single-cell RNA sequencing have revolutionized biology, but they come with a critical limitation: by dissociating tissue into a suspension, they erase all spatial context. We learn which cells are present, but not where they were or how they were organized.\nThe CosMx SMI is an in-situ imaging technology designed to overcome this challenge. Instead of removing cells from the tissue, it measures RNA or protein molecules directly in their native environment, providing a high-plex, high-resolution map of cellular activity.\nThe underlying chemistry and hardware, detailed by He et al.1, enables a multi-step process:\nThe final output is a rich suite of data tables, including the foundational gene-by-cell expression matrix, spatial coordinates, and morphological features for every cell. This is complemented by the raw imaging data, which enables deeper quality control and visualization, as we‚Äôll explore in later chapters.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#what-is-the-cosmx-spatial-molecular-imager",
    "href": "introduction.html#what-is-the-cosmx-spatial-molecular-imager",
    "title": "1¬† Introduction",
    "section": "",
    "text": "Labeling: Tissue sections on a glass slide are treated with a cocktail of probes designed to bind to specific target RNA molecules. These probes act as unique, programmable labels.\nImaging Cycles: The slide is placed in the instrument and imaged in a series of cycles. In each cycle, fluorescent ‚Äúreporter‚Äù probes are washed over the tissue, lighting up a subset of the molecular labels.\nBarcode Reading: An image is captured in each cycle. The pattern of ‚Äúon‚Äù and ‚Äúoff‚Äù signals for a single RNA molecule across all cycles creates a unique optical barcode that identifies the gene target. The molecule‚Äôs (X, Y, Z) coordinates are precisely measured from its position in the high-resolution images.\nCell Segmentation: Finally, the identified transcripts and protein markers are assigned to individual cells. This segmentation process relies on immunofluorescence (IF) stains‚Äîsuch as DAPI to visualize nuclei and antibodies against proteins like CD298 to visualize cell membranes‚Äîthat allow algorithms to accurately draw cell boundaries.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#accessing-cosmx-smi-data",
    "href": "introduction.html#accessing-cosmx-smi-data",
    "title": "1¬† Introduction",
    "section": "1.2 Accessing CosMx SMI Data",
    "text": "1.2 Accessing CosMx SMI Data\nAfter a CosMx experiment, the instrument uploads raw imaging data to the AtoMx¬Æ Spatial Informatics Platform (SIP), a cloud-based environment where the heavy computation of barcode decoding and cell segmentation occurs. Once this primary processing is complete, the data can be explored within the AtoMx SIP ecosystem or, as we will do, exported for custom downstream analysis.\n\n\n\n\n\n\n\n\nTipExporting from AtoMx¬Æ SIP\n\n\n\nFor a detailed guide on navigating the AtoMx SIP interface and exporting your processed data, see the post: Using Squidpy with AtoMx¬Æ SIP exports.\n\n\nPublic datasets are another invaluable resource. For example, Bruker provides a list of FFPE datasets, and indeed for this guide, we will be analyzing the human colon cancer dataset featured on that site.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#sec-setup-env",
    "href": "introduction.html#sec-setup-env",
    "title": "1¬† Introduction",
    "section": "1.3 Setting up Your Own Analysis Environment",
    "text": "1.3 Setting up Your Own Analysis Environment\n\n\n\n\n\n\nNote\n\n\n\nFor this initial release the renv.lock, requirements.txt, and other helper files are not yet available. Check back later for the source code for this book.\n\n\nThis subsection in primarily for those who wish to use this book as a springboard for their own analysis.\nWhen working in a mixed R and python environment, I make use of RStudio IDE and work within an analysis ‚ÄúProject‚Äù. While your version of R will likely be different, this particular version is R version 4.5.1 (2025-06-13) and managing packages with renv2. Similarly, I‚Äôm using a virtual environment within pyenv that‚Äôs based on Python 3.10.18.\nI highly recommend maintaining packages within your project as this field is moving at a very rapid pace and package versions can quickly create issues and conflicts. To ‚Äúrestore‚Äù the R packages use renv::restore() within the project folder. To create the python virtual environment using pyenv, type this into your terminal:\n1pyenv install 3.10.18\npyenv virtualenv 3.10.18 pyenv_simple\npyenv activate pyenv_simple\npip install -r requirements.txt\n\n1\n\nassumes you have pyenv installed. See Additional Resources for more information on pyenv.\n\n\nTo link this virtual environment to our project, I make use of symbolic links and add the path to my .Renviron project file.\nFor example, typing\npyenv versions\nin the terminal will reveal the specific path that pyenv placed the virtual environment. For me it was:\n pyenv versions\n  system\n  3.10.18/envs/pyenv_simple\n* pyenv_simple --&gt; /opt/pyenv/versions/3.10.18/envs/pyenv_simple (set by /opt/pyenv/version)\nand then within the project directory I can add pyenv_simple to the folder like so:\nln -s /opt/pyenv/versions/3.10.18/envs/pyenv_simple ./pyenv_simple\nNow that a symbolic link to the virtual environment is present in the project directory, add this line to .Renviron and restart Rstudio.\nRETICULATE_PYTHON=pyenv_simple/bin/python\nThe organizational structure of the data itself is as follows: within the analysis_results folder there is a folder for input_files and another folder for output_files. Within the output_files folder there will be a series of sub-folders with data as well as a file is named results_list.rds that I‚Äôll populate throughout and use to ‚Äì for example ‚Äì reference the number of cells or other ‚Äúsmall‚Äù statistics that will be handy.\nFinally, since Quarto renders each chapter in isolation, at the beginning of analysis chapters we will add a ‚Äúpreamble‚Äù that loads common R scripts, python functions, and the results_file.rds file.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#our-example-dataset",
    "href": "introduction.html#our-example-dataset",
    "title": "1¬† Introduction",
    "section": "1.4 Our Example Dataset",
    "text": "1.4 Our Example Dataset\nThoughout this book, we‚Äôll examine these foundational WTX analyses by looking at a 400-field-of-view (FOV) section of FFPE colon adenocarcinoma. This tissue was analyzed using Bruker Spatial Biology‚Äôs pre-commercial WTX CosMx¬Æ SMI assay and is available online. Our primary biological questions driving this analysis are:\n\nWhat are the major spatial domains within this sample and what cell types do they contain?\nWhat pathways are enriched within these domains?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. He, S. et al. High-plex imaging of RNA and proteins at subcellular resolution in fixed tissue by spatial molecular imaging. Nat. Biotechnol. 40, 1794‚Äì1806 (2022).\n\n\n2. Ushey, K. & Wickham, H. Renv: Project Environments. (2024). doi:10.32614/CRAN.package.renv.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data-ingestion.html",
    "href": "data-ingestion.html",
    "title": "2¬† Data Wrangling",
    "section": "",
    "text": "No data analysis journey can truly begin without first converting something and our task for this chapter is simple: take the flat files that are exported from AtoMx SIP into a usable format. That format is primarily python‚Äôs anndata format but, interestingly enough, we‚Äôll take advantage of R‚Äôs data.table1 package to efficiently read in the expression matrix file. I find this is much faster than reading in the expression matrix into pandas.\nSplit the expression data into targets, negatives, and system controls. Read in the metadata and add columns that represent the slide position in micrometers.\nWhile the matrix and metadata information do not contain cell segmentation detail, it‚Äôs always a good idea to plot the cells in space to ensure they match our expected orientation.\nFigure¬†2.1 confirms the expected orientation and alignment from the flat files.\nWith that confirmation, create the initial anndata object. Specifically, we‚Äôll start with dense1 matrices of expression, system controls (i.e., ‚Äúfalse codes‚Äù), and negative probes, and add these into the X elment and into obsm, respectively. We‚Äôll place the metadata into the obs and we‚Äôll also create a matrix of (X, Y) coordinates into their own obsm.\nWhen analyzing interactively I switch between R and python blocks explicitly with reticulate::reply_python() to enter python and type exit() to return back to R.\nAnd that‚Äôs it! Our data have been converted into anndata format and now we‚Äôre ready to assess the quality.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "data-ingestion.html#footnotes",
    "href": "data-ingestion.html#footnotes",
    "title": "2¬† Data Wrangling",
    "section": "",
    "text": "I generally avoid handing off sparse matrices from R to python and vice versa and since the data were dense to begin with (i.e., it was a CSV file), we‚Äôll make it sparse in with python.‚Ü©Ô∏é",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "quality-processing.html",
    "href": "quality-processing.html",
    "title": "3¬† Quality Processing",
    "section": "",
    "text": "3.1 FOV QC\nThis section is critical in any data analysis. We‚Äôll pass the data through a series of filters to ensure the downstream processing steps contain high-quality data. We do this by screening and flagging any FOVs that might have lower quality and running a counts-based filter.\nLoad the dataset we generated in Chapter 2.\nLower quality FOVs generally result in reduced overall gene expression or reduced signal from select genes. Potential causes for lower FOV quality (e.g.¬†lower relative signal for all/select genes for a given FOV compared to majority of FOVs) include tissue/section quality, high autofluorescence, and inadequate fiducials. We can quantify this signal loss using the FOV QC method as described recently in this scratch space tool. For a more detailed explanation of the the FOV QC functions, expand the box below.\nSince the FOV QC code was written in R, convert relevant annData components to R objects.\nPython Code\nmeta = adata.obs.copy()\nexpr = adata.X.astype('float64')\nRun the runFOVQC routine. The source call below will load several functions into memory. Since this dataset is from WTX, we‚Äôll use the barcode patterns from Hs_WTX.\nR Code\n# source the necessary functions:\n1source(\"https://raw.githubusercontent.com/Nanostring-Biostats/CosMx-Analysis-Scratch-Space/Main/_code/FOV%20QC/FOV%20QC%20utils.R\")\n\n\nallbarcodes &lt;- readRDS(url(\"https://github.com/Nanostring-Biostats/CosMx-Analysis-Scratch-Space/raw/Main/_code/FOV%20QC/barcodes_by_panel.RDS\"))\n\nresults_list[['barcodes']] &lt;- allbarcodes['Hs_WTX']\nsaveRDS(results_list, results_list_file)\n\n\n\n1\n\nFor historic reasons, the characters in the barcode string are duplicated.\nWith the functions loaded, execute the runFOVQC function. For this example, I choose a less restrictive parameter set (max_prop_loss = 0.4 and max_totalcounts_loss = 0.3).\nPlot the flagged FOVs in R simply with mapFlaggedFOVs(res) function to get the spatial layout of any FOVs that were flagged. In this case (Figure¬†3.1), you can see some FOVs that were flagged along the tissue perimeter.\nFigure¬†3.1: Spatial location of the flagged FOVs.\nFor the targets that were flagged, plot how many FOVs they were flagged in.\nR Code\nflagged_genes &lt;- res$flagged_fov_x_gene[,2]\n1flagged_genes &lt;- flagged_genes[!is.na(flagged_genes)]\nflagged_genes &lt;- as.data.frame(rev(sort(table(flagged_genes))))\ncolnames(flagged_genes)[1] &lt;- 'target'\n\ndf &lt;- data.frame(target=py$adata$var_names$to_list())\ndf &lt;- merge(df, flagged_genes, by=\"target\", all.x=TRUE, all.y=FALSE)\ndf$Freq[is.na(df$Freq)] &lt;- 0L\n\npy$adata$var['fov_qc_flagged'] &lt;- as.integer(df$Freq)\n\np &lt;- ggplot(flagged_genes, aes(x = factor(Freq), fill = factor(Freq))) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=after_stat(count)), vjust=-0.5) +\n  labs(x = \"Number of FOVs\", y = \"Number of Flagged Genes\") +\n  theme_minimal() +\n  scale_x_discrete(breaks = 1:13) + \n  theme(legend.position = \"none\")\n\nggsave(p, filename=file.path(qc_dir, \"genes_impacted_in_flagged_fovs.png\"),\n       width=4, height=5, dpi=150, type=\"cairo\")\n\n\n\n1\n\nA value of NA here means the gene in a given FOV was not flagged.\nFigure¬†3.2: Number of targets impacted in a given number of FOVs.\nIn Figure¬†3.2, there are only a few genes (149) that were flagged in three FOVs. If we found a set of genes that were systematically flagged in many FOVs, we may consider removing the impacted FOVs. Alternatively we could remove the impacted genes from all FOVs. In this sample, it‚Äôs probably fine to ignore this result.\nWith the FOVSignalLossSpatialPlot function, we can gain a higher resolution perspective by plotting the 7x7 sub-FOV grids across space and coloring these sub-FOV grids by the change in our expected total counts. In Figure¬†3.3, our focus is on FOVs that are solidly blue which would suggestion fewer transcripts than other FOVs. In this example, eight of the FOVs flagged as low total counts occured along the tissue border and were not complete 7x7 grids. The other section in Figure¬†3.3 is contiguous and may suggest a domain or type of tissue with lower overall transcripts.\nFigure¬†3.3: Number of genes impacted in a given number of FOVs.\nTo see details how these FOVs might have been impacted, we can use the function below to plot the signal lost found for each cycle-by-reporter combination.\nR Code\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\nFOVEffectsHeatmap &lt;- function(res, fovs=NULL,\n                              cluster_rows = FALSE, \n                              cluster_columns = TRUE) {\n  if(is.null(fovs)){\n    fovs &lt;- rownames(res$fovstats$bias)\n  }\n\n  transposed_matrix &lt;- t(res$fovstats$bias[fovs,])\n  col_fun = colorRamp2(\n    breaks = c(min(transposed_matrix), 0, max(transposed_matrix)), \n    colors = c(\"magenta\", \"white\", \"cyan\") \n  )\n  \n  ht_obj &lt;- ComplexHeatmap::Heatmap(\n      matrix = transposed_matrix,\n      name = \"FOV bias\", \n      col = col_fun, \n      cluster_rows = cluster_rows, \n      cluster_columns = cluster_columns, \n      show_row_dend = TRUE, \n      show_column_dend = TRUE, \n      row_names_gp = gpar(fontsize = 7), \n      column_names_gp = gpar(fontsize = 8)\n  )\n  \n  return(ht_obj)\n}\n\npng(file.path(qc_dir, \"FOVEffectsHeatmap.png\"), \n    width=10, height=15, res=350, units = \"in\", type = 'cairo')\n  draw(FOVEffectsHeatmap(res, fovs=res$flaggedfovs))\ndev.off()\n\nresults_list$flaggedfovs &lt;- res$flaggedfovs\nsaveRDS(results_list, results_list_file)\nFigure¬†3.4: Reporter-by-FOV combinations that were flagged.\nWhat we are checking for in Figure¬†3.4 is:\nWhile we do see two reporter cycles (19 and 27) with two flagged FOVs (155 and 239), each, there‚Äôs no evidence of a systemic signal lost in any reporter cycle. If we did find strong evidence, one could conservatively filter out the genes that are present in that reporter cycle. This would be roughly 2,000 genes for a given reporter cycle. Looking from the perspective of the FOVs (#2), we see only a handful of FOVs showed one (or two) underperforming reporter cycles. These include FOVs 92, 113, 155, 160, and 239. At this point, one could remove all FOVs that were flagged (length(res$flaggedfovs); 23 in this case), just the five that we found evidence of signal lost in one or more reporter cycles, or flag the cells within the impacted FOVs and see if any downstream results are impacted. If you wanted to be on the conservative side, you would remove all flagged FOVs unless you have biological justification that the signal difference isn‚Äôt due to FOV effects. For this analysis, I‚Äôll simply do the ‚Äúflag and monitor‚Äù approach.\nR Code\nmeta &lt;- py$adata$obs\nmeta$fovqcflag &lt;- ifelse(meta$fov %in% as.numeric(res$flaggedfovs), 1, 0)\npy$adata$obs$fovqcflag &lt;- meta$fovqcflag",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Quality Processing</span>"
    ]
  },
  {
    "objectID": "quality-processing.html#sec-fov-qc",
    "href": "quality-processing.html#sec-fov-qc",
    "title": "3¬† Quality Processing",
    "section": "",
    "text": "Understanding the FOV QC parameters\n\n\n\n\n\nThis deep dive shows a how the two tuning parameters of the FOV QC function, max_prop_loss and max_totalcount_loss), affect the results.\nThe parameter max_prop_loss sets a tolerance for the maximum allowable proportion of signal loss for any single barcode bit before an FOV is flagged. For example, if we set max_prop_loss to 0.3, it means we‚Äôd accept a given bit given if it has lost 30% of its original strength. While max_prop_loss focuses on the errors in a single specific barcode bit, max_totalcounts_loss looks at the bigger picture. It asks, ‚ÄúIs this entire FOV significantly dimmer or less populated with transcripts than it should be?‚Äù This can help detect broader issues like poor tissue quality, focusing problems, or reagent failures in that specific area.\nLet‚Äôs see what happens to the number of flagged FOVs when adjust these parameters.\n\nviewof max_prop_loss = Inputs.range([0.1, 0.6], {\n  step: 0.1,\n  label: \"Max Proportion Loss\"\n})\nviewof max_totalcounts_loss = Inputs.range([0.1, 0.6], {\n  step: 0.1,\n  label: \"Max Total Counts Loss\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code below will plot the spatial distribution of failed FOVs. Feel free to adjust the code, if desired.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAny report cycles that show systematically reduced signal across many FOVs\nAny FOVs that show underperforming multiple reporter cycles.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Quality Processing</span>"
    ]
  },
  {
    "objectID": "quality-processing.html#cell-level-qc",
    "href": "quality-processing.html#cell-level-qc",
    "title": "3¬† Quality Processing",
    "section": "3.2 Cell-level QC",
    "text": "3.2 Cell-level QC\nWhere the previous section examined signal at the FOV level, this section examines target counts at the cell level. The purpose of this filter is simple: to remove low signal outliers while keeping the biology. The cells in a given dataset comprise of a mix of:\n\nviable, intact cells with high signal\ndamaged or dying cells. These may have leaky membranes and may have reduced cytoplasmic RNA\nimperfect segmentation of cells ‚Äì especially around FOV borders\n\nand so our aim is to filter out cells from the latter two scenarios.\nCounts-based filtering has a trade-off. While several downstream ‚Äútertiary‚Äù analyses account for low signal in a variety of ways (discussed later), many of the pre-processing lenient cutoff can introduce low-quality cells in dimensional reductions like PCA and UMAP and can break up clustering patterns (creating spurious clusters or merging otherwise distinct clusters). On the other hand, a stringent cutoff can introduce unexpected signal lost. This is because cell types vary in their transcript counts so removing cells based on counts will distort the composition of cells in your data.\nBest practice for counts based filtering of CosMx data includes:\n\nexamining the distribution of transcript and gene counts\nchoosing an initial permissive or lenient cutoff\nexamining signal relative to background\nplotting the spatial distribution of flagged cells in space\nremoving small cell artifacts around the FOV borders\nincluding plots of total transcripts in your downstream pre-processing steps\n\n\n\n\n\n\n\n\nAlternative Approach\n\n\nThere are many cell-level attributes that one can use as a bases for filtering and it is recommended to use metrics relevant to your tissue. For example, if you are analyzing brain, you many want to incorporate or evaluate cell area, eccentricity, or other morphological characteristics that are available in the metadata. For a list of cell metadata column definitions, you can see this Scratch Space blog post\n\n\n\n3.2.1 Counts and Features\nFor the distribution of transcript and gene counts, I like to look at the joint distribution in addition to the univariate distributions. In the code below I set a permissive, symmetrical threshold of 2.5 standard deviations (SDs) around the mean (in log10 space) but this thresholding is sample-dependent so different values might make more sense on your data.\n\n# meta &lt;- py$adata$obs\ncounts_min_threshold &lt;- round(10^(mean(log10(meta$nCount_RNA)) - 2.5*sd(log10(meta$nCount_RNA))))\nfeatures_min_threshold &lt;- round(10^(mean(log10(meta$nFeature_RNA)) - 2.5*sd(log10(meta$nFeature_RNA))))\ncounts_max_threshold &lt;- round(10^(mean(log10(meta$nCount_RNA)) + 2.5*sd(log10(meta$nCount_RNA))))\nfeatures_max_threshold &lt;- round(10^(mean(log10(meta$nFeature_RNA)) + 2.5*sd(log10(meta$nFeature_RNA))))\n\nresults_list['counts_min_threshold'] = counts_min_threshold\nresults_list['features_min_threshold'] = features_min_threshold\nresults_list['counts_max_threshold'] = counts_max_threshold\nresults_list['features_max_threshold'] = features_max_threshold\n\n\nmeta$counts_filter &lt;- ifelse(\n  meta$nFeature_RNA &gt;= features_min_threshold & \n         meta$nFeature_RNA &lt;= features_max_threshold & \n         meta$nCount_RNA &gt;= counts_min_threshold & \n         meta$nCount_RNA &lt;= counts_max_threshold\n  , \"pass\", \"filtered\")\n\nresults_list['prop_counts_based_filter'] &lt;- sum(meta$counts_filter==\"pass\") / nrow(meta)\nsaveRDS(results_list, results_list_file)\n\n\nlibrary(scales)\np &lt;- ggplot(\n  data = meta,\n  aes(x=nFeature_RNA, y=nCount_RNA, color=counts_filter)) + \n  geom_point(alpha=0.002, pch=\".\") +\n  scale_color_manual(values=c(\"pass\"=\"dodgerblue\", \"filtered\"=\"darkorange\")) +\n  geom_vline(xintercept = c(features_min_threshold, features_max_threshold), lty=\"dotted\") + \n  geom_hline(yintercept = c(counts_min_threshold, counts_max_threshold), lty=\"dotted\") + \n  scale_x_log10(\n    breaks = trans_breaks(\"log10\", function(x) 10^x),\n    labels = trans_format(\"log10\", math_format(10^.x))\n  ) +\n  scale_y_log10(\n    breaks = trans_breaks(\"log10\", function(x) 10^x),\n    labels = trans_format(\"log10\", math_format(10^.x))\n  ) + \n  theme_minimal() + \n  coord_fixed() + \n  theme(legend.position = \"none\")\n  \np &lt;- ggMarginal(p, type = \"density\")\n\nggsave(filename = file.path(qc_dir, \"qc_joint_distribution.png\"), p,\n       width=8, height=8, type = 'cairo')\n\np1 &lt;- ggplot(\n      data=meta, \n      aes(x=nCount_RNA)) + \n      geom_density(alpha=0.01) + \n      # scale_x_log10() +\n      theme_minimal() + \n      geom_vline(xintercept = c(counts_min_threshold, counts_max_threshold), lty=\"dotted\") \n\nggsave(filename = file.path(qc_dir, \"qc_dist_counts.png\"), p1,\n       width=8, height=8, type = 'cairo')\n\np2 &lt;- ggplot(\n      data=meta, \n      aes(x=nFeature_RNA)) + \n      geom_density(alpha=0.01) + \n      # scale_x_log10() +\n      theme_minimal() + \n      geom_vline(xintercept = c(features_min_threshold, features_max_threshold), lty=\"dotted\") \n\nggsave(filename = file.path(qc_dir, \"qc_dist_features.png\"), p2,\n       width=8, height=8, type = 'cairo')\n\np3 &lt;- ggplot(\n        data=meta) +\n      geom_point(\n        aes(x=x_slide_mm, y=y_slide_mm, color=counts_filter),\n        size=0.001, alpha=0.02) + \n      coord_fixed() + theme_bw() + \n      scale_color_manual(values=c(\"pass\"=\"dodgerblue\", \"filtered\"=\"darkorange\")) + facet_wrap(~counts_filter) + \n      guides(color = guide_legend(override.aes = list(size = 7, alpha = 1)))\n\nggsave(filename = file.path(qc_dir, \"qc_xy_flagged.png\"), p3,\n       width=8, height=8, type = 'cairo')\n\nThe tabs below show the summary plots. Based on the distributions, the following thresholds we derived from the data: min counts = 148, max counts = 9973, min features = 120, max features = 6016. This removes about 2% of the data. The spatial layout of these flagged cells shows some concentration along the perimeter and epithelial regions. No concentration within FOVs were observed (Figure¬†3.8).\n\nTranscripts per cellFeatures per cellJoint DistributionSpatial Arrangement of flagged cells\n\n\n\nrender(file.path(analysis_asset_dir, \"qc\"), \"qc_dist_counts.png\", qc_dir)\n\n\n\n\n\n\n\nFigure¬†3.5: Distribution of transcripts per cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3.6: Distribution of features per cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3.7: Joint distribution of targets (features vs counts).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3.8: Spatial arrangement of flagged cells.\n\n\n\n\n\n\n\n\n\n\n3.2.2 (Optional) Cells Near FOV Borders\nIn this particular dataset, 6.2% of the cells were located on the border of FOVs (i.e., touching the FOV edge). This is a minority of cells that in the analysis as a whole shouldn‚Äôt affect downstream analyses. For this reason this step is optional.\nWithin the metadata there is a column named SplitRatioToLocal. For cells that are adjacent to the FOV boundaries, the SplitRatioToLocal metric measures the cell area relative to the mean area of cells in the FOVs. For 0 &lt; SplitRatioToLocal &lt; 1, the cell is smaller than average and for SplitRatioToLocal &gt; 1 the cell is larger than average. A value of 0 means the cell is not along the border. Let‚Äôs plot the distribution of boarder abutting cells (i.e., SplitRatioToLocal &gt; 0) and tentatively choose a cutoff of SplitRatioToLocal = 0.5 which translates to removing cells that are 0.5 (50%) the average cell size. Since this is a ratio, we‚Äôll plot in log2 space (log2(SplitRatioToLocal) &lt; -1).\n\n\nR Code\nresults_list['SplitRatioToLocalThreshold'] &lt;- 0.5\nsaveRDS(results_list, results_list_file)\n\n# meta &lt;- py$adata$obs\n\nlibrary(patchwork)\nlibrary(scales)\n\np_detail &lt;- ggplot(\n    data = meta %&gt;% filter(SplitRatioToLocal != 0), \n    aes(x = log2(SplitRatioToLocal))) + \n    geom_histogram(bins = 100, fill = \"steelblue\") +\n    labs(\n      x = expression(log[2](\"SplitRatioToLocal\")),\n      y = \"Number of FOV border cells\"\n    ) + \n    theme_minimal() + \n    geom_vline(xintercept = log2(results_list[['SplitRatioToLocalThreshold']]), \n               color = \"darkorange\", lty = \"dashed\")\npie_data &lt;- meta %&gt;%\n  mutate(Category = if_else(SplitRatioToLocal &gt; 0, \"Border cell\", \"Non-border cell\")) %&gt;%\n  count(Category) %&gt;%\n  mutate(\n    Percentage = (n / sum(n)) * 100,\n    Label = paste0(Category, \" (\", round(Percentage, 1), \"%)\")\n  )\n\np_pie &lt;- ggplot(pie_data, aes(x = 2, y = n, fill = Category)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_manual(values = c(\"Border cell\" = \"steelblue\", \"Non-border cell\" = \"gray90\")) +\n  geom_text(aes(label = Label), \n            position = position_stack(vjust = 0.5), \n            size = 3, \n            fontface = \"bold\") +\n  theme_void() +\n  xlim(0.5, 2.5) + \n  theme(legend.position = \"none\")\n\nfull_plot &lt;- p_detail + \n  inset_element(\n    p_pie, \n    left = 0.6, bottom = 0.6, \n    right = 1.0,\n    top = 1.0\n  )\n\nggsave(filename = file.path(qc_dir, \"qc_splitratiotolocal.png\"), full_plot,\n       width=5, height=5, type = 'cairo')\n\n\n\n\n\n\n\n\n\n\nFigure¬†3.9: Distribution of SplitRatioToLocal for cells abutting an FOV border. Overlay: proportion of border cells relative to all cells.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Quality Processing</span>"
    ]
  },
  {
    "objectID": "quality-processing.html#regional-level-cell-qc",
    "href": "quality-processing.html#regional-level-cell-qc",
    "title": "3¬† Quality Processing",
    "section": "3.3 Regional-level cell QC",
    "text": "3.3 Regional-level cell QC\nIt‚Äôs possible that some regions of the tissue might have high background. We can evaluate the total signal relative to the background. For this approach we are interested in the Signal to Background Ratio (SBR) in neighborhoods or tissue regions as opposed to cell-level measures or target-level measures. Since the number of targets is not comparable to the number of negative probes, we‚Äôll consider the average target expression (S) divided by the average background expression.\n\\[sbr = \\frac{S}{\\mu_{B}}\\]\nWhen passing the data through this equation, you‚Äôll likely find that many cells have an undefined SBR due to the sparse nature of background counts. To mitigate this effect, we can spatially smooth the transcript and background counts before applying this equation. To do this we‚Äôll use the liana package that creates a connectivities matrix based on a Gaussian kerneland then multiple this matrix by the negative probe matrix and the expression matrix to get the spatially-weighted matrices for each. For more information on this spatial smoothing see Chapter 7.\n\n\nPython Code\nimport liana as li\n\nli.ut.spatial_neighbors(\n    adata,\n1    bandwidth=0.010,\n2    cutoff=0.080,\n    kernel='gaussian',\n    set_diag=True,\n    key_added = 'liana',\n    standardize=True\n)\n\nconnectivities = adata.obsp['liana_connectivities']\nadata.obsm['counts_neg_spatially_smooth'] = connectivities @ adata.obsm['counts_neg']\nadata.obsm['counts_spatially_smooth'] = connectivities @ adata.X\nsmoothed_mean_neg = np.ravel(adata.obsm['counts_neg_spatially_smooth'].mean(axis=1))\nsmoothed_mean_target = np.ravel(adata.obsm['counts_spatially_smooth'].mean(axis=1))\nepsilon = 1e-9\nSBR = smoothed_mean_target / (smoothed_mean_neg + epsilon)\n\n\n\n1\n\nuse 10 ¬µm bandwidth (this tunable)\n\n2\n\nanything below this value is considered 0 (this is tunable)\n\n\n\n\n\n\n\n\n\n\n\nAlternative Approach\n\n\nWhile not entirely equivalent, if you run into memory issues with creating a spatially-weighted expression matrix, you can instead spatially smooth the total counts from the metadata column nCount_RNA.\n\n\nWhat we are looking for in SBR are larger tissue regions with low SBR ‚Äì not necessarily individual cells with low SBR. Looking at Figure¬†3.10 we see a low SBR region on the top of the tissue just below the epithelium. This region corresponds to an area of smooth muscle and we‚Äôll see in the next section that this region partially overlaps with an area flagged by the FOV-level QC. Since these low SBR cells (i.e., log2(SBR) &lt; 0) are concentrated spatially, we‚Äôll choose to flag them for removal.\n\n\nR Code\nmeta$SBR &lt;- py$SBR\n\nsbr_breaks &lt;- c(-Inf, -1, 0, 1, 2, 3, Inf)\n\nsbr_labels &lt;- c(\"&lt;= -1\", \"-1 to 0\", \"0 to 1\", \"1 to 2\", \n                \"2 to 3\", \"&gt; 3\")\nsbr_labels &lt;- paste0(sbr_labels,\n                     paste0(\" (\", round(100 * table(cut(log2(meta$SBR), \n                                breaks = sbr_breaks)) / nrow(meta), 1), \"%)\"))\n\nmanual_colors &lt;- c(\n  \"&lt;= -1\"   = \"#D73027\",  # \n  \"-1 to 0\" = \"#F46D43\",  # \n  \"0 to 1\"  = \"#D9EF8B\",  # \n  \"1 to 2\"  = \"#A6D96A\",  # \n  \"2 to 3\"  = \"#1A9850\",  # \n  \"&gt; 3\"     = \"#006837\"   # \n)\nnames(manual_colors) &lt;- sbr_labels\n\np &lt;- ggplot(data = meta) +\n  geom_point(\n    aes(\n      x = x_slide_mm,\n      y = y_slide_mm,\n      color = cut(log2(SBR), breaks = sbr_breaks, labels = sbr_labels)\n    ),\n    size = 0.001, alpha = 1\n  ) +\n  scale_color_manual(values = manual_colors) +\n  guides(color = guide_legend(\n    override.aes = list(size = 7, alpha = 1) # Sets legend points to size 5 and opaque\n  )) +\n  labs(color = \"log2(SBR)\") +\n  coord_fixed() +\n  theme_bw()\n\nggsave(filename = file.path(qc_dir, \"qc_xy_sbr.png\"), p,\n       width=10, height=10, type = 'cairo')\n\n\n\n\n\n\n\n\n\n\nFigure¬†3.10: Spatially-smoothed Signal to Background for each cell.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Quality Processing</span>"
    ]
  },
  {
    "objectID": "quality-processing.html#combining-flags",
    "href": "quality-processing.html#combining-flags",
    "title": "3¬† Quality Processing",
    "section": "3.4 Combining Flags",
    "text": "3.4 Combining Flags\nTaken together, what cells were flagged and why? Figure¬†3.11 shows the configuration of the flags.\n\n\nR Code\nlibrary(UpSetR)\nfilter_list &lt;- list(\n  `Low SplitRatio` = meta %&gt;%\n    filter(SplitRatioToLocal &gt; 0 & SplitRatioToLocal &lt; results_list[['SplitRatioToLocalThreshold']]) %&gt;%\n    pull(cell_ID),\n  \n  `Low Counts` = meta %&gt;%\n    filter(nCount_RNA &lt; results_list[['counts_min_threshold']]) %&gt;%\n    pull(cell_ID),\n  \n  `High Counts` = meta %&gt;%\n    filter(nCount_RNA &gt; results_list[['counts_max_threshold']]) %&gt;%\n    pull(cell_ID),\n  \n  `Low Features` = meta %&gt;%\n    filter(nFeature_RNA &lt; results_list[['features_min_threshold']]) %&gt;%\n    pull(cell_ID),\n    \n  `High Features` = meta %&gt;%\n    filter(nFeature_RNA &gt; results_list[['features_max_threshold']]) %&gt;%\n    pull(cell_ID), \n  \n  `Low SBR` = meta %&gt;% \n    filter(log2(SBR) &lt; 0) %&gt;%\n    pull(cell_ID),\n  \n  `FOV QC` = meta %&gt;% \n    filter(fovqcflag == 1) %&gt;%\n    pull(cell_ID)\n)\n\nfilter_list &lt;- purrr::keep(filter_list, ~ length(.) &gt; 0)\n\npng(file.path(qc_dir, \"flagged_cells.png\"), \n    width=10, height=8, res=350, units = \"in\", type = \"cairo\")\n  upset(\n  fromList(filter_list),\n  nintersects = 10,\n  order.by = \"freq\",     \n  nsets = length(filter_list), \n  text.scale = 1.5)\ndev.off()\n\n\n\n\n\n\n\n\n\n\nFigure¬†3.11: Combinations of quality filters flagged in this study. Only the 10 most frequent sets are shown for clarity.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Quality Processing</span>"
    ]
  },
  {
    "objectID": "quality-processing.html#filtering",
    "href": "quality-processing.html#filtering",
    "title": "3¬† Quality Processing",
    "section": "3.5 Filtering",
    "text": "3.5 Filtering\nNow that we have flagged the cells, this section does the actual filtering and saves data to disk so that we can use it in the pre-processing step.\nIn regular analyses, I simply filter the cells based on the chosen cutoffs and continue with the pre-processing step. In this case, I am interested in showing the downstream effects of leaving poor quality cells in versus filtering them. To that end, I‚Äôll save two annData objects: unfiltered and filtered. In both datasets, I will add a qc flag column to keep track of what QC conditions were flagged in any given cell.\nTo be efficient I‚Äôll make use of bitwise shifts to create the QC flag column.\n\n\nR Code\nqc_masks &lt;- list(\n  LOW_COUNTS = bitwShiftL(1, 0),  # 1\n  HIGH_COUNTS = bitwShiftL(1, 1), # 2\n  LOW_FEAT = bitwShiftL(1, 2),    # 4\n  HIGH_FEAT = bitwShiftL(1, 3),   # 8\n  LOW_SPLIT = bitwShiftL(1, 4),   # 16\n  FOV_QC = bitwShiftL(1, 5),      # 32\n  LOW_SBR = bitwShiftL(1, 6),     # 64 \n  BLANK7 = bitwShiftL(1, 7)       # 128 (not used)\n)\n\nmeta &lt;- meta %&gt;%\n  mutate(\n    qc_flag = (\n      # Condition 1\n      (nCount_RNA &lt; results_list[['counts_min_threshold']]) * qc_masks$LOW_COUNTS +\n      \n      # Condition 2\n      (nCount_RNA &gt; results_list[['counts_max_threshold']]) * qc_masks$HIGH_COUNTS +\n      \n      # Condition 3\n      (nFeature_RNA &lt; results_list[['features_min_threshold']]) * qc_masks$LOW_FEAT +\n      \n      # Condition 4\n      (nFeature_RNA &gt; results_list[['features_max_threshold']]) * qc_masks$HIGH_FEAT +\n      \n      # Condition 5\n      (SplitRatioToLocal &gt; 0 & SplitRatioToLocal &lt; results_list[['SplitRatioToLocalThreshold']]) * qc_masks$LOW_SPLIT + \n      \n      # Condition 6\n      (fovqcflag == 1) * qc_masks$FOV_QC +\n      \n      # Condition 7\n      (log2(SBR) &lt; 0) * qc_masks$LOW_SBR\n      \n    )\n  )\n\npy$adata$obs$qcflag &lt;- meta$qc_flag\nresults_list['n_cells_before_qc'] = py$adata$n_obs\n\n\nRemove some of the intermediate matrices and save the annData to disk.\n\n\nPython Code\nadata.obs['qcflag'] = adata.obs['qcflag'].astype('uint8')\ndel adata.obsp['liana_connectivities']\ndel adata.obsm['counts_neg_spatially_smooth']\ndel adata.obsm['counts_spatially_smooth']\n\nfilename = os.path.join(r.analysis_dir, \"anndata-1-qc-flagged.h5ad\")\n\nadata.write_h5ad(\n  filename,\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)\n\n\nIn addition to saving a copy of flagged data, let‚Äôs filter out any cells with a QC flag that is not ‚Äú32‚Äù and save that ‚Äúfiltered‚Äù dataset to disk.\n\n\nPython Code\nadata.obs['qcflag'] = adata.obs['qcflag'].astype('uint8')\n\nadata = adata[adata.obs['qcflag'].isin([0, 32]), :].copy()\n\nfilename = os.path.join(r.analysis_dir, \"anndata-1-qc-filtered.h5ad\")\nadata.write_h5ad(\n  filename,\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)\n\n\nSave project-level results.\n\n\nR Code\nresults_list['n_cells_after_qc'] = py$adata$n_obs\nsaveRDS(results_list, results_list_file)\n\n\nAfter filtering, we have 466820 (94.5 %) that are ready to analyze. Note that we did not do any gene-level filtering. My primary reason for leaving all genes in the data at this point is primarily because ‚Äì while we do not expect every gene to be highly expressed in every cell ‚Äì there are rare cells that may express genes that would considered ‚Äúbelow background‚Äù in the rest of the data. My general approach is to keep all targets in the data and identify which of these are highly variable and use those genes when appropriate (e.g., PCA, UMAP, Leiden).",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Quality Processing</span>"
    ]
  },
  {
    "objectID": "processing.html",
    "href": "processing.html",
    "title": "4¬† Normalization, Reduction, and Clustering",
    "section": "",
    "text": "4.1 Two pre-processing workflows\nOur quality control steps in Chapter 3 identified the analyzable cells, but these their raw counts need further processing to reveal biological patterns. This chapter covers the essential pre-processing steps to make the data interpretable.\nFirst, normalization adjusts counts to account for technical factors like cell area (i.e., larger cells typically have more counts), enabling fair comparisons between cells. Second, dimensionality reduction (using PCA and UMAP) helps reduce the total number of dimensions in the data (almost 19,000) to a manageable representation that captures key biological variation and allows visualization. Finally, clustering leverages this reduced space to group cells with similar expression profiles, which can be a foundation for downstream analyses like cell typing.\nBy the end of this chapter, we will have transformed the filtered count matrix into a clustered, low-dimensional dataset and classified cells into groups which, taken together, form our foundation for biological interpretation and spatial analysis. I often get asked ‚ÄúWhat is the best parameter combination for CosMx data?‚Äù and I hope by the end of this chapter you‚Äôre able to understand how parameter adjustments impact many of these processing steps.\nLet‚Äôs begin by loading the data.\nThere are two different pre-processing workflows that I use. The first one is borrowed from spatially-unaware scRNA-seq. The main advantage of this approach is that it is fast, the normalization matrix can remain sparse, the values are easy to understand (e.g., counts of gene X per 10,000 or some transformation of such), and often times for WTX data provides the basis for good clustering of cells in downstream UMAP. Moreover, Scanpy and Seurat each have built-in methods for these steps which make it relatively low friction. However, there are cases were this standard (‚Äúlegacy‚Äù) workflow provides unexpected results. One reason is that total counts-based normalization might have unstable variance1 such that high-expressing housekeeping genes might have high variance and disproportionately effect downstream dimensional reduction and clustering.\nThe second, newer workflow that I have been using is based on normalization using Pearson Residuals (PR). The approach itself is not new and scanpy has a built-in method for it (i.e., scanpy.experimental.pp.normalize_pearson_residuals). Until recently the main disadvantage for using PR is that it doesn‚Äôt scale well to large number of cells that are typical in CosMx SMI1 and it creates a large, dense normalization matrix that can make analysis and read/writing slower. Fortunately, in many cases I do not need to compute and store such a dense matrix. For example, Dan McGuire recently created the R package scPearsonPCA that can estimate the Principle Components (PCs) of the PR normalized data without needing to convert and use very dense matrices (which we will show below). While this workflow involves converting data between python and R, I generally find the clusters that are derived from such data are comparable to the standard workflow or superior and so I recommend this workflow overall.\nIn this chapter, I‚Äôll run both the standard and recommended workflows on the colon cancer dataset to provide code for both approaches. I will also do a deep-dive on the choice of UMAP parameters. This particular dataset is a case where the results are more-or-less comparable and I‚Äôll pick the PR data to use throughout the rest of the colon analysis.\nLet‚Äôs begin. Both options begin the same way: computing the highly variable genes (HVGs). I have found that the pearson_residulas method to detect HVGs (not to be confused with PR normalization) provides stable results for a variety of CosMx SMI WTX experiments.\nPython Code\nadata.layers[\"counts\"] = adata.X.copy()\n\n1sc.experimental.pp.highly_variable_genes(\n    adata,\n    flavor='pearson_residuals',\n2    n_top_genes=4000,\n    layer='counts'\n)\n\n\n\n1\n\nthe pearson_residuals ‚Äòflavor‚Äô implement in this function is not the same as the pearson residuals normalization method (see below).\n\n2\n\ngenerally 3000-5000 is a good starting point here.\nThe tabs below show both of these workflows. In each workflow, I set the umap parameters to be identical (40 PCs, 15 nearest neighbors, spread = 2 and minimum distance = 0.02). While these are fixed here, see the box Choosing UMAP Parameters below to see how these parameters effect the UMAP visual and the Leiden cluster assignments.\nSave the annData object.\nPython Code\nadata.write_h5ad(\n  os.path.join(r.analysis_dir, \"anndata-2-leiden.h5ad\"),\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Normalization, Reduction, and Clustering</span>"
    ]
  },
  {
    "objectID": "processing.html#two-pre-processing-workflows",
    "href": "processing.html#two-pre-processing-workflows",
    "title": "4¬† Normalization, Reduction, and Clustering",
    "section": "",
    "text": "Alternative Approach\n\n\nThe pre-processing workflow presented here can be considered a good overall starting point towards understanding the structure of the data. As such I have omitted more complex workflows and tasks such as integrating morphology-based and/or protein-based PCs into the analysis. For a more involved workflow, see our upcoming WTX paper.\n\n\n\n\nTotal Counts WorkflowPearson Residuals Workflow\n\n\n\nWorkflow: Total counts-based normalization &gt; log transformation &gt; PCA\n\nThe procedure below adapts a standard scanpy pipeline. We‚Äôll first normalize each cell the median total counts and then log tranform the data. With this approach I find that scaling the log1p data tends to generate more distinct and biologically relevant clusters so I add that step. Thus, we‚Äôll focus our analysis on the most variable genes found in the dataset. After subsetting down to only these 4000 HVGs, we‚Äôll scale each gene, run PCA, and put these HVG-derivied PCs into the full annData object. On this dataset (466820 cells), this whole process took about a minute.\n\n\nPython Code\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata) # -&gt; adata.X\nadata.layers['TC'] = adata.X.copy()\n\n# Subset to HVGs and get PCs\nadata_hvg = adata[:, adata.var.highly_variable].copy()\nsc.pp.scale(adata_hvg) # -&gt; adata.X\nsc.tl.pca(adata_hvg, svd_solver='auto') \nadata.obsm['X_pca_TC'] = adata_hvg.obsm['X_pca']\n\n\nRun UMAP and Leiden with the top 40 PCs.\n\n\nPython Code\nsc.pp.neighbors(adata, n_neighbors=15, n_pcs=40, metric = 'cosine',\n  use_rep='X_pca_TC', key_added='neighbors_TC')\n\nUMAP = sc.tl.umap(adata, min_dist=0.02, spread=2, neighbors_key='neighbors_TC', copy=True)\n\nadata.obsm['umap_TC'] = UMAP.obsm['X_umap']\nadata.uns['umap_TC_params'] = UMAP.uns['umap']\n\nsc.tl.leiden(adata, resolution=0.5, \n  key_added='leiden_tc', flavor='igraph', \n  n_iterations=2, neighbors_key='neighbors_TC')\n\n\n\n\n\nWorkflow: Py to R &gt; scPearsonPCA\n\nThe scPearsonPCA package estimates the PCs of the PR data without computing and storing a dense normalized matrix. Since it is written in R, we‚Äôll add it to this workflow via reticulate after converting a few objects.\n\n\nPython Code\ntotal_counts_per_cell = adata.layers['counts'].sum(axis=1)\ntotal_counts_per_cell = np.asarray(total_counts_per_cell).flatten()\n\ntotal_counts_per_target = adata.layers['counts'].sum(axis=0)\ntotal_counts_per_target = np.asarray(total_counts_per_target).flatten()\n\ntarget_frequencies = total_counts_per_target / total_counts_per_target.sum()\n\nadata_hvg = adata[:, adata.var.highly_variable].copy()\nhvgs_counts = adata_hvg.layers['counts'].copy().astype(np.int64)\n\n\nConvert relevant data to R.\n\n\nR Code\nlibrary(Matrix)\nhvgs_counts &lt;- py$hvgs_counts\nrownames(hvgs_counts) &lt;- py$adata_hvg$obs_names$to_list()\ncolnames(hvgs_counts) &lt;- py$adata_hvg$var_names$to_list()\n\n# the approach we use below expects a sparse matrix with genes (rows) by cells (columns)\nt_hvgs_counts &lt;- Matrix::t(hvgs_counts)\nt_hvgs_counts &lt;- as(t_hvgs_counts, \"CsparseMatrix\")\n\n\nInstall the scPearsonPCA package (and remotes), if needed.\n\n\nR Code\nremotes::install_github(\"Nanostring-Biostats/CosMx-Analysis-Scratch-Space\",\n                         subdir = \"_code/scPearsonPCA\", ref = \"Main\")\n\n\nRun Seurat-style PCA using scPearsonPCA.\n\n\nR Code\nlibrary(scPearsonPCA)\n\ntotal_counts_per_cell &lt;- py$total_counts_per_cell\n\ntarget_frequencies &lt;- py$target_frequencies\nnames(target_frequencies) &lt;- py$adata$var_names$to_list()\n\npcaobj &lt;- sparse_quasipoisson_pca_seurat(\n              x = t_hvgs_counts,\n              totalcounts = total_counts_per_cell,\n              grate = target_frequencies[rownames(t_hvgs_counts)],\n              scale.max = 10,\n              do.scale = TRUE,\n              do.center = TRUE,\n              ncores = 5\n          )\npca &lt;- pcaobj$reduction.data@cell.embeddings\n\n\nAdd these PCs to the annData object in Python. Run UMAP and Leiden with the top 40 PCs.\n\n\nPython Code\nadata.obsm[\"X_pca_pr\"] = r.pca\n\nsc.pp.neighbors(adata, n_neighbors=15, n_pcs=40, metric = 'cosine',\n  use_rep='X_pca_pr', key_added='neighbors_pr')\n\nUMAP = sc.tl.umap(adata, min_dist=0.02, spread=2, neighbors_key='neighbors_pr', copy=True)\nadata.obsm['umap_pr'] = UMAP.obsm['X_umap']\nadata.uns['umap_pr_params'] = UMAP.uns['umap']\n\nsc.tl.leiden(adata, resolution=0.5, \n  key_added='leiden_pr', flavor='igraph', \n  n_iterations=2, neighbors_key='neighbors_pr')",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Normalization, Reduction, and Clustering</span>"
    ]
  },
  {
    "objectID": "processing.html#visualizations",
    "href": "processing.html#visualizations",
    "title": "4¬† Normalization, Reduction, and Clustering",
    "section": "4.2 Visualizations",
    "text": "4.2 Visualizations\nNow that we have the UMAP embeddings and the Leiden cluster assignments in the annData object, we can plot the results of the two methods and compare. The easiest way to plot the Leiden clusters in UMAP space is with scnapy‚Äôs built-in method, sc.pl.umap; however, since we have non-typical obsm keys, we‚Äôll use the more generic sc.pl.embedding method.\n\n\nPython Code\nimport matplotlib.pyplot as plt\nsc.settings.figdir = r.pp_dir\nsave_dir = r.pp_dir\n\nadata.obs['log10_nCount_RNA'] = np.log10(adata.obs['nCount_RNA'] + 1)\nadata.obs['qcflag'] = adata.obs['qcflag'].astype('category')\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(15, 10))\n\nsc.pl.embedding(adata,\n                basis='umap_TC',\n                color='leiden_tc',\n                title='Total Counts (leiden_tc)',\n                palette=sc.pl.palettes.default_20,\n                ax=ax1,\n                show=False)\n\nsc.pl.embedding(adata,\n                basis='umap_pr',\n                color='leiden_pr',\n                title='Pearson Residuals (leiden_pr)',\n                palette=sc.pl.palettes.default_20,\n                ax=ax2,\n                show=False)\n                \nsc.pl.embedding(adata,\n                basis='umap_TC',\n                color='log10_nCount_RNA',\n                title='Total Counts (log10_nCount_RNA)',\n                ax=ax3,\n                show=False)\n\nsc.pl.embedding(adata,\n                basis='umap_pr',\n                color='log10_nCount_RNA',\n                title='Pearson Residuals (log10_nCount_RNA)',\n                ax=ax4,\n                show=False)\n\nsc.pl.embedding(adata,\n                basis='umap_TC',\n                color='qcflag',\n                title='Total Counts (FOV QC Flag)',\n                palette=sc.pl.palettes.default_20,\n                ax=ax5,\n                show=False)\n\nsc.pl.embedding(adata,\n                basis='umap_pr',\n                color='qcflag',\n                title='Pearson Residuals (FOV QC Flag)',\n                palette=sc.pl.palettes.default_20,\n                ax=ax6,\n                show=False)\n\nplt.tight_layout()\nfilename = \"umap_umap_compare.png\"\nsave_path = os.path.join(save_dir, filename)\nplt.savefig(save_path)          \n\n\n\n\n\n\n\n\n\n\nFigure¬†4.1: UMAP with Leiden clusters from total counts normalization (left) and scPearsonPCA PCs (right). Note that a given cluster label in one plot is not the same as that label in the other plot. Top: Leiden clusters. Middle: cells colored by their total counts. Bottom: cells colored by their QC flag (0 = no flag; 32 = FOV flag; no other flaggeed cells were processed).\n\n\n\n\n\nBoth normalization methods demonstrate effective cluster separation (Figure¬†4.1). When evaluating these visualizations, it is important to watch for artifacts, particularly sub-clustering driven primarily by total transcript counts, which can signal suboptimal normalization. Additionally, because we retained cells flagged by FOV QC (flag 32), we must verify that these cells do not aggregate into spurious ‚Äúsatellite‚Äù clusters which could indicate technical artifacts rather than biological signal. In this dataset, while FOV QC-flagged cells are present in the upper right cluster (Leiden 5 in the total counts workflow and Leiden 11 in the Pearson Residuals workflow), they do not form a distinct artifactual group. Instead, they appear integrated with the dominant cell population, suggesting their distribution is driven by the biology of that region ‚Äì a hypothesis we will elucidate further in ?sec-celltyping.\nWe can compare which combination of Leiden clusters a given cell was assigned to:\n\nimport pandas as pd\nimport seaborn as sns\n\ncrosstab = pd.crosstab(\n    adata.obs['leiden_tc'],\n    adata.obs['leiden_pr']\n)\n\ncrosstab_norm = crosstab.div(crosstab.sum(axis=1), axis=0)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(\n    crosstab_norm,\n    annot=True,\n    fmt=\".2f\", cmap=\"viridis\",\n    linewidths=.5\n)\n\nplt.title(\"Comparison of Leiden clusters derived from TC or PR workflows\", fontsize=16)\nplt.ylabel(\"Total Counts (leiden_tc)\", fontsize=12)\nplt.xlabel(\"Pearson Residuals (leiden_pr)\", fontsize=12)\nfilename = \"leiden_compare_crosstab.png\"\nsave_path = os.path.join(save_dir, filename)\nplt.savefig(save_path)     \n\n\n\n\n\n\n\n\n\nFigure¬†4.2: Proportion of cells classified with the pure scanpy-based approach compared to the scPearsonPCA-based appraoch.\n\n\n\n\n\nFigure¬†4.2 shows a relationship between the clusters derived from our two normalization approaches. Most (15 of 16) Leiden clusters with the total counts approach have more than 85% of cells that are found in a single Leiden cluster for the Pearson Residuals method (e.g., 95% of tc_3 cells mapped to pr_1). One cluster in the total counts approach (tc_1) ‚Äúsplit‚Äù amongst PR clusters (primarily clusters pr_5, pr_6, and pr_8).\nSo which is better? With this particular dataset the two approaches are comparable. For the majority of my CosMx SMI WTX analyses I have found the Pearson Residual-based normalization to provide more meaningful biological clusters consistently across datasets so that might be a good overall recommendation ‚Äì especially if you are working within the R ecosystem. If you are looking for a quick analysis, then the total counts-based approach may work in many cases.\n\n\n\n\n\n\nChoosing UMAP Parameters\n\n\n\n\n\n\n4.3 Choosing UMAP Parameters\nUMAP helps visualize how groups of cells relate to each other in high-dimensional space. While there isn‚Äôt one ‚Äúcorrect‚Äù UMAP layout, some embeddings are more effective than others at revealing underlying biological structure. We have seen in this chapter how having choice in normalization alone (via PCA) can alter the shape of a UMAP plot even when all other parameters are identical (Figure¬†4.1).\nThis section explores how commonly adjusted parameters and inputs other than the choice of normalization influence the resulting UMAP visualization, aiming to build intuition for how to tune these parameters effectively in your dataset.\nLet‚Äôs systematically vary five key factors:\n\nThe quality filtering applied to the input cells. Using only high-quality cells often leads to clearer, tighter clusters representing core biological populations. If filtering was too stringent then entire cell populations might be unrepresented.\nThe number of Principal Components (PCs) used. Using a lower number will concetrate on the strongest axes of variation at the cost of reducing any distinction between cell subtypes if that distinction is found in higher PCs. Choosing a higher number of PCs can potentially resolve finer subtypes but also risks incorporating noise, which might slightly blur cluster boundaries or create small, potentially spurious groupings.\nThe number of nearest neighbors (n_neighbors). Lower n_neighbors tends to emphasize local cluster separation while higher n_neigbhors tends to form broader clusters.\nThe distance metric (metric). Defines the rule for calculating ‚Äúcloseness‚Äù between cells. Euclidean measures straight-line distance while cosine measures the angle between gene expression profiles. Since changing this alters which cells are considered ‚Äúneighbors,‚Äù the parameter can have large impacts on the global shape. Euclidean is the default many packages but cosine often provides more biologically meaningful clusters for CosMx SMI data.\nThe minimum distance parameter (min_dist). Controls how tightly packed points are within a cluster. Higher values tend to make more diffuse clusters.\nThe spread parameter (spread). Controls the separation between clusters. Lower spread tends to bring clusters closer together.\n\nThis list isn‚Äôt exhaustive, but varying these while keeping others constant will illustrate their core effects. To make this exploration computationally feasible, we will use a representative subsample of 50,000 cells from our quality-flagged dataset. And to make visualization smooth, we‚Äôll only plot at most 500 cells.\nClick the radio buttons below to see what effect these parameter have on the UMAP visualization. Some of these changes are gradual while some dramatically alter the shape and configuration of the UMAP embeddings. You‚Äôll note that filtering out the poor quality cells doesn‚Äôt merely remove the cells from the UMAP; instead, the inclusion of poorer-quality data can effect the entire UMAP topology. I have also included the Leiden clusters for these cells. The number of PCs and the number of neighbors effect Leiden cluster cell assignment while spread and min_dist do not.\nEncouragingly, in this dataset there doesn‚Äôt appear to be any UMAP clusters that appear to be made up of cells that were flagged in our FOV QC analysis (Section 3.1). If this was the case, it would suggest that we would want to remove the cells in the effected FOVs.\n\n\n\n\n\n\n\n\n\n\n\nviewof qc_level = Inputs.radio([\"no QC filter\", \"include FOV QC cells\", \"filter all flags\"], {label: \"QC Level\", value: \"include FOV QC cells\"})\nviewof n_pcs = Inputs.radio([10, 20, 30, 40, 50], {label: \"PCs\", value: 30})\nviewof n_neighbors = Inputs.radio([15, 30, 50], {label: \"Neighbors\", value: 30})\nviewof metric = Inputs.radio([\"euclidean\", \"cosine\"], {label: \"Metric\", value: \"cosine\"})\nviewof mdist = Inputs.radio([0.01, 0.05, 0.2, 0.5], {label: \"Min. distance\", value: 0.2})\nviewof spread = Inputs.radio([0.5, 1.0, 2.0], {label: \"Spread\", value: 2.0})\nviewof colorby = Inputs.radio([\"QC\", \"Leiden\"], {label: \"Color by\", value: \"QC\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqcMasks = ({\n  LOW_COUNTS: 1 &lt;&lt; 0, \n  HIGH_COUNTS: 1 &lt;&lt; 1, \n  LOW_FEAT: 1 &lt;&lt; 2,\n  HIGH_FEAT: 1 &lt;&lt; 3, \n  LOW_SPLIT: 1 &lt;&lt; 4, \n  FOV_QC: 1 &lt;&lt; 5, \n  LOW_SBR: 1 &lt;&lt; 6\n})\n\nflagNames = Object.keys(qcMasks).sort((a, b) =&gt; qcMasks[a] - qcMasks[b]);\nqcFlagMap = new Map(qc_flags_data.map(d =&gt; [d.cell_id, d.qcflag]));\n\nflagColors = {\n  const uniqueFlagsInData = Array.from(new Set(qc_flags_data.map(d =&gt; d.qcflag))).sort((a, b) =&gt; a - b);\n  const uniqueFlagsWithZero = Array.from(new Set([0, ...uniqueFlagsInData])).sort((a,b)=&gt; a-b);\n  const colors = d3.schemeTableau10;\n  const map = {};\n  let colorIndex = 0;\n  uniqueFlagsWithZero.forEach(flagValue =&gt; {\n    if (flagValue === 0) { map[flagValue] = \"black\"; }\n    else { map[flagValue] = colors[colorIndex++ % colors.length]; }\n  });\n  return map;\n}\n\nqcColorScale = (flagValue) =&gt; flagColors[flagValue ?? 0];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqcFlagLegend = {\n  try {\n    const uniqueFlagsWithZero = Object.keys(flagColors).map(Number).sort((a,b)=&gt; a-b);\n    const tableRows = uniqueFlagsWithZero.map(flagValue =&gt; {\n      const flagColor = flagColors[flagValue]; // Use static map\n      const circles = flagNames.map(name =&gt; {\n         const mask = qcMasks[name];\n         const isSet = (flagValue & mask) &gt; 0;\n         const circleFill = isSet ? flagColor : \"#e0e0e0\";\n         const circleSvg = `&lt;svg width=\"15\" height=\"15\"&gt;&lt;circle cx=\"7.5\" cy=\"7.5\" r=\"6\" fill=\"${circleFill}\" stroke=\"${isSet ? 'black' : '#ccc'}\" stroke-width=\"1\"&gt;&lt;/circle&gt;&lt;/svg&gt;`;\n         return `&lt;td style=\"text-align: center;\"&gt;${circleSvg}&lt;/td&gt;`;\n      }).join('');\n      const rowHeader = `&lt;th scope=\"row\" style=\"text-align: right; padding-right: 10px; white-space: nowrap;\"&gt;\n                           &lt;span style=\"display: inline-block; width: 12px; height: 12px; background-color: ${flagColor}; border: 1px solid #555; margin-right: 5px; vertical-align: middle;\"&gt;&lt;/span&gt;\n                           ${flagValue === 0 ? 'Passed' : flagValue}\n                         &lt;/th&gt;`;\n      return `&lt;tr&gt;${rowHeader}${circles}&lt;/tr&gt;`;\n    }).join('');\n    const headerCells = flagNames.map(name =&gt;\n      `&lt;th style=\"height: 100px; text-align: center; vertical-align: bottom; padding-bottom: 5px; font-size: 0.8em; white-space: nowrap;\"&gt;\n         &lt;span style=\"writing-mode: vertical-lr; transform: rotate(180deg);\"&gt;${name.replace(/_/g, ' ')}&lt;/span&gt;\n       &lt;/th&gt;`\n    ).join('');\n    const tableHeader = `&lt;thead&gt;&lt;tr&gt;&lt;th style=\"vertical-align: bottom;\"&gt;Flag Value&lt;/th&gt;${headerCells}&lt;/tr&gt;&lt;/thead&gt;`;\n    return html`&lt;table style=\"border-collapse: collapse; margin-top: 10px; font-size: 0.9em; table-layout: fixed;\"&gt;\n                   ${tableHeader}&lt;tbody&gt;${tableRows}&lt;/tbody&gt;\n                 &lt;/table&gt;`;\n   } catch (error) {\n     console.error(\"Error generating QC Legend:\", error);\n     return html`&lt;div&gt;Error generating QC Legend&lt;/div&gt;`;\n   }\n}\n\n\n\n\n\n\n\n\n\n\nleidenScaleAndLegend = {\n  let scale, legend;\n  try { // Add try...catch\n    // Check if query_data is ready and has 'leiden'\n    if (!query_data || query_data.length === 0 || !query_data[0].hasOwnProperty('leiden')) {\n        console.warn(\"Leiden data (query_data) not ready for legend/scale.\");\n        scale = d3.scaleOrdinal().domain([\"0\"]).range([\"grey\"]); // Placeholder scale\n        legend = html`&lt;div&gt;&lt;ul style=\"list-style: none; padding-left: 0; margin-top: 10px; font-size: 0.9em;\"&gt;\n                        &lt;li style=\"margin-bottom: 2px;\"&gt;&lt;span style=\"display: inline-block; width: 12px; height: 12px; background-color: grey; border: 1px solid #555; margin-right: 5px; vertical-align: middle;\"&gt;&lt;/span&gt; Cluster 0&lt;/li&gt;\n                      &lt;/ul&gt;(Loading...)&lt;/div&gt;`; // placeholder\n    } else {\n        const uniqueClusters = Array.from(new Set(query_data.map(d =&gt; d.leiden))).sort((a, b) =&gt; a - b);\n        scale = d3.scaleOrdinal(d3.schemeTableau10).domain(uniqueClusters);\n\n        const legendItems = uniqueClusters.map(cluster =&gt; {\n           const color = scale(cluster);\n           const clusterLabel = String(cluster);\n           return `&lt;li style=\"margin-bottom: 2px;\"&gt;&lt;span style=\"display: inline-block; width: 12px; height: 12px; background-color: ${color}; border: 1px solid #555; margin-right: 5px; vertical-align: middle;\"&gt;&lt;/span&gt; Cluster ${clusterLabel}&lt;/li&gt;`;\n        }).join('');\n        legend = html`&lt;ul style=\"list-style: none; padding-left: 0; margin-top: 10px; font-size: 0.9em;\"&gt;${legendItems}&lt;/ul&gt;`;\n    }\n  } catch(error) {\n     console.error(\"Error generating Leiden Legend:\", error);\n     scale = () =&gt; 'grey';\n     legend = html`&lt;div&gt;Error generating Leiden Legend&lt;/div&gt;`;\n  }\n  return { scale, legend };\n}\n\nleidenColorScale = leidenScaleAndLegend.scale\nleidenLegendHtml = leidenScaleAndLegend.legend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd3 = require(\"d3@7\")\n\nwidth = 500\nheight = 500\nmarginTop = 20\nmarginRight = 20\nmarginBottom = 30\nmarginLeft = 40\n\nxScale = d3.scaleLinear().domain([0, 1]).range([marginLeft, width - marginRight])\nyScale = d3.scaleLinear().domain([0, 1]).range([height - marginBottom, marginTop])\n\nsvg = d3.create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto;\");\n\nxAxis = d3.axisBottom(xScale)\n    .ticks(width / 80)\n    .tickSizeOuter(0)\n    .tickSizeInner(-(height - marginTop - marginBottom));\n\nyAxis = d3.axisLeft(yScale)\n    .ticks(height / 40)\n    .tickSizeOuter(0)\n    .tickSizeInner(-(width - marginLeft - marginRight));\n\ngx = svg.append(\"g\")\n    .attr(\"class\", \"x-axis\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .call(xAxis);\n\ngy = svg.append(\"g\")\n    .attr(\"class\", \"y-axis\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .call(yAxis);\n\nsvg.selectAll(\".tick line\")\n   .attr(\"stroke-opacity\", 0.1);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsvg.append(\"text\")\n    .attr(\"x\", width - marginRight)\n    .attr(\"y\", height - marginBottom - 4)\n    .attr(\"fill\", \"currentColor\")\n    .attr(\"text-anchor\", \"end\")\n    .text(\"UMAP 1 ‚Üí\");\n\n\n\n\n\n\n\nsvg.append(\"text\")\n    .attr(\"x\", marginLeft + 4)\n    .attr(\"y\", marginTop)\n    .attr(\"fill\", \"currentColor\")\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"dominant-baseline\", \"hanging\")\n    .text(\"‚Üë UMAP 2\");\n\n\n\n\n\n\n\n-\nsvg.append(\"clipPath\")\n    .attr(\"id\", \"clip\")\n  .append(\"rect\")\n    .attr(\"x\", marginLeft)\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n\n\n\n\n\n\npointGroup = svg.append(\"g\")\n    .attr(\"fill\", \"black\")\n    .attr(\"clip-path\", \"url(#clip)\");\n\n\n\n\n\n\n\n\n\n{ // Reactive block\n  const updateVisualization = () =&gt; {\n    const duration = 750;\n    \n    const currentScale = colorby === \"QC\" ? qcColorScale : leidenColorScale;\n\n    if (!currentScale) { \n        console.error(\"Scale missing\"); \n        return; \n    }\n    \n    if (!query_data || query_data.length === 0) {\n       console.warn(\"No data available for plotting.\");\n       pointGroup.selectAll(\"circle\").transition().duration(duration).attr(\"opacity\", 0).remove();\n       return; \n    }\n\n    const xExtent = d3.extent(query_data, d =&gt; d.umap_1);\n    const yExtent = d3.extent(query_data, d =&gt; d.umap_2);\n\n    const xPad = (xExtent[1] - xExtent[0]) * 0.05;\n    const yPad = (yExtent[1] - yExtent[0]) * 0.05;\n\n    xScale.domain([xExtent[0] - xPad || -1, xExtent[1] + xPad || 1]);\n    yScale.domain([yExtent[0] - yPad || -1, yExtent[1] + yPad || 1]);\n\n    svg.select(\".x-axis\")\n      .transition().duration(duration)\n      .call(xAxis)\n      .on(\"start\", () =&gt; {\n         svg.selectAll(\".x-axis .tick line\").attr(\"stroke-opacity\", 0.1);\n      });\n\n    svg.select(\".y-axis\")\n      .transition().duration(duration)\n      .call(yAxis)\n      .on(\"start\", () =&gt; {\n         svg.selectAll(\".y-axis .tick line\").attr(\"stroke-opacity\", 0.1);\n      });\n\n    pointGroup.selectAll(\"circle\")\n      .data(query_data, d =&gt; d.cell_id)\n      .join(\n        enter =&gt; enter.append(\"circle\")\n            .attr(\"cx\", d =&gt; xScale(d.umap_1)) \n            .attr(\"cy\", d =&gt; yScale(d.umap_2))\n            .attr(\"r\", 2.5)\n            .attr(\"fill\", d =&gt; {\n                try {\n                    const valueToColor = colorby === \"QC\" ? qcFlagMap.get(d.cell_id) : d.leiden;\n                    return currentScale(valueToColor) || 'grey';\n                } catch(e) { return 'grey'; }\n            }) \n            .attr(\"opacity\", 0)\n            .call(enter =&gt; enter.transition().duration(duration).attr(\"opacity\", 0.8)),\n        \n        update =&gt; update\n            .call(update =&gt; update.transition().duration(duration)\n                .attr(\"cx\", d =&gt; xScale(d.umap_1))\n                .attr(\"cy\", d =&gt; yScale(d.umap_2))\n                .attr(\"fill\", d =&gt; { \n                    try {\n                        const valueToColor = colorby === \"QC\" ? qcFlagMap.get(d.cell_id) : d.leiden;\n                        return currentScale(valueToColor) || 'grey';\n                    } catch(e) { return 'grey'; }\n                })\n                .attr(\"opacity\", 0.8)\n             ),\n        \n        exit =&gt; exit\n            .call(exit =&gt; exit.transition().duration(duration).attr(\"opacity\", 0).remove())\n      );\n  };\n  \n  try { \n    updateVisualization();\n  } catch(error) {\n    console.error(\"Error during D3 updateVisualization:\", error);\n  }\n\n  return svg.node(); \n}\n\n\n\n\n\n\nIn the dot plot on the bottom left provides a QC flag legend. For example, QC flag ‚Äò5‚Äô represents cells that were flagged for having low counts and low features whereas QC flag ‚Äò96‚Äô represents cells that wee flagged for FOV QC as wells as low SBR.\n\n\nIf you want to further explore this subset, you can examine the query_data and qc_flags_data dataframes below.\n\n\n\n\n\n\n\n\n\n\n\n\nFor the remainder of this chapter, I will focus on the PR-based method.\nI find it‚Äôs helpful to:\n\nHave more control of the plotting aesthetics and label multiple sub-clusters of a given Leiden cluster for clarity and\nisolate the Leiden clusters and visualize them in both UMAP space and physical (XY) space to see if there are regions in the tissue that might provide clues about the cell types.\n\nInstead of the default plotDots colors, let‚Äôs define our own.\n\n\nR Code\n# define colors semi-manually instead of using the default colors\ncolumn &lt;- 'leiden_pr'\ncolumn_levels &lt;- levels(py$adata$obs[[column]])\nn_levels &lt;- length(column_levels)\n\nif(n_levels&lt;27){\n  colors_use &lt;- pals::alphabet(n_levels)\n} else if(n &lt; 53){\n  colors_use &lt;- c(pals::alphabet(26), pals::alphabet2(n_levels-26))\n} else {\n  stop(\"consider fewer groups\")\n}\n\nnames(colors_use) &lt;- column_levels\n\n# saving colors for later\nresults_list[['leiden_global_names']] &lt;- names(colors_use)\nresults_list[['leiden_global_colors']] &lt;- as.character(colors_use)\nsaveRDS(results_list, results_list_file)\n\n\nPlot the cells in XY space and UMAP space and color based on leiden_pr.\n\n\nR Code\n1group_prefix &lt;- \"leiden\"\n\npp_assets_dir &lt;- file.path(analysis_asset_dir, \"preprocessing\")\n\n# XY (global only)\nplotDots(py$adata, color_by='leiden_pr',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = pp_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Leiden (PR)\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n# XY (facets only)\nplotDots(py$adata, color_by='leiden_pr',\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = pp_assets_dir,\n                  fileType = \"png\",\n                  dpi = 100,\n                  width = 5,\n                  height = 5,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Leiden (PR)\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n# UMAP (global only)\nplotDots(py$adata, \n              obsm_key = \"umap_pr\",\n              color_by='leiden_pr',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001, alpha=0.1\n                  ),\n                  geom_label_params = list(\n                    size = 4\n                  ),\n                  labels_on_plot = data.frame(),\n                  directory = pp_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8,\n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"UMAP 1\"),\n                ylab(\"UMAP 2\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                # guides(color = guide_legend(\n                #   title=\"Cell Type\",\n                #   override.aes = list(size = 3) ) ), \n                theme(legend.position = \"none\")\n              )\n            )\n\n# UMAP (facets only)\nplotDots(py$adata, \n              obsm_key = \"umap_pr\",\n              color_by='leiden_pr',\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001, alpha=0.1\n                  ),\n                  geom_label_params = list(\n                    size = 2\n                  ),\n                  labels_on_plot = data.frame(),\n                  directory = pp_assets_dir,\n                  fileType = \"png\",\n                  dpi = 100,\n                  width = 5,\n                  height = 5,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"UMAP 1\"),\n                ylab(\"UMAP 2\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n            )\n\n\n\n1\n\nin the plotting below, we will use this name to parse out files.\n\n\n\n\nHere are the overall (global) plots.\n\nLeiden - UMAPLeiden - XY\n\n\n\n\n\n\n\n\n\n\nFigure¬†4.3: UMAP with Leiden (PR-based) cells.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†4.4: XY with Leiden (PR-based) cells.\n\n\n\n\n\n\n\n\nHere are the individual plots2 we created organized by Leiden cluster. From these pairs of plots one can quickly see how some Leiden clusters are spatially restricted. For example, Leiden 0 consists of cells in the top part of the tissue (i.e., the non-tumoral epithelium). Similarly, cluster 12 occupies the left-most region of the tissue.\n\n0123456789101112131415",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Normalization, Reduction, and Clustering</span>"
    ]
  },
  {
    "objectID": "processing.html#choosing-umap-parameters",
    "href": "processing.html#choosing-umap-parameters",
    "title": "4¬† Normalization, Reduction, and Clustering",
    "section": "4.3 Choosing UMAP Parameters",
    "text": "4.3 Choosing UMAP Parameters\nUMAP helps visualize how groups of cells relate to each other in high-dimensional space. While there isn‚Äôt one ‚Äúcorrect‚Äù UMAP layout, some embeddings are more effective than others at revealing underlying biological structure. We have seen in this chapter how having choice in normalization alone (via PCA) can alter the shape of a UMAP plot even when all other parameters are identical (Figure¬†4.1).\nThis section explores how commonly adjusted parameters and inputs other than the choice of normalization influence the resulting UMAP visualization, aiming to build intuition for how to tune these parameters effectively in your dataset.\nLet‚Äôs systematically vary five key factors:\n\nThe quality filtering applied to the input cells. Using only high-quality cells often leads to clearer, tighter clusters representing core biological populations. If filtering was too stringent then entire cell populations might be unrepresented.\nThe number of Principal Components (PCs) used. Using a lower number will concetrate on the strongest axes of variation at the cost of reducing any distinction between cell subtypes if that distinction is found in higher PCs. Choosing a higher number of PCs can potentially resolve finer subtypes but also risks incorporating noise, which might slightly blur cluster boundaries or create small, potentially spurious groupings.\nThe number of nearest neighbors (n_neighbors). Lower n_neighbors tends to emphasize local cluster separation while higher n_neigbhors tends to form broader clusters.\nThe distance metric (metric). Defines the rule for calculating ‚Äúcloseness‚Äù between cells. Euclidean measures straight-line distance while cosine measures the angle between gene expression profiles. Since changing this alters which cells are considered ‚Äúneighbors,‚Äù the parameter can have large impacts on the global shape. Euclidean is the default many packages but cosine often provides more biologically meaningful clusters for CosMx SMI data.\nThe minimum distance parameter (min_dist). Controls how tightly packed points are within a cluster. Higher values tend to make more diffuse clusters.\nThe spread parameter (spread). Controls the separation between clusters. Lower spread tends to bring clusters closer together.\n\nThis list isn‚Äôt exhaustive, but varying these while keeping others constant will illustrate their core effects. To make this exploration computationally feasible, we will use a representative subsample of 50,000 cells from our quality-flagged dataset. And to make visualization smooth, we‚Äôll only plot at most 500 cells.\nClick the radio buttons below to see what effect these parameter have on the UMAP visualization. Some of these changes are gradual while some dramatically alter the shape and configuration of the UMAP embeddings. You‚Äôll note that filtering out the poor quality cells doesn‚Äôt merely remove the cells from the UMAP; instead, the inclusion of poorer-quality data can effect the entire UMAP topology. I have also included the Leiden clusters for these cells. The number of PCs and the number of neighbors effect Leiden cluster cell assignment while spread and min_dist do not.\nEncouragingly, in this dataset there doesn‚Äôt appear to be any UMAP clusters that appear to be made up of cells that were flagged in our FOV QC analysis (Section 3.1). If this was the case, it would suggest that we would want to remove the cells in the effected FOVs.\n\n\n\n\n\n\n\n\n\n\n\nviewof qc_level = Inputs.radio([\"no QC filter\", \"include FOV QC cells\", \"filter all flags\"], {label: \"QC Level\", value: \"include FOV QC cells\"})\nviewof n_pcs = Inputs.radio([10, 20, 30, 40, 50], {label: \"PCs\", value: 30})\nviewof n_neighbors = Inputs.radio([15, 30, 50], {label: \"Neighbors\", value: 30})\nviewof metric = Inputs.radio([\"euclidean\", \"cosine\"], {label: \"Metric\", value: \"cosine\"})\nviewof mdist = Inputs.radio([0.01, 0.05, 0.2, 0.5], {label: \"Min. distance\", value: 0.2})\nviewof spread = Inputs.radio([0.5, 1.0, 2.0], {label: \"Spread\", value: 2.0})\nviewof colorby = Inputs.radio([\"QC\", \"Leiden\"], {label: \"Color by\", value: \"QC\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqcMasks = ({\n  LOW_COUNTS: 1 &lt;&lt; 0, \n  HIGH_COUNTS: 1 &lt;&lt; 1, \n  LOW_FEAT: 1 &lt;&lt; 2,\n  HIGH_FEAT: 1 &lt;&lt; 3, \n  LOW_SPLIT: 1 &lt;&lt; 4, \n  FOV_QC: 1 &lt;&lt; 5, \n  LOW_SBR: 1 &lt;&lt; 6\n})\n\nflagNames = Object.keys(qcMasks).sort((a, b) =&gt; qcMasks[a] - qcMasks[b]);\nqcFlagMap = new Map(qc_flags_data.map(d =&gt; [d.cell_id, d.qcflag]));\n\nflagColors = {\n  const uniqueFlagsInData = Array.from(new Set(qc_flags_data.map(d =&gt; d.qcflag))).sort((a, b) =&gt; a - b);\n  const uniqueFlagsWithZero = Array.from(new Set([0, ...uniqueFlagsInData])).sort((a,b)=&gt; a-b);\n  const colors = d3.schemeTableau10;\n  const map = {};\n  let colorIndex = 0;\n  uniqueFlagsWithZero.forEach(flagValue =&gt; {\n    if (flagValue === 0) { map[flagValue] = \"black\"; }\n    else { map[flagValue] = colors[colorIndex++ % colors.length]; }\n  });\n  return map;\n}\n\nqcColorScale = (flagValue) =&gt; flagColors[flagValue ?? 0];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqcFlagLegend = {\n  try {\n    const uniqueFlagsWithZero = Object.keys(flagColors).map(Number).sort((a,b)=&gt; a-b);\n    const tableRows = uniqueFlagsWithZero.map(flagValue =&gt; {\n      const flagColor = flagColors[flagValue]; // Use static map\n      const circles = flagNames.map(name =&gt; {\n         const mask = qcMasks[name];\n         const isSet = (flagValue & mask) &gt; 0;\n         const circleFill = isSet ? flagColor : \"#e0e0e0\";\n         const circleSvg = `&lt;svg width=\"15\" height=\"15\"&gt;&lt;circle cx=\"7.5\" cy=\"7.5\" r=\"6\" fill=\"${circleFill}\" stroke=\"${isSet ? 'black' : '#ccc'}\" stroke-width=\"1\"&gt;&lt;/circle&gt;&lt;/svg&gt;`;\n         return `&lt;td style=\"text-align: center;\"&gt;${circleSvg}&lt;/td&gt;`;\n      }).join('');\n      const rowHeader = `&lt;th scope=\"row\" style=\"text-align: right; padding-right: 10px; white-space: nowrap;\"&gt;\n                           &lt;span style=\"display: inline-block; width: 12px; height: 12px; background-color: ${flagColor}; border: 1px solid #555; margin-right: 5px; vertical-align: middle;\"&gt;&lt;/span&gt;\n                           ${flagValue === 0 ? 'Passed' : flagValue}\n                         &lt;/th&gt;`;\n      return `&lt;tr&gt;${rowHeader}${circles}&lt;/tr&gt;`;\n    }).join('');\n    const headerCells = flagNames.map(name =&gt;\n      `&lt;th style=\"height: 100px; text-align: center; vertical-align: bottom; padding-bottom: 5px; font-size: 0.8em; white-space: nowrap;\"&gt;\n         &lt;span style=\"writing-mode: vertical-lr; transform: rotate(180deg);\"&gt;${name.replace(/_/g, ' ')}&lt;/span&gt;\n       &lt;/th&gt;`\n    ).join('');\n    const tableHeader = `&lt;thead&gt;&lt;tr&gt;&lt;th style=\"vertical-align: bottom;\"&gt;Flag Value&lt;/th&gt;${headerCells}&lt;/tr&gt;&lt;/thead&gt;`;\n    return html`&lt;table style=\"border-collapse: collapse; margin-top: 10px; font-size: 0.9em; table-layout: fixed;\"&gt;\n                   ${tableHeader}&lt;tbody&gt;${tableRows}&lt;/tbody&gt;\n                 &lt;/table&gt;`;\n   } catch (error) {\n     console.error(\"Error generating QC Legend:\", error);\n     return html`&lt;div&gt;Error generating QC Legend&lt;/div&gt;`;\n   }\n}\n\n\n\n\n\n\n\n\n\n\nleidenScaleAndLegend = {\n  let scale, legend;\n  try { // Add try...catch\n    // Check if query_data is ready and has 'leiden'\n    if (!query_data || query_data.length === 0 || !query_data[0].hasOwnProperty('leiden')) {\n        console.warn(\"Leiden data (query_data) not ready for legend/scale.\");\n        scale = d3.scaleOrdinal().domain([\"0\"]).range([\"grey\"]); // Placeholder scale\n        legend = html`&lt;div&gt;&lt;ul style=\"list-style: none; padding-left: 0; margin-top: 10px; font-size: 0.9em;\"&gt;\n                        &lt;li style=\"margin-bottom: 2px;\"&gt;&lt;span style=\"display: inline-block; width: 12px; height: 12px; background-color: grey; border: 1px solid #555; margin-right: 5px; vertical-align: middle;\"&gt;&lt;/span&gt; Cluster 0&lt;/li&gt;\n                      &lt;/ul&gt;(Loading...)&lt;/div&gt;`; // placeholder\n    } else {\n        const uniqueClusters = Array.from(new Set(query_data.map(d =&gt; d.leiden))).sort((a, b) =&gt; a - b);\n        scale = d3.scaleOrdinal(d3.schemeTableau10).domain(uniqueClusters);\n\n        const legendItems = uniqueClusters.map(cluster =&gt; {\n           const color = scale(cluster);\n           const clusterLabel = String(cluster);\n           return `&lt;li style=\"margin-bottom: 2px;\"&gt;&lt;span style=\"display: inline-block; width: 12px; height: 12px; background-color: ${color}; border: 1px solid #555; margin-right: 5px; vertical-align: middle;\"&gt;&lt;/span&gt; Cluster ${clusterLabel}&lt;/li&gt;`;\n        }).join('');\n        legend = html`&lt;ul style=\"list-style: none; padding-left: 0; margin-top: 10px; font-size: 0.9em;\"&gt;${legendItems}&lt;/ul&gt;`;\n    }\n  } catch(error) {\n     console.error(\"Error generating Leiden Legend:\", error);\n     scale = () =&gt; 'grey';\n     legend = html`&lt;div&gt;Error generating Leiden Legend&lt;/div&gt;`;\n  }\n  return { scale, legend };\n}\n\nleidenColorScale = leidenScaleAndLegend.scale\nleidenLegendHtml = leidenScaleAndLegend.legend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd3 = require(\"d3@7\")\n\nwidth = 500\nheight = 500\nmarginTop = 20\nmarginRight = 20\nmarginBottom = 30\nmarginLeft = 40\n\nxScale = d3.scaleLinear().domain([0, 1]).range([marginLeft, width - marginRight])\nyScale = d3.scaleLinear().domain([0, 1]).range([height - marginBottom, marginTop])\n\nsvg = d3.create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto;\");\n\nxAxis = d3.axisBottom(xScale)\n    .ticks(width / 80)\n    .tickSizeOuter(0)\n    .tickSizeInner(-(height - marginTop - marginBottom));\n\nyAxis = d3.axisLeft(yScale)\n    .ticks(height / 40)\n    .tickSizeOuter(0)\n    .tickSizeInner(-(width - marginLeft - marginRight));\n\ngx = svg.append(\"g\")\n    .attr(\"class\", \"x-axis\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .call(xAxis);\n\ngy = svg.append(\"g\")\n    .attr(\"class\", \"y-axis\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .call(yAxis);\n\nsvg.selectAll(\".tick line\")\n   .attr(\"stroke-opacity\", 0.1);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsvg.append(\"text\")\n    .attr(\"x\", width - marginRight)\n    .attr(\"y\", height - marginBottom - 4)\n    .attr(\"fill\", \"currentColor\")\n    .attr(\"text-anchor\", \"end\")\n    .text(\"UMAP 1 ‚Üí\");\n\n\n\n\n\n\n\nsvg.append(\"text\")\n    .attr(\"x\", marginLeft + 4)\n    .attr(\"y\", marginTop)\n    .attr(\"fill\", \"currentColor\")\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"dominant-baseline\", \"hanging\")\n    .text(\"‚Üë UMAP 2\");\n\n\n\n\n\n\n\n-\nsvg.append(\"clipPath\")\n    .attr(\"id\", \"clip\")\n  .append(\"rect\")\n    .attr(\"x\", marginLeft)\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n\n\n\n\n\n\npointGroup = svg.append(\"g\")\n    .attr(\"fill\", \"black\")\n    .attr(\"clip-path\", \"url(#clip)\");\n\n\n\n\n\n\n\n\n\n{ // Reactive block\n  const updateVisualization = () =&gt; {\n    const duration = 750;\n    \n    const currentScale = colorby === \"QC\" ? qcColorScale : leidenColorScale;\n\n    if (!currentScale) { \n        console.error(\"Scale missing\"); \n        return; \n    }\n    \n    if (!query_data || query_data.length === 0) {\n       console.warn(\"No data available for plotting.\");\n       pointGroup.selectAll(\"circle\").transition().duration(duration).attr(\"opacity\", 0).remove();\n       return; \n    }\n\n    const xExtent = d3.extent(query_data, d =&gt; d.umap_1);\n    const yExtent = d3.extent(query_data, d =&gt; d.umap_2);\n\n    const xPad = (xExtent[1] - xExtent[0]) * 0.05;\n    const yPad = (yExtent[1] - yExtent[0]) * 0.05;\n\n    xScale.domain([xExtent[0] - xPad || -1, xExtent[1] + xPad || 1]);\n    yScale.domain([yExtent[0] - yPad || -1, yExtent[1] + yPad || 1]);\n\n    svg.select(\".x-axis\")\n      .transition().duration(duration)\n      .call(xAxis)\n      .on(\"start\", () =&gt; {\n         svg.selectAll(\".x-axis .tick line\").attr(\"stroke-opacity\", 0.1);\n      });\n\n    svg.select(\".y-axis\")\n      .transition().duration(duration)\n      .call(yAxis)\n      .on(\"start\", () =&gt; {\n         svg.selectAll(\".y-axis .tick line\").attr(\"stroke-opacity\", 0.1);\n      });\n\n    pointGroup.selectAll(\"circle\")\n      .data(query_data, d =&gt; d.cell_id)\n      .join(\n        enter =&gt; enter.append(\"circle\")\n            .attr(\"cx\", d =&gt; xScale(d.umap_1)) \n            .attr(\"cy\", d =&gt; yScale(d.umap_2))\n            .attr(\"r\", 2.5)\n            .attr(\"fill\", d =&gt; {\n                try {\n                    const valueToColor = colorby === \"QC\" ? qcFlagMap.get(d.cell_id) : d.leiden;\n                    return currentScale(valueToColor) || 'grey';\n                } catch(e) { return 'grey'; }\n            }) \n            .attr(\"opacity\", 0)\n            .call(enter =&gt; enter.transition().duration(duration).attr(\"opacity\", 0.8)),\n        \n        update =&gt; update\n            .call(update =&gt; update.transition().duration(duration)\n                .attr(\"cx\", d =&gt; xScale(d.umap_1))\n                .attr(\"cy\", d =&gt; yScale(d.umap_2))\n                .attr(\"fill\", d =&gt; { \n                    try {\n                        const valueToColor = colorby === \"QC\" ? qcFlagMap.get(d.cell_id) : d.leiden;\n                        return currentScale(valueToColor) || 'grey';\n                    } catch(e) { return 'grey'; }\n                })\n                .attr(\"opacity\", 0.8)\n             ),\n        \n        exit =&gt; exit\n            .call(exit =&gt; exit.transition().duration(duration).attr(\"opacity\", 0).remove())\n      );\n  };\n  \n  try { \n    updateVisualization();\n  } catch(error) {\n    console.error(\"Error during D3 updateVisualization:\", error);\n  }\n\n  return svg.node(); \n}\n\n\n\n\n\n\nIn the dot plot on the bottom left provides a QC flag legend. For example, QC flag ‚Äò5‚Äô represents cells that were flagged for having low counts and low features whereas QC flag ‚Äò96‚Äô represents cells that wee flagged for FOV QC as wells as low SBR.\n\n\nIf you want to further explore this subset, you can examine the query_data and qc_flags_data dataframes below.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Normalization, Reduction, and Clustering</span>"
    ]
  },
  {
    "objectID": "processing.html#conclusion",
    "href": "processing.html#conclusion",
    "title": "4¬† Normalization, Reduction, and Clustering",
    "section": "4.4 Conclusion",
    "text": "4.4 Conclusion\nAnd with that, we‚Äôve navigated the essential pre-processing steps. Starting with our quality-controlled cell data, we applied normalization to account for technical variations, identified the most informative genes, and used PCA to reduce the data‚Äôs dimensionality. Building upon this foundation, we generated UMAP embeddings for visualization and performed Leiden clustering to partition the cells into distinct groups based on their expression profiles.\nThe interactive exploration highlighted a critical point: parameters matter. Choices made during normalization, dimensionality reduction, and clustering significantly influence the final UMAP layout and cluster assignments. There isn‚Äôt a single ‚Äúcorrect‚Äù set of parameters, but understanding their effects allows you to tailor the analysis to best reveal the biological structures relevant to your specific questions.\nThe resulting AnnData object, now enriched with normalized data layers, PCA coordinates, UMAP embeddings, and Leiden cluster labels, is primed for the next crucial phase: assigning biological meaning to these patterns. In the following chapters we will delve into grouping cells based on their spatial domain and their cell types.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Hafemeister, C. & Satija, R. Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression. Genome Biol. 20, 296 (2019).",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Normalization, Reduction, and Clustering</span>"
    ]
  },
  {
    "objectID": "processing.html#footnotes",
    "href": "processing.html#footnotes",
    "title": "4¬† Normalization, Reduction, and Clustering",
    "section": "",
    "text": "when I tried using the sc.experimental.pp.normalize_pearson_residuals method on this dataset, the OS crashed (&gt;200 GBs of RAM).‚Ü©Ô∏é\nTo see how to generate this type of output, click the &lt;/&gt; icon on the top right of this chapter and then click view source.‚Ü©Ô∏é",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Normalization, Reduction, and Clustering</span>"
    ]
  },
  {
    "objectID": "spatial-domains.html",
    "href": "spatial-domains.html",
    "title": "5¬† Spatial Domains",
    "section": "",
    "text": "5.1 Model tuning\nWhile cell typing is one of the most useful cell-level labels we can use to organize our data, it can be illuminating to identifying the function regions within the sample based on the local composition of cells. This chapter uses novae1 to identify function regions within the tissue. Note that this approach does not rely on pre-existing cell type labels.\nIn the code below, the anndata object is loaded and spatial coordinates are converted. Then a Delaunay graph is generated. Since the pre-trained model is from a composite of platforms, we‚Äôll run the optional fine-tuning procedure. To make this computation more efficient, we‚Äôll specify the fine_tune method to use GPU instead of CPU. After tuning, we‚Äôll computing the representations on the data and assign spatial domains. Finally, we‚Äôll save the results and the tuned model to disk for later.\nPython Code\nimport torch\nimport novae\nimport igraph\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\n\nsc.settings.figdir = r.dom_dir\ntorch.set_float32_matmul_precision('high')\nnovae.settings.auto_preprocessing = True\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nif 'adata' not in dir():\n  adata = ad.read_h5ad(os.path.join(analysis_dir, \"anndata-2-leiden.h5ad\"))\n\nadata.X = adata.layers['counts'].copy()\n\n# convert spatial from mm to microns\nadata.obsm['spatial_mm'] = adata.obsm['spatial'].copy()\nadata.obsm['spatial_um'] = adata.obsm['spatial_mm']*1000\nadata.obsm['spatial'] = adata.obsm['spatial_um']\n\n# Create a Delaunay graph of the data. \nnovae.spatial_neighbors(adata, radius=100, coord_type='generic')\n\nnovae.plot.connectivities(adata)\nplt.gca().invert_yaxis()\nplt.savefig(os.path.join(dom_dir, \"connectivity_plot.png\"), dpi=300, bbox_inches='tight')\nplt.close()\n\nmodel1 = novae.Novae.from_pretrained(\"MICS-Lab/novae-human-0\")\nFigure¬†5.1 confirms that a radius of 100 ¬µm produces relatively few isolated cells. If there were many isolated cells within regions, we might consider increasing the radius.\nFigure¬†5.1: Cells with low connectivity (in red).\nIf you want to fine-tune the model based on your current data, you can run the fine_tune method like so.\nPython Code\nimport time\nstart_time = time.time()  # Record the start time\nmodel1.fine_tune(adata, max_epochs=50, logger=True, accelerator='cuda', num_workers=4)\nend_time = time.time()    # Record the end time\nelapsed_time = end_time - start_time\nprint(f\"Execution time: {elapsed_time:.4f} seconds\")\n\nnovae_cells = adata.shape[0]\nnovae_fine_tune_seconds = elapsed_time\nFrom the data and the model, we can compute the representations and assign cells on of a varying number of domain levels. When saving domain levels, I like to increment from one or two to a relatively high number and visualize on the tissue where domains split. Let‚Äôs save the model in case we ever want to use it later and plot the domain hierarchy.\nPython Code\nstart_time = time.time()\nmodel1.compute_representations(adata, zero_shot=False, accelerator='cuda', num_workers=4)\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint(f\"Execution time: {elapsed_time:.4f} seconds\")\n\nnovae_compute_representations_seconds = elapsed_time\n\nfor i in range(1, 12):\n  model1.assign_domains(adata, i)\n\nmodel1_dir = os.path.join(dom_dir, \"novae_model_one\")\nmodel1.save_pretrained(save_directory=model1_dir)\n\ndh = model1.plot_domains_hierarchy()\nplt.savefig(os.path.join(dom_dir, \"novae_model1_hierarchy.png\"), dpi=300, bbox_inches='tight')\nplt.close()\n\nadata.write_h5ad(\n  os.path.join(analysis_dir, \"anndata-3-novae.h5ad\"),\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)\nR Code\nresults_list[['novae_cells']] = py$novae_cells\nresults_list[['novae_fine_tune_seconds']] = py$novae_fine_tune_seconds\nresults_list[['novae_compute_representations_seconds']] = py$novae_compute_representations_seconds\nsaveRDS(results_list, results_list_file)\nIf you find that running the above code in CPU-only mode takes a long time and you have GPUs available with cuda configured, I recommend trying accelerator='cuda'. For this dataset with 4.6682^{5} cells using a single L4 GPU, it took 16 minutes to run the fine tuning procedure and 4 minutes to compute representations.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Spatial Domains</span>"
    ]
  },
  {
    "objectID": "spatial-domains.html#model-tuning",
    "href": "spatial-domains.html#model-tuning",
    "title": "5¬† Spatial Domains",
    "section": "",
    "text": "Note\n\n\n\nWhile most of this analysis uses Pearson Residuals-based normalization results, we do not have the normalization matrix and novae works best with total counts-based normalization. Thus, we‚Äôll let novae run the preprocessing steps.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Spatial Domains</span>"
    ]
  },
  {
    "objectID": "spatial-domains.html#model-visuals",
    "href": "spatial-domains.html#model-visuals",
    "title": "5¬† Spatial Domains",
    "section": "5.2 Model Visuals",
    "text": "5.2 Model Visuals\nWe assigned 11 domain levels. Figure¬†5.2 shows the hierarchical relationship between them.\n\n\n\n\n\n\n\n\nFigure¬†5.2: Hierarchical relationships among novae domains.\n\n\n\n\n\nPlot these novae clusters in XY and UMAP space. As with ?sec-processing, we‚Äôll make use of the plotDots function after defining colors.\n\n\nR Code\ndf &lt;- py$adata$obs %&gt;% \n  select(starts_with(\"novae_domains_\"))\n\ndomain_names &lt;- c()\nfor(i in 1:ncol(df)){\n  pick &lt;- which(colnames(df)==paste0('novae_domains_', i))\n  print(pick)\n  domain_names &lt;- c(domain_names, sort(unique(as.character(df[,pick]))))\n}\ndomain_names &lt;- unique(domain_names)\n\nset.seed(98103)\ndomain_colors &lt;- sample(pals::alphabet2(length(domain_names)))\nnames(domain_colors) &lt;- domain_names\nresults_list[['novae_model_1_domain_names']] &lt;- names(domain_colors)\nresults_list[['novae_model_1_domain_colors']] &lt;- as.character(domain_colors)\nsaveRDS(results_list, results_list_file)\n\n\n\n\nR Code\nsource(\"./helpers.R\")\nfor(prefix in colnames(df)){\n  plotDots(py$adata, color_by=prefix,\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = dom_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = domain_colors),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Spatial Domains\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n}\n\n\n\nDomains: 1Domains: 2Domains: 3Domains: 4Domains: 5Domains: 6Domains: 7Domains: 8Domains: 9Domains: 10Domains: 11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe choice of domain resolution depends on the types of biological questions that are used. For example, if you wanted finer resolution of the micro-niches within the epithelium (top part of the tissue, you may increase the number of domains). For the purpose of this chapter, let‚Äôs pick seven domains.\nFocusing on six domain solution, plot individual XY plots to see the spatial layout of each domain.\n\n\nR Code\nprefix &lt;- \"novae_domains_6\"\nplotDots(py$adata, color_by=prefix,\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = dom_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = domain_colors),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Spatial Domains\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n\n\nDomain: D1000Domain: D1003Domain: D1011Domain: D1015Domain: D1016Domain: D1017",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Spatial Domains</span>"
    ]
  },
  {
    "objectID": "spatial-domains.html#conclusions",
    "href": "spatial-domains.html#conclusions",
    "title": "5¬† Spatial Domains",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nNow that we have the spatial domain assignments, the next step is to assign functional names to these assignments. To aid in this effort, we‚Äôll first look at the composition of cell types within these domains which is the topic of the next chapter.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Blampey, Q., Benkirane, H., Bercovici, N., Andre, F. & Cournede, P.-H. Novae: A graph-based foundation model for spatial transcriptomics data. 2024.09.09.612009 (2024) doi:10.1101/2024.09.09.612009.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Spatial Domains</span>"
    ]
  },
  {
    "objectID": "cell-typing.html",
    "href": "cell-typing.html",
    "title": "6¬† Cell Typing",
    "section": "",
    "text": "6.1 Cell Typing Approaches\nOkay, let‚Äôs chart the course for this crucial phase of our analysis expedition: cell typing. This is where we assign identities to the cell clusters discovered in the previous chapter, transforming abstract groups into recognizable biological entities like T cells, macrophages, or tumor cells.\nIf pre-processing was about plotting our trajectory through high-dimensional space, cell typing is akin to navigating a dense asteroid field. It‚Äôs a critical step, but one fraught with potential obstacles. Assigning definitive labels can be challenging, often requiring careful consideration of marker genes and existing biological knowledge. What constitutes a ‚Äúcorrect‚Äù cell type label can even be subjective, depending entirely on the resolution needed for your specific biological questions. Are you aiming to distinguish broad categories like ‚Äúimmune‚Äù versus ‚Äútumor,‚Äù or do you need to pinpoint specific T cell subtypes? Like adjusting a microscope‚Äôs focus, the level of detail required dictates the approach. Navigating this field requires careful maneuvering and the right instruments. Autopilot hasn‚Äôt been invented just yet and so the best recommendation need manual input.\nOne common hazard is attempting to directly apply analysis pipelines designed for spatially-dissociated scRNA-seq. While scRNA-seq vignettes offer valuable starting points, CosMx SMI data, generated by direct in situ hybridization, has fundamentally different characteristics. Simply copy-pasting scRNA-seq methods without adaptation can lead to suboptimal or incomplete cell type assignments. Instead, we must employ or adapt methods that leverage the strengths of high-plex, direct hybridization data to achieve reliable annotations. In doing so it‚Äôs possible to achieve the most comprehensive and biologically-rich cell typing and sub-typing possible in spatial transcriptomics.\nIt‚Äôs also crucial to remember that cell typing, while essential, isn‚Äôt the final destination of our journey. It‚Äôs a powerful tool for organizing our cellular map, allowing us to ask spatially-aware questions. However, other organizational frameworks, such as classifying cells based on their spatial neighborhood or ‚Äúniche,‚Äù are equally important for understanding the tissue‚Äôs complex ecosystem. Ultimately, cell typing is foundational: it establishes the structural anatomy of the dataset, paving the way for us to investigate its functional physiology in the next chapters.\nIn this chapter, we will navigate the cell typing process in the colon dataset. The main goal is to generate cell type labels that are ‚Äúclose‚Äù while also being approachable. I‚Äôll begin (Section 6.1) by surveying some of the spatially unaware methods and then summarize the state of the direct hybridization-inspired approaches. Then I will guide you through the specific, hybrid workflow used for this colon dataset. We will start with the broad Leiden clusters defined in the previous chapter, refine them based on spatial observations, and assign primary identities using marker gene analysis. Finally, for the more complex immune populations where standard clustering often struggles, we will employ HieraType, a probabilistic method explicitly designed to handle the specific characteristics of CosMx SMI data.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Cell Typing</span>"
    ]
  },
  {
    "objectID": "cell-typing.html#sec-ct-approaches",
    "href": "cell-typing.html#sec-ct-approaches",
    "title": "6¬† Cell Typing",
    "section": "",
    "text": "6.1.1 Non-spatial Cell Typing Approaches\nBefore discussing spatially-aware or technology-specific approaches, let‚Äôs briefly cover common methods designed for non-spatial, single-cell RNA sequencing analysis. These techniques primarily leverage the gene expression matrix (adata.X and normalized layers) and the cluster assignments (e.g., adata.obs['leiden']) derived in the previous chapter. Many excellent vignettes exist for these methods in popular frameworks like scanpy (Python) and Seurat (R), providing a rough ‚Äú10,000-foot view‚Äù of the data‚Äôs cellular composition.\nCluster Marker Gene Identification (Leiden/Louvain): This is often a foundational step in scRNA-seq. After obtaining clusters (like the Leiden clusters from Chapter 4), differential expression tests are performed between each cluster and all other cells (or between pairs of clusters). This identifies genes significantly upregulated within a specific cluster. Tools like scanpy‚Äôs rank_genes_groups or Seurat‚Äôs FindMarkers are standard. The resulting lists of marker genes are then manually compared against known canonical markers from literature or cell atlases to assign putative cell type identities (e.g., observing high CD3E, CD8A suggests a T cell cluster; high EPCAM, KRT19 suggests epithelial cells). While effective, this relies heavily on prior biological knowledge and the quality of the initial clustering. It also assumes that transcripts found in the cell do not arise from any spatial co-localization or imperfect cell-cell segmentation boundaries that can arise when assigning transcripts to cells.\nNested / Hierarchical Clustering Analysis: Sometimes, broad initial clusters (like ‚ÄúImmune Cells‚Äù or ‚ÄúFibroblasts‚Äù) contain sub-populations that are meaningful for your analysis. A common refinement is then to subset the data to include only cells from a specific Leiden cluster (or set of clusters) and then re-run the clustering process within that subset. Identifying marker genes for these sub-clusters can reveal finer cell types or states (e.g., distinguishing CD4+ from CD8+ T cells, or identifying different fibroblast subtypes. This iterative approach allows for a hierarchical understanding of cell identity; however, the imperfect segmentation noted above is amplified in this approach. Consider a workflow where one uses HVGs to create an initial set of ‚ÄúElementary‚Äù clusters and uses a marker gene-based approach to label these broad clusters. When subsetting down to, say, fibroblasts and rerunning the above HVG -&gt; Leiden -&gt; marker gene workflow, one may get non-fibroblast marker genes returned. The reason for this is twofold. First the general fibroblast marker genes are no longer as differentially expressed in the subset of Fibroblasts as they were in the full data and 2) if there are cell segmentation errors of fibroblast sub-populations that are spatially-associated with unrelated cell types ‚Äì like plasma cells ‚Äì the HVG algorithm may identify spurious gene markers as highly variable. The result would be markers like JCHAIN in fibroblasts that happen to be located near a germinal center, tertiary lymphoid structure, or similar. Thus, while this nested approach can be valuable, it should be used with caution. For more information on this overlap concept, see Dan McGuire‚Äôs blog post on smiDE.\nReference-Based Annotation: Instead of relying solely on de novo marker finding, many methods leverage existing annotated single-cell datasets (atlases) as references. These algorithms typically project the query data onto the reference or use statistical models trained on the reference to directly assign cell type labels to your individual cells or clusters. Popular tools include:\n\nscanpy.tl.ingest: Integrates query data onto an existing annotated AnnData object.\nSeurat‚Äôs FindTransferAnchors and TransferData: A widely used method in the R ecosystem.\nInSituType‚Äôs fully supervised method: InSituType ‚Äì while designed for spatial data ‚Äì can be used as a fully supervised classifier. I‚Äôm including it here since many reference datasets and atlases at the time of writing are based on scRNA-seq data.\n\n\n\n6.1.2 Spatially-Informed and Hybridization-Aware Methods\nUnlike standard scRNA-seq workflows, these approaches leverage the unique features of in situ data: specifically the spatial coordinates, the negative probe background, and the available protein data.\nBackground-Aware Modeling. Methods like InSituType explicitly model the background noise using the negative control probes. This allows for more accurate classification of cells with low transcript counts that might be discarded or misclassified by standard scRNA-seq tools\nSpatial-Molecular Joint Inference. Tools like Banksy utilize the expression of a cell‚Äôs physical neighbors to inform its identity. This leverages the biological reality that cells of the same type often cluster spatially, helping to smooth out technical noise in individual cells.\nMulti-modal Integration. CosMx SMI often includes protein markers (e.g., CD45, PanCK) in the form of IF markers or ‚Äì more recently ‚Äì with true RNA and protein same-slide multiomics. ‚ÄúDual-mode‚Äù typing strategies use these robust protein signals to define major lineages (e.g., ‚ÄúThis cell is definitely CD45+ Immune‚Äù) before using the RNA data to determine the specific subtype (e.g., ‚ÄúIt is a CD8+ T Cell‚Äù). Similarly, HieraType is a new R package for supervised classification that can combine multi-omics information to cell type. HieraType also classifies RNA-only data (as we‚Äôll see below).\nReference-Based Annotation: Reference profiles based on CosMx SMI can be used to more quickly cell type new datasets. This approach can be much faster than cell typing de novo but requires such annotations to be available.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Cell Typing</span>"
    ]
  },
  {
    "objectID": "cell-typing.html#cell-type-determination",
    "href": "cell-typing.html#cell-type-determination",
    "title": "6¬† Cell Typing",
    "section": "6.2 Cell Type Determination",
    "text": "6.2 Cell Type Determination\nJust like there are many paths through an asteroid field, there are many ways to navigate cell typing. I find the following approach makes a good starting place for any analysis as it‚Äôs relatively fast while still allowing for human intervention.\n\nUse Leiden clusters identified in Chapter 4 as the basis. 1.1. Optional: refine Leiden clusters based on discovered biology. For example, there may be some Leiden clusters that makes sense to merge together or some evidence that splitting a Leiden cluster into two or splitting a given Leiden cluster into multiple sub-clusters based on the spatial layout of cells.\nRun HieraType to classify cells and use its integration function to merge its supervised classifications with the unsupervised Leiden clusters.\nOf the remaining unclassified cells, use marker genes to infer the most likely cell type.\n\n\n6.2.1 Step 1: Read Leiden clusters\nLoad the data and make a copy of the leiden_pr metadata column that we‚Äôll use.\n\n\nPython Code\nadata = ad.read_h5ad(os.path.join(r.analysis_dir, \"anndata-2-leiden.h5ad\"))\n\ncluster_renaming = {}\ninitial = \"C\"\nfor name in adata.obs['leiden_pr'].unique():\n  cluster_renaming[name] = f\"{initial}-{name}\"\nadata.obs['leiden'] = adata.obs['leiden_pr'].map(cluster_renaming)\n\n\n\n\n6.2.2 Step 2: Run HieraType\nInstall the HieraType package (and remotes), if needed. Then extract the lists of marker genes.\n\n\nR Code\ninstall.packages(\"mvtnorm\")\n\nremotes::install_github(\"Nanostring-Biostats/CosMx-Analysis-Scratch-Space\",\n                         subdir = \"_code/HieraType\", ref = \"Main\")\n\nlibrary(HieraType)\n\nmarkerg &lt;- unlist(lapply(c(\n  HieraType::markerslist_l1\n  ,HieraType::markerslist_immune\n  ,HieraType::markerslist_cd8tminor\n  ,HieraType::markerslist_cd4tminor\n  ,HieraType::markerslist_tcellmajor\n), \"[[\", \"predictors\"))\n\nmarker_genes &lt;- as.character(markerg)\n\n\nConvert data to R.\n\n\nPython Code\ntotal_counts_per_cell = adata.layers['counts'].sum(axis=1)\ntotal_counts_per_cell = np.asarray(total_counts_per_cell).flatten()\n\ntotal_counts_per_target = adata.layers['counts'].sum(axis=0)\ntotal_counts_per_target = np.asarray(total_counts_per_target).flatten()\n\ntarget_frequencies = total_counts_per_target / total_counts_per_target.sum()\n\n# Include all HVGs and marker genes (even if not in the HVGs)\nmarker_genes = r.marker_genes\nmarker_mask = adata.var.index.isin(marker_genes)\nhighly_variable_mask = adata.var['highly_variable'].to_numpy()\nadata.var['hieratype_target'] = (highly_variable_mask | marker_mask)\n\nadata_ht = adata[:, adata.var.hieratype_target].copy()\n1ht_counts = adata_ht.layers['counts'].copy().astype(np.int64)\n\n\n\n1\n\nIn order to use this matrix in R, we need to convert the 32 bit integer counts into 64 bit integers.\n\n\n\n\nFollow this tutorial to refine Leiden clusters with immune cells.\n\n\nR Code\nht_counts &lt;- py$ht_counts\nrownames(ht_counts) &lt;- py$adata_ht$obs_names$to_list()\ncolnames(ht_counts) &lt;- py$adata_ht$var_names$to_list()\nht_counts &lt;- as(ht_counts, \"CsparseMatrix\")\n\npca_embeddings &lt;- py$adata_ht$obsm['X_pca_pr'] # n_cells x n_pcs\n\ntarget_frequencies &lt;- py$target_frequencies \nnames(target_frequencies) &lt;- py$adata$var_names$to_list()\ntarget_frequencies &lt;- target_frequencies[colnames(ht_counts)] \n\ntotal_counts_per_cell &lt;- py$total_counts_per_cell\n\n# Assumes this was based on cosine.\nsim_graph &lt;- py$adata_ht$obsp['neighbors_pr_connectivities']\nsim_graph &lt;- as(sim_graph, \"CsparseMatrix\")\nrownames(sim_graph) &lt;- colnames(sim_graph) &lt;- rownames(ht_counts)\n\n\nRun the pipeline.\n\n\nR Code\npipeline &lt;- HieraType::make_pipeline(\n  markerslists = list(\n    \"l1\" = HieraType::markerslist_multiomic_l1\n    ,\"l2\" = HieraType::markerslist_multiomic_immune\n    ,\"lt\" = HieraType::markerslist_multiomic_tcellmajor\n    ,\"lt4minor\" = HieraType::markerslist_multiomic_cd4tminor\n    ,\"lt8minor\" = HieraType::markerslist_multiomic_cd8tminor\n  )\n  ,priors = list(\n    \"l2\" = \"l1\"\n    ,\"lt\" = \"l2\"\n    ,\"lt4minor\" = \"lt\"\n    ,\"lt8minor\" = \"lt\"\n  )\n  ,priors_category = list(\n    \"l2\" = \"immune\"\n    ,\"lt\" = \"tcell\"\n    ,\"lt4minor\" = \"cd4t\"\n    ,\"lt8minor\" = \"cd8t\"\n  )\n)\n\nrnactobj &lt;- HieraType::run_pipeline(\n  pipeline = pipeline,\n  counts_matrix = ht_counts,\n  adjacency_matrix = sim_graph[rownames(ht_counts), rownames(ht_counts)],\n  totalcounts = total_counts_per_cell,\n  gene_wise_frequency = target_frequencies\n)\nsaveRDS(rnactobj, file=file.path(ct_dir, \"rnactobj.rds\"))\n\n\nMerge the Leiden cluster calls with the HieraType results. There are several ways we could do this but for this tutorial we‚Äôll use HieraType‚Äôs built-in celltype_label_integration function using the default parameters. celltype_label_integration integrates the immune celltype annotations from HieraType with unsupervised cluster labels. The goal of this step is to enable granular detection of novel or tissue-specific cell types (unsupervised), along with well known immune cell types (HieraType). The logic for merging these annotations works like this:\n\nAll cells which are annotated with an immune-celltype HieraType label keep their label.\nAll cells with a non-immune HieraType label take the unsupervised cluster label.\nUnsupervised clusters that had a high rate of cells taking immune labels (say 90%), and make up only a small proportion of all cells (say 1%) after step 1 are ‚Äòdissolved‚Äô. These dissoved cells are assigned the most common cluster label (could be immune or unsupervised) amongst most the similar neighboring cells. Here we used the neighbor cells from the adjacency matrix that was used to run HieraType.\n\n\n\nR Code\ncell_type_dt &lt;- rnactobj$post_probs$l1\n1cell_type_dt &lt;- rename(cell_type_dt, cell_id = cell_ID,\n                       Hieratype_celltype_fine = celltype_granular)\n\nto_merge &lt;- py$adata$obs %&gt;% select(leiden)\n\ncell_type_dt$Leiden &lt;- to_merge$leiden[match(rownames(to_merge), cell_type_dt$cell_id)]\n\ncell_type_dt &lt;- celltype_label_integration(\n  metadata = cell_type_dt, \n  adjacency_mat = sim_graph[rownames(ht_counts), rownames(ht_counts)],\n  cellid_colname = 'cell_id',\n  supervised_colname = 'Hieratype_celltype_fine',\n  unsupervised_colname = 'Leiden')\n\ncell_type_dt &lt;- rename(cell_type_dt, merged = celltype)\n\nsaveRDS(cell_type_dt, file=file.path(ct_dir, \"cell_type_dt.rds\"))\n\n\n\n1\n\ncell_id here is the row name from the anndata object (as opposed to the c_i_j_k cell_ID notation that is sometimes used).\n\n\n\n\nSave the new calumns back to the anndata object.\n\n\nPython Code\ncell_type_df = r.cell_type_dt\n\nadata.obs = adata.obs.join(cell_type_df[['cell_id', 'Hieratype_celltype_fine', 'merged']].set_index('cell_id'))\n\n\n\n\n6.2.3 Step 3: Classify remaining cells using marker genes\nFor the cells still assigned a Leiden cluster label, run a marker gene analysis to determine the dominant cell type per cluster. We‚Äôll subset larger clusters down to 10,000 cells to speed up the computation. Since scanpy‚Äôs tl.rank_genes_groups function needs normalizaed data, we‚Äôll use the log1p-transformed matrix that we generated in Chapter 4.\n\nbdata = adata[adata.obs['leiden']==adata.obs['merged'], :].copy()\n\nrandom_seed = 98103\nnp.random.seed(random_seed)\n\ntarget_cells_per_cluster = 10000\ncells_to_keep_indices = []\ncluster_counts = bdata.obs['merged'].value_counts()\n\nfor cluster_label in cluster_counts.index:\n    cluster_cells = bdata.obs_names[bdata.obs['merged'] == cluster_label]\n    num_cells_in_cluster = len(cluster_cells)\n\n    if num_cells_in_cluster &gt; target_cells_per_cluster:\n        print(f\"Cluster '{cluster_label}' has {num_cells_in_cluster} cells, subsampling to {target_cells_per_cluster}.\")\n        subsampled_cells = np.random.choice(\n            cluster_cells,\n            size=target_cells_per_cluster,\n            replace=False\n        )\n        cells_to_keep_indices.extend(subsampled_cells)\n    else:\n      cells_to_keep_indices.extend(cluster_cells)\n\n\nbdata_subsampled = bdata[cells_to_keep_indices, :].copy()\n\n1bdata_subsampled.X = bdata_subsampled.layers['TC'].copy()\n\n\n1\n\nIf you do not have the log1p-transformed total counts layer ‚ÄòTC‚Äô saved, run sc.pp.normalize_total and sc.pp.log1p (see ?sec-tc-workflow).\n\n\n\n\nRun rank_genes_groups and save results.\n\nct_dir = r.ct_dir\nsc.settings.figdir = ct_dir\n\nsc.tl.rank_genes_groups(bdata_subsampled, 'leiden', method='wilcoxon',\n  solver='saga', max_iter=200, pts=True) # ~an hour using logreg\nsc.pl.rank_genes_groups(bdata_subsampled, n_genes=8, sharey=True, fontsize=10, save=\"_marker_gene_ranks_global.png\")\nsc.pl.rank_genes_groups_dotplot(bdata_subsampled, n_genes=8, save=\"_marker_gene_dotplot_global.png\")\n\nfilename = os.path.join(r.analysis_dir, \"anndata-5-subset-marker-genes.h5ad\")\n\nbdata_subsampled.write_h5ad(\n  filename,\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)\n\nThe next task is determine from the marker gene results the dominant cell types that are likely found within each Leiden cluster. While some Leiden clusters will have a high proportion of cells that are of the same type or state, keep in mind that other Leiden clusters might be composites of cell types. The tools we have for this exercise are:\n\nvisual aids from the marker gene results and\ncompare with external sources. The literature and subject matter expertise is the gold-standard for this.\n\n\n\n\n\n\n\n\n\nFigure¬†6.1: Marker gene ranks by Leiden cluster (global).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.2: Marker gene dot plot by Leiden cluster (global).\n\n\n\n\n\nExamine the clusters by extracting the top 25 markers and their relative scores and comparing to the literature. Large Language Models can provide supportive information here but it‚Äôs always recommended to use LLMs with caution and to verify any of the results. In other words, LLMs can be fast but at the cost of accuracy. In the example below, I created an LLM prompt that includes the top marker gene statistics. Let‚Äôs see what it generates.\n\nmarker_dict, marker_df = format_ranked_genes(bdata_subsampled, 25)\n\ncsv_file_path = os.path.join(ct_dir, \"colon_cancer_top_marker_genes_global.csv\")\nmarker_df.to_csv(csv_file_path, index=True)\n\nprint(f\"I am analyzing a CosMx SMI dataset of from Colon cancer and have run Leiden clustering.\\nI have already classified several of the immune cells within the larger dataset and now I would like your help in predicting the most like cell type given the marker gene profile from this subset of data.\\nBelow is a dictionary of results where the key represents the Leiden cluster\\nname and its corresponding item is a list of ordered tuples where each tuple\\nprovides the marker name and the relative score for that marker.\\n\\n Please provide a table with the columns that represent 1. inferred cell type 2. your confidence in that cell type 3. up to five markers from the list that are key to your result and 4. a brief justification of your result. Please present the results in a markdown table format to make it easier to copy and paste.\\n\\n{marker_dict}\")\n\n\n\n\nTable¬†6.1: Estimating most likely cell type from Leiden clusters‚Äô marker gene rankings. Note: predictions were generated with the aid of an LLM.\n\n\n\n\n\n\n\n\n\n\n\n\nCluster\nInferred Cell Type\nConfidence\nTop 5 Key Markers\nBrief Justification\n\n\n\n\nC-0\nEpithelial (Goblet/Secretory)\nHigh\nPIGR, MUC2, EPCAM, KRT8, CLDN7\nExpresses broad epithelial markers (EPCAM, KRT8) alongside specific secretory/mucosal markers (PIGR, MUC2) typical of normal or well-differentiated colon epithelium.\n\n\nC-3\nPlasma Cells (IgG)\nHigh\nIGHG1, IGKC, MZB1, JCHAIN, XBP1\nDefined by very high expression of Immunoglobulin G heavy chains (IGHG1) and plasma cell maturation factors (MZB1, JCHAIN).\n\n\nC-4\nCAF\nHigh\nMMP14, MMP2, FN1, COL1A1, SPARC\nSpatially coincident with tumor. The high levels of matrix metalloproteinases (MMP14, MMP2) and Fibronectin (FN1) identify these as the activated myofibroblasts driving tumor desmoplasia.\n\n\nC-5\nUnclassified\nLow\nMPV17L, ZNF91, DUX4, CXCL8, USP17L\nLacks clear lineage markers (No EPCAM, CD45, or COL1A1).\n\n\nC-6\nImmune (Mixed)\nModerate\nKIR3DL1, CD79A, CSF2, CD53, RAG1\nContains conflicting a mix of immune markers: NK cell (KIR3DL1) and B cell (CD79A) markers appear together. Likely represents lymphoid aggregates.\n\n\nC-7\nEndothelial Cells\nHigh\nPECAM1, VWF, PLVAP, EGFL7, SHANK3\nDistinct expression of vascular endothelium markers, including PECAM1 (CD31) and VWF. PLVAP suggests fenestrated capillaries common in the gut.\n\n\nC-8\nPlasma Cells (IgA)\nHigh\nIGHA1, JCHAIN, IGKC, GRP, MZB1\nSimilar to C-3 but distinguished by the specific expression of IgA (IGHA1), the dominant isotype in mucosal immunity of the colon.\n\n\nC-9\nTumor Epithelial (Invasive)\nHigh\nCEACAM5, MMP7, LCN2, KRT8, CLDN4\nMalignant epithelial profile (EPCAM, KRT8) with high expression of tumor markers (CEACAM5/CEA) and invasion/stress markers (MMP7, LCN2).\n\n\nC-10\nStructural Fibroblasts \nHigh\nSFRP2, MGP, FBLN1, C3, CXCL12\nSpatially coincident with muscle (SMC). The profile (SFRP2+, MGP+, FBLN1+) matches ‚ÄúAdventitial‚Äù or ‚ÄúUniversal‚Äù fibroblasts that act as the structural scaffold for muscle layers and vessels.\n\n\nC-11\nTumor Epithelial (High Cycling)\nHigh\nRPS19, CEACAM5, EPCAM, RPS18, PIGR\nEpithelial tumor cells (CEACAM5) dominated by ribosomal proteins (RPS/RPL), indicating high protein synthesis and rapid cell cycling.\n\n\nC-12\nSmooth Muscle Cells\nHigh\nMYH11, ACTG2, DES, CNN1, MYLK\nExpression of contractile proteins (MYH11, ACTG2) and Desmin (DES) identifies these as mural smooth muscle cells (muscularis mucosae/propria).\n\n\nC-13\nEnteric Glia / Schwann Cells\nHigh\nCDH19, PMP22, SCN7A, LGI4, CLU\nPresence of peripheral nervous system markers (PMP22, CDH19, SCN7A) identifies these as supportive glial cells of the Enteric Nervous System.\n\n\nC-14\nPericytes\nHigh\nNOTCH3, PDGFRB, MCAM, COL4A1, RGS5\nExpresses pericyte markers (PDGFRB, MCAM, NOTCH3) and basement membrane collagen (COL4A1), distinguishing them from the broader fibroblast clusters.\n\n\n\n\n\n\nFollowing a little back and forth and helping provide the LLM with additional spatial context, we have the marker gene results in Table¬†6.1, we have most of the structural cell types identified from the remaining clusters. Cluster C-5 lacks a clear and dominant lineage signature. This cluster also occupies roughly the center of the UMAP where poorer quality cells sometimes occupy. For the purposes of this tutorial and the downstream questions, we‚Äôll leave those cells unclassified and label them as ‚Äúundetermined‚Äù. Similarly, cluster C-6 showed two distinct lienage markers for NK cells (KIR3DL1) and B cells (CD79A). Since these markers are unlikely to be present in the same cell it is likely that C-6 comprises a composite of NK and lymphoid cell types. Interestingly, HieraType did not classify the cells within as either NK or B cell. Since our primary interest are on tumor and CAFs, we‚Äôll not unravel this cluster any further and instead label it as a mix of cell types.\nFrom the HieraType-derived merged data, map these new cell type labels.\n\nremap = {\n    'C-0': 'epithelial',\n    'C-3': 'plasma_IgG',\n    'C-4': 'CAF',\n    'C-5': 'undetermined',\n    'C-6': 'mix_NK_Lymphoid',\n    'C-7': 'endothelial',\n    'C-8': 'plasma_IgA',\n    'C-9': 'tumor',\n    'C-10': 'fibroblast',\n    'C-11': 'tumor_cyling',\n    'C-12': 'smc',\n    'C-13': 'glial',\n    'C-14': 'pericyte'\n}\n\n\nadata.obs['celltype_fine'] = adata.obs['merged'].astype(str).replace(remap)\n\nOften we want to plot or work with broader classifications of cell types. The code below combines, for example, all the various T cell subtypes into a single group.\n\n\nPython Code\nbroad_map = {\n    'cd8_tem': 'tcell',\n    'cd4_treg': 'tcell',\n    'cd4_tem': 'tcell',\n    'cd8_cytotoxic': 'tcell',\n    'cd8_naive': 'tcell',\n    'cd8_exhausted': 'tcell',\n    'cd4_tcm': 'tcell',\n    'cd4_th2': 'tcell',\n    'cd4_th17': 'tcell',\n    'cd4_naive': 'tcell',\n    'cd4_th1': 'tcell',\n    'cd8_tcm': 'tcell',\n\n    'bcell': 'bcell',\n    'plasma_IgA': 'plasma',\n    'plasma_IgG': 'plasma',\n\n    'tumor': 'tumor',\n    'tumor_cyling': 'tumor',\n    'epithelial': 'epithelial',\n\n    'CAF': 'CAF',\n    'fibroblast': 'fibroblast',\n    'smc': 'smc',\n    'pericyte': 'pericyte',\n    'endothelial': 'endothelial',\n    'glial': 'glial',\n\n    'macrophage': 'macrophage',\n    'monocyte': 'monocyte',\n    'dendritic': 'dendritic',\n    'mast': 'mast',\n    'neutrophil': 'neutrophil',\n    'nk': 'nk',\n    'mix_NK_Lymphoid': 'mix_NK_Lymphoid',\n\n    'undetermined': 'undetermined'\n}\n\nadata.obs['celltype_broad'] = adata.obs['celltype_fine'].map(broad_map)\n\n\nWhich provides 18 broad cell types and 32 fine cell types.\nSave the results to disk.\n\n\nR Code\nfilename = os.path.join(r.analysis_dir, \"anndata-6-celltypes.h5ad\")\nadata.write_h5ad(\n  filename,\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Cell Typing</span>"
    ]
  },
  {
    "objectID": "cell-typing.html#cell-type-visualization",
    "href": "cell-typing.html#cell-type-visualization",
    "title": "6¬† Cell Typing",
    "section": "6.3 Cell Type Visualization",
    "text": "6.3 Cell Type Visualization\nIt is useful at this point to visualize the distributions of cells in a variety of ways to get an understanding of their composition. We can visualize these cell types in UMAP space and XY space.\n\n6.3.1 Broad cell types\nInstead of the default colors in plotDots, let‚Äôs create manual ones.\n\n\nR Code\n# define colors semi-manually instead of using the default colors\ncolumn &lt;- 'celltype_broad'\ncolumn_levels &lt;- levels(py$adata$obs[[column]])\nn_levels &lt;- length(column_levels)\n\nif(n_levels&lt;27){\n  colors_use &lt;- pals::alphabet(n_levels)\n} else if(n &lt; 53){\n  colors_use &lt;- c(pals::alphabet(26), pals::alphabet2(n_levels-26))\n} else {\n  stop(\"consider fewer groups\")\n}\n\nnames(colors_use) &lt;- column_levels\n\ncolors_use['mast'] = \"#FFCC99\"\ncolors_use['tumor'] = \"#C20088\"\ncolors_use['undetermined'] = \"#808080\"\ncolors_use['mix_NK_Lymphoid'] = \"#8080FF\"\n\n\n# saving colors for later\nresults_list[['celltype_broad_names']] &lt;- names(colors_use)\nresults_list[['celltype_broad_colors']] &lt;- as.character(colors_use)\nsaveRDS(results_list, results_list_file)\n\n\nPlot the cells in XY space and UMAP space and color based on celltype_broad.\n\n\nR Code\n1group_prefix &lt;- \"broad\"\n\nct_assets_dir &lt;- file.path(analysis_asset_dir, \"ct\")\n\n# XY (global only)\nplotDots(py$adata, color_by='celltype_broad',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n# XY (facets only)\nplotDots(py$adata, color_by='celltype_broad',\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 100,\n                  width = 5,\n                  height = 5,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n# UMAP (global only)\nplotDots(py$adata, \n              obsm_key = \"umap_pr\",\n              color_by='celltype_broad',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001, alpha=0.1\n                  ),\n                  geom_label_params = list(\n                    size = 2\n                  ),\n                  labels_on_plot = data.frame(),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8,\n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"UMAP 1\"),\n                ylab(\"UMAP 2\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                # guides(color = guide_legend(\n                #   title=\"Cell Type\",\n                #   override.aes = list(size = 3) ) ), \n                theme(legend.position = \"none\")\n              )\n            )\n\n# UMAP (facets only)\nplotDots(py$adata, \n              obsm_key = \"umap_pr\",\n              color_by='celltype_broad',\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001, alpha=0.1\n                  ),\n                  geom_label_params = list(\n                    size = 2\n                  ),\n                  labels_on_plot = data.frame(),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 100,\n                  width = 5,\n                  height = 5,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"UMAP 1\"),\n                ylab(\"UMAP 2\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n            )\n\n\n\n1\n\nin the plotting below, we will use this name to parse out files.\n\n\n\n\nHere are the overall (global) plots.\n\nCell Type Broad - UMAPCell Type Broad - XY\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.3: UMAP with broad cell type in the full dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.4: XY with broad cell type in the full dataset.\n\n\n\n\n\n\n\n\nAnd here are the facetted plots.\n\nCAFbcelldendriticendothelialepithelialfibroblastglialmacrophagemastmix_NK_Lymphoidmonocyteneutrophilnkpericyteplasmasmctcelltumorundetermined\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.3.2 Fine cell types\nThis section performs a similar routine as above but with the fine cell type classifications.\nFor the fine cell types, we‚Äôll create colors that are various shades of the parent type.\n\n\nR Code\nbroad_map &lt;- unlist(py$broad_map)\n\ngenerate_fine_colors &lt;- function(mapping, broad_colors, mode = \"shades\") {\n  groups &lt;- split(names(mapping), mapping)\n  fine_colors &lt;- c()\n  for (broad_name in names(groups)) {\n    subtypes &lt;- groups[[broad_name]]\n    n &lt;- length(subtypes)\n    base_col &lt;- broad_colors[broad_name]\n    if (n == 1) {\n      cols &lt;- base_col\n      names(cols) &lt;- subtypes\n    } else {\n      if (mode == \"shades\") {\n        ramp_func &lt;- colorRampPalette(c(\n          adjustcolor(base_col, transform=diag(c(1,1,1,1))*1.4), # Lighten\n          base_col,\n          adjustcolor(base_col, transform=diag(c(1,1,1,1))*0.6)  # Darken\n        ))\n        cols &lt;- ramp_func(n)\n      } else {\n        ramp_func &lt;- colorRampPalette(c(\"#FFFFFF\", base_col, \"#000000\"))\n        cols &lt;- ramp_func(n + 2)[2:(n + 1)]\n      }\n      names(cols) &lt;- subtypes\n    }\n    fine_colors &lt;- c(fine_colors, cols)\n  }\n  return(fine_colors)\n}\n\nfine_colors &lt;- generate_fine_colors(broad_map, colors_use)\n\nresults_list[['celltype_fine_names']] &lt;- names(fine_colors)\nresults_list[['celltype_fine_colors']] &lt;- as.character(fine_colors)\n\nsaveRDS(results_list, results_list_file)\n\n\n\n\nR Code\ngroup_prefix &lt;- \"fine\"\n\nct_assets_dir &lt;- file.path(analysis_asset_dir, \"ct\")\n\n# XY (global only)\nplotDots(py$adata, color_by='celltype_fine',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = fine_colors),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n# XY (facets only)\nplotDots(py$adata, color_by='celltype_fine',\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 100,\n                  width = 5,\n                  height = 5,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = fine_colors),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n# UMAP (global only)\nplotDots(py$adata, \n              obsm_key = \"umap_pr\",\n              color_by='celltype_fine',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001, alpha=0.1\n                  ),\n                  geom_label_params = list(\n                    size = 2\n                  ),\n                  labels_on_plot = data.frame(),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8,\n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"UMAP 1\"),\n                ylab(\"UMAP 2\"), \n                coord_fixed(),\n                scale_color_manual(values = fine_colors),\n                # guides(color = guide_legend(\n                #   title=\"Cell Type\",\n                #   override.aes = list(size = 3) ) ), \n                theme(legend.position = \"none\")\n              )\n            )\n\n# UMAP (facets only)\nplotDots(py$adata, \n              obsm_key = \"umap_pr\",\n              color_by='celltype_fine',\n              plot_global = FALSE,\n              facet_by_group = TRUE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001, alpha=0.1\n                  ),\n                  geom_label_params = list(\n                    size = 2\n                  ),\n                  labels_on_plot = data.frame(),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 100,\n                  width = 5,\n                  height = 5,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"UMAP 1\"),\n                ylab(\"UMAP 2\"), \n                coord_fixed(),\n                scale_color_manual(values = fine_colors),\n                guides(color = guide_legend(\n                  title=\"Cell Type\",\n                  override.aes = list(size = 3) ) )\n              )\n            )\n\n\n\nCell Type Fine - UMAPCell Type Fine - XY\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.5: UMAP with fine cell type labels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.6: XY with fine cell type labels.\n\n\n\n\n\n\n\n\nAnd here are the facetted plots.\n\nCAFbcellcd4_naivecd4_tcmcd4_temcd4_th1cd4_th17cd4_th2cd4_tregcd8_cytotoxiccd8_exhaustedcd8_naivecd8_tcmcd8_temdendriticendothelialepithelialfibroblastglialmacrophagemastmix_NK_Lymphoidmonocyteneutrophilnkpericyteplasma_IgAplasma_IgGsmctumortumor_cylingundetermined\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that within the SMC XY plots we can see an ‚Äúoutline‚Äù that appears to be the muscularis mucosa.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Cell Typing</span>"
    ]
  },
  {
    "objectID": "cell-typing.html#sec-integration",
    "href": "cell-typing.html#sec-integration",
    "title": "6¬† Cell Typing",
    "section": "6.4 Integration with Spatial Domains",
    "text": "6.4 Integration with Spatial Domains\nRecall in Chapter 5 that we used novae to define spatial domains. Now that we have cell type information, let‚Äôs look at the composition of cell types within each domain and assign a biological function to them.\nSince we only need the metadata associated with the spatial domain results, we‚Äôll only load the obs.\n\n\nPython Code\nfocal_domain_resolution = 'novae_domains_6'\n\nif 'adata_domains' not in dir():\n  filename = os.path.join(r.analysis_dir, \"anndata-3-novae.h5ad\")\n  adata_domains = ad.read_h5ad(filename, backed='r')\n\nmeta_domains = adata_domains.obs.copy()\ncolumns_to_copy = [focal_domain_resolution]\n\nadata.obs[columns_to_copy] = meta_domains[columns_to_copy]\n\n\nCreate a contingency table for the domain and cell type assignments.\n\n\nR Code\nfocal_domain_resolution &lt;- py$focal_domain_resolution\nfocal_celltype_resolution &lt;- \"celltype_fine\"\n\ndf &lt;- py$adata$obs %&gt;% select(\n    all_of(focal_domain_resolution), \n    all_of(focal_celltype_resolution))\n\nplot_data &lt;- df %&gt;% \n  group_by(.data[[focal_domain_resolution]], \n           .data[[focal_celltype_resolution]]) %&gt;% \n  summarise(count = n()) %&gt;% \n  mutate(proportion = count / sum(count))\n\n# Create the geom_tile plot\np &lt;- ggplot(plot_data, aes(x = .data[[focal_domain_resolution]],\n                           y = .data[[focal_celltype_resolution]], \n                           fill = proportion)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = paste0(round(100*proportion, 3), \"%\")), color = \"black\", size=2) +\n  scale_fill_gradient(low = \"white\", high = \"dodgerblue\") +  # Set color scale\n  labs(y = \"Cell Type\", x = \"Spatial Domain\", fill = \"Proportion\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\nggsave(p, filename = file.path(ct_dir, \"contingency_table.png\"), \n       width=5, height=7)\nwrite.table(plot_data, \"./tmp.csv\", col.names=T, row.names=F, quote=F)\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.7: The proportion of a given cell type found in each domain. For example, domain D1015 is comprised of 65.3% smooth muscle cells (SMCs).\n\n\n\n\n\nFrom this information and the spatial layout of domains we can assign a function names Table¬†6.2. Just looking at the composition, the differences between three of the domains (D1011, D1015, and D1016) appear to have varying degrees of tumor, cycling tumor, and CAFs. D1015 has relatively more CAFs so let‚Äôs call that a Desmoplastic Stroma domain and let‚Äôs label D1016, which has the highest concentration of tumor cells, the Tumor Core. D1011 has abundant tumor (cycling, specifically) and also 12% B cell and 20% (normal) epithelial cells. Spatially, D1011 occurs throughout lymphoid structures within the epithelium and around the tumor region (invasive margin).\n\n\n\nTable¬†6.2: Functional names associated with each novae domain.\n\n\n\n\n\n\n\n\n\n\nDomain\nInferred Biological Identity\nTop 3 Cell Types (Proportion)\n\n\n\n\nD1000\nNormal Mucosa\n1. epithelial (53.4%), 2. plasma_IgA (17.2%), 3. mix_NK_Lymphoid (6.8%)\n\n\nD1003\nMuscularis Layer\n1. smc (65.3%), 2. fibroblast (7.7%), 3. macrophage (6.2%)\n\n\nD1011\nInvasive Margin (Immune-Rich)\n1. epithelial (20.4%), 2. tumor_cyling (18.5%), 3. bcell (12.0%)\n\n\nD1015\nDesmoplastic Stroma\n1. CAF (34.7%), 2. tumor_cyling (11.6%), 3. monocyte (8.3%)\n\n\nD1016\nTumor Core\n1. tumor_cyling (31.8%), 2. CAF (22.2%), 3. tumor (15.4%)\n\n\nD1017\nHeterogeneous\n1. tumor_cyling (16.1%), 2. undetermined (12.2%), 3. epithelial (12.1%)\n\n\n\n\n\n\nLet‚Äôs add a new column in the metadata with these values.\n\n\nPython Code\ndomain_map = {\n    'D1000': 'Normal Mucosa',\n    'D1003': 'Muscularis Layer',\n    'D1011': 'Invasive Margin',\n    'D1015': 'Desmoplastic Stroma',\n    'D1016': 'Tumor Core',\n    'D1017': 'Heterogeneous'\n}\n\nadata.obs['annotated_domain'] = adata.obs[focal_domain_resolution].map(domain_map)\n\nfilename = os.path.join(r.analysis_dir, \"anndata-7-domain_annotations.h5ad\")\nadata.write_h5ad(\n  filename,\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)\n\n\nAnd while were at it, let‚Äôs plot the domains in XY space using plotDots with the new labels.\n\n\nR Code\ndomain_colors &lt;- results_list[['novae_model_1_domain_colors']]\nnames(domain_colors) &lt;- results_list[['novae_model_1_domain_names']]\n  \ndomain_map &lt;- py$domain_map\ndomain_map &lt;- data.frame('domain_id' = names(domain_map), \n                         'domain_description'=unlist(domain_map))\n\ndomain_colors &lt;- domain_colors[match(domain_map$domain_id, names(domain_colors))]\ndomain_map$domain_color &lt;- domain_colors\n\nresults_list[['domain_colors']] &lt;- domain_map\nsaveRDS(results_list, results_list_file)\n\ncolors_use &lt;- domain_map$domain_color\nnames(colors_use) &lt;- domain_map$domain_description\n\ngroup_prefix &lt;- \"annotated_domain\"\n\nplotDots(py$adata, color_by='annotated_domain',\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = ct_assets_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=group_prefix\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                scale_color_manual(values = colors_use),\n                theme(legend.position = c(0.8, 0.4)),\n                guides(color = guide_legend(\n                  title=\"Spatial Domain\",\n                  override.aes = list(size = 3) ) )\n              )\n              )\n\n\n\n\n\n\n\n\n\n\nFigure¬†6.8: XY with spatial domains.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Cell Typing</span>"
    ]
  },
  {
    "objectID": "cell-typing.html#conclusion",
    "href": "cell-typing.html#conclusion",
    "title": "6¬† Cell Typing",
    "section": "6.5 Conclusion",
    "text": "6.5 Conclusion\nWe have now mapped the cellular landscape of our tissue. By combining broad unsupervised clustering and the specialized HieraType algorithm, we have moved from a matrix of counts to a spatially annotated map. Then we used this information to create functional names to the domains that we found in Chapter 5.\nIt is important to recognize that this cell typing workflow is a foundational draft. Depending on your specific research questions, such as defining specialized epithelial cell types or mapping complex stromal niches, more advanced methods may be required.\nWith our cells now labeled with a type and a domain, we are ready to ask ‚Äútertiary‚Äù questions. At the moment, this includes an analysis on pathway enrichment but more analysis chapters are in the works.",
    "crumbs": [
      "Processing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Cell Typing</span>"
    ]
  },
  {
    "objectID": "pathways.html",
    "href": "pathways.html",
    "title": "7¬† Pathways",
    "section": "",
    "text": "7.1 Introduction\nIn the previous chapters, we defined ‚Äúwho‚Äù is in the tissue (cell types) and where they are located (spatial domains). The next logical step is to ask: ‚Äúwhat are they doing?‚Äù. This is a particularly exciting and open-ended question. Since we have access to the whole transcriptome, we can measure biological activity with unparalleled precision and down to the subcellular level, if desired.1\nPathway analysis allows us to move beyond simple identity markers to infer the active biological processes driving the tissue‚Äôs organization. For example, identifying a cell as a ‚Äúfibroblast‚Äù tells us its lineage, but pathway analysis tells us if that fibroblast is actively building scar tissue (TGF-\\(\\beta\\) signaling) or recruiting immune cells (NF-\\(\\kappa\\)B signaling).\nWhile we can measure thousands of pathways from any number of databases, in this primer we‚Äôll keep things tractable and estimate the activity of 14 cancer-relevant signaling pathways using the PROGENy1 database (see below).\nHere is our approach:\nThis workflow will allow us to answer questions like:",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#introduction",
    "href": "pathways.html#introduction",
    "title": "7¬† Pathways",
    "section": "",
    "text": "Smoothing: We will apply nearest neighbor smoothing to borrow information from similar cells, overcoming the sparsity of single-cell data.\nScoring: We will calculate an activity score for each pathway in every single cell using the python package decoupler2.\nInference: We will aggregate these scores by cell type and spatial domain to interpret signaling landscapes that define dominant biological programs and their spatial context within the tissue.\n\n\n\nIs the tumor driving angiogenesis, or is the stroma?\nWhich immune cells are actively inflamed versus suppressed?\nDoes the ‚ÄúDesmoplastic Stroma‚Äù domain have a distinct signaling signature?",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#processing",
    "href": "pathways.html#processing",
    "title": "7¬† Pathways",
    "section": "7.2 Processing",
    "text": "7.2 Processing\nRead the annData object.\n\nif 'adata' not in dir():\n  filename = os.path.join(r.analysis_dir, \"anndata-7-domain_annotations.h5ad\")\n  adata = ad.read_h5ad(filename)\n\n1adata.obsm['spatial'][:,1] *= -1\n\n\n1\n\nflipping the y-axis so that the tissue is in the same orientation as the rest of the analysis.\n\n\n\n\nWe‚Äôll use the PROGENy (Pathway RespOnsive GENes)1 database available within decoupler2 to estimate the single cell enrichment scores of each of the 14 cancer-relevant pathways and their significant values. PROGENy is a resource that estimates pathway activity by analyzing the downstream genes known to change in response to perturbation experiments across a wide variety of human cancer cell lines. I find that it is useful in a wide range of cancer samples but it might not be ideal for, say, transplant or viral infection samples.\nThe code below adapts decoupler‚Äôs tutorial which uses the univarte linear model method (ulm) function. PROGENy can provide a high-level overview of the tissue‚Äôs molecular functions distilled down to a handful of pathways ‚Äì which is relatively quick. For non-cancer systems, or if greater resolution is desired, other databases can be used with the ulm approach. If you are interested in exploring other databases within decoupler, run decoupler.op.show_resources().\nHere‚Äôs a description of those pathways from decoupler‚Äôs website.\n- Androgen: involved in the growth and development of the male reproductive organs.\n- EGFR: regulates growth, survival, migration, apoptosis, proliferation, and differentiation in mammalian cells\n- Estrogen: promotes the growth and development of the female reproductive organs.\n- Hypoxia: promotes angiogenesis and metabolic reprogramming when O2 levels are low.\n- JAK-STAT: involved in immunity, cell division, cell death, and tumor formation.\n- MAPK: integrates external signals and promotes cell growth and proliferation.\n- NFkB: regulates immune response, cytokine production and cell survival.\n- p53: regulates cell cycle, apoptosis, DNA repair and tumor suppression.\n- PI3K: promotes growth and proliferation.\n- TGFb: involved in development, homeostasis, and repair of most tissues.\n- TNFa: mediates haematopoiesis, immune surveillance, tumour regression and protection from infection.\n- Trail: induces apoptosis.\n- VEGF: mediates angiogenesis, vascular permeability, and cell migration.\n- WNT: regulates organ morphogenesis during development and tissue repair.\nLet‚Äôs load the PROGENy dataset.\n\n\nPython Code\nimport decoupler as dc\n\nprogeny = dc.op.progeny(organism='human', top=500, license=\"commercial\")\nprogeny_genes = progeny['target'].unique()\n\n\n\nresults_list['n_progeny_genes'] = length(py$progeny_genes)\nsaveRDS(results_list, results_list_file)\n\nFor the analysis below we‚Äôll need normalized data. As we saw in Chapter 4, we bypassed the creation of the dense Pearson Residuals normalization matrix and used the PCs instead for nearest neighbors calculations, Leiden, etc. The main reason for this was computational tractability (&gt;400,000 cells by ca. 19,000 targets). That issue is still present here. There are only 5276 genes in the pathway database that we chose and so we do not necessarily need to normalized the entire matrix. Scanpy has a method for Pearson Residuals normalization (sc.experimental.pp.normalize_pearson_residuals) but there‚Äôs a catch: ideally we would not run Pearson Normalization on a subset of features. Instead, we would like the non-truncated transcript totals to factor into the normalization procedure. We can achieve this by creating a custom code.\n\n\nPython Code\n# 1. Get valid genes\n# these are the ones that are in BOTH the progeny dataset and in the anndata, adata\nvalid_genes = [g for g in progeny_genes if g in adata.var_names]\n\n# 2. Get GLOBAL Stats (before subsetting)\ncounts_layer = adata.layers['counts'] if 'counts' in adata.layers else adata.X\nglobal_cell_sums = np.array(counts_layer.sum(axis=1)).flatten() # or just from nCount_RNA\ntotal_count = global_cell_sums.sum() # i.e., sum(obs$nCount_RNA)\n\n# 3. Get GENE Stats (Just for the subset is all that's necessary)\ngene_indices = [adata.var_names.get_loc(g) for g in valid_genes]\nsubset_gene_sums = np.array(counts_layer.sum(axis=0)).flatten()[gene_indices]\n\n# 4. Create the Subset\nadata_sub = adata[:, valid_genes].copy()\n# Ensure we are using raw counts for the calculation\nif 'counts' in adata_sub.layers:\n    adata_sub.X = adata_sub.layers['counts'].copy()\n\n# 5. Expected counts based on global depth (from the full dataset)\nmu = np.outer(global_cell_sums, subset_gene_sums) / total_count\n\n# Pearson Residuals: (Observed - Expected) / StdDev\ntheta = 100\nobserved = adata_sub.X.toarray()\nresiduals = (observed - mu) / np.sqrt(mu + mu**2 / theta)\n\n# Clip outliers (similar to what scanpy does)\nclip_val = np.sqrt(adata_sub.shape[0])\nresiduals = np.clip(residuals, -clip_val, clip_val)\n\n# 6. Save results\nadata_sub.X = residuals\ndel adata\nadata = adata_sub \n\n# Clean up\nimport gc\ndel adata_sub, mu, observed, residuals, global_cell_sums, subset_gene_sums\ngc.collect()\n\n\nAt this point the anndata object has many components that are not needed. Let‚Äôs reduce the size of this object to reduce the memory footprint.\n\n\nPython Code\n# Clean up obsm\nobsm_delete = ['X_pca_TC', 'counts_neg', 'counts_sys', 'umap_TC']\nfor x in obsm_delete:\n    if x in adata.obsm:\n        del adata.obsm[x]\n\n# Clean up obsp\nobsp_delete = ['neighbors_TC_connectivities', 'neighbors_TC_distances']\nfor x in obsp_delete:\n    if x in adata.obsp:\n        del adata.obsp[x]\n\ngc.collect()\n\n1adata.layers['pr_norm'] = adata.X.astype('float32').copy()\n\n\n\n1\n\nConvert from float 64 bit to float 32 bit Optional step for systems with less RAM.",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#smoothing-expression",
    "href": "pathways.html#smoothing-expression",
    "title": "7¬† Pathways",
    "section": "7.3 Smoothing Expression",
    "text": "7.3 Smoothing Expression\nOne attribute of all spatial single cell datasets relative to non-spatial method is sparsity. Even for technologies with high-sensitivity detection, individual cells may lack the detection of every transcript required to precisely score pathways. To overcome this, tools like decoupler and liana3 4 utilize smoothing ‚Äì a process of borrowing information from neighboring cells to impute missing values and stabilize pathway scores. However, the term ‚Äúneighbor‚Äù here can be ambiguous. Many of the existing tutorials for these tools were developed with spot-based technologies (like Visium) in mind where spatial smoothing is used because spots are already multi-cellular mixtures. For single-cell resolution data like CosMx SMI, the choice of using spatial smoothing depends on the types of biological questions you have Table¬†7.1. For pathway analysis, we recommend smoothing based on nearest expression neighbors (NN). Check back later when we release a chapter on ligand-receptor analysis for an example of spatial smoothing.\n\n\n\nTable¬†7.1: Two types of smoothing and when to use them.\n\n\n\n\n\nFeature\nNearest Expression Neighbors (NN)\nSpatial Neighbors (SN)\n\n\n\n\nDefinition\nAverages signal from cells with similar gene expression profiles (e.g., neighbors in PCA space).\nAverages signal from cells physically touching or near the target cell (XY space).\n\n\nPrimary Benefit\nPreserves Cell Identity. A T cell is smoothed with other T cells, maintaining lineage-specific signals.\nVisualizes Zones. Highlights continuous tissue gradients and regional (i.e., multiple domain) behaviors. Analyzing Larger Spatial Patterns When examining zonal, regional (e.g., hypoxia), or other larger effects, cells are responding by an interaction of their lineage and their spatial position. Spatial smoothing in this scenario can aid in quantifying the metabolic spatial neighborhood by denoising cells with sparse data. Ligand Receptor Analysis. While we might not want to spatially smooth a CD4 T cell with, say, a Tumor cell, for certain analyses, this computational approach can be effective in analyzing ligand-receptor relationships. Essentially, if we borrow the receptor expression of nearby cells, we can then test if that receptor is correlated with the focal cells‚Äô corresponding ligand receptor expression.\n\n\nDrawback\nMay erode any cell type by specific local/regional interaction effect.\nSignal Bleeding Can artificially blend high-expression markers (e.g., PTPRC) into neighboring negative cells (e.g., Tumor). Tuning The degree (e.g., radius, Gaussian kernel) that is used for spatial smoothing is a tuning parameter that, ideally, should align the observational scale with the functional scale.\n\n\nBest Use Case\nLineage-specific pathways (e.g., TCR signaling, Cell Cycle, B cell activation).\nEnvironmental gradients that occur at regional levels not captured by expression-based domain assignments (e.g., Hypoxia, Nutrient Deprivation, pH levels).\n\n\nExample\nSee Section 7.4 below\nSee upcoming ligand-receptor chapter (expected early 2026)\n\n\n\n\n\n\nLet‚Äôs apply nearest neighbor smoothing. Recall in Chapter 4 we created a neighbor graph based on pearson residuals PC values derived using the scPearsonPCA package. This produced the neighbors_pr_connectivities connectivity matrix in obsp. We‚Äôll use this to smooth our cells‚Äô expression.\n\n\nPython Code\nadata.layers['nn_smooth'] = adata.obsp['neighbors_pr_connectivities'] @ adata.layers['pr_norm']",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#sec-path-enrichment",
    "href": "pathways.html#sec-path-enrichment",
    "title": "7¬† Pathways",
    "section": "7.4 Pathway Enrichment",
    "text": "7.4 Pathway Enrichment\nRun the univariate linear model from decoupler using the PROGENy database with this smoothed expression matrix to generate pathway scores. Save the results.\n\n\nPython Code\ndc.mt.ulm(\n  data=adata, \n  net=progeny, \n  verbose=True, \n  layer=f'nn_smooth',\n  bsize=80000\n  )\n  \nfilename = os.path.join(r.analysis_dir, \"anndata-8-pathways-nn.h5ad\")\nadata.write_h5ad(\n  filename,\n  compression=hdf5plugin.FILTERS[\"zstd\"],\n  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n)",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#visualizing-pathway-enrichment",
    "href": "pathways.html#visualizing-pathway-enrichment",
    "title": "7¬† Pathways",
    "section": "7.5 Visualizing Pathway Enrichment",
    "text": "7.5 Visualizing Pathway Enrichment\nWe‚Äôll visualize the pathways ‚Äúlocally‚Äù on the tissue as well as ‚Äúglobally‚Äù by creating heatmaps per cell type and domain.\n\n7.5.1 Local: spatial visualizations\nThe local plots provide fine-resolution maps of pathway scores on the tissue. The simplest way to do this is to use scanpy‚Äôs pl.spatial method. If you want greater flexibility in the plotting aesthetics, we can use the plotDots function in R that we have used throughout this book. Below we‚Äôll show code and results for both approaches.\n\nUsing Scanpy‚Äôs built-in spatial plotting functionUsing plotDots in R\n\n\nWe can convert the scores themselves into a new annData object and then use scanpy‚Äôs functions to plot the individual pathways (features).\n\n\nPython Code\nsc.settings.figdir = r.pw_dir\nsc.settings.set_figure_params(dpi_save=200, frameon=False)\n\nnn_pwdata = dc.pp.get_obsm(adata=adata, key=f'score_ulm')\nnn_pwdata.obsm[f'padj_ulm'] = adata.obsm[f'padj_ulm']\n\nfor x in nn_pwdata.var_names:\n  sc.pl.spatial(\n      nn_pwdata,\n      color=[x],\n      cmap='RdBu_r',\n      vcenter=0,\n      size=1.5,\n      spot_size=0.01, show=False,\n      save=\"_nn_pathway_Scanpy_\" + str(x) + \"_xy.png\",\n      alpha_img=1\n  )\n\n\n\nPath: AndrogenPath: EGFRPath: EstrogenPath: HypoxiaPath: JAK-STATPath: MAPKPath: NFkBPath: PI3KPath: TGFbPath: TNFaPath: TrailPath: VEGFPath: WNTPath: p53\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.1: Local Androgen pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.2: Local EGFR pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.3: Local Estrogen pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.4: Local Hypoxia pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.5: Local JAK-STAT pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.6: Local MAPK pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.7: Local NFkB pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.8: Local PI3K pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.9: Local TGFb pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.10: Local TNFa pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.11: Local Trail pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.12: Local VEGF pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.13: Local WNT pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.14: Local p53 pathway scores plotted with sc.pl.spatial.\n\n\n\n\n\n\n\n\n\n\nThis block runs the plotDots function that we have used in previous chapters on the objects that we create in the previous subsection, nn_pwdata.\n\n\nR Code\n1py$nn_pwdata$obsm['spatial'][,2] &lt;- py$nn_pwdata$obsm['spatial'][,2] * -1\n\nfeatures &lt;- py$nn_pwdata$var_names$to_list()\n\nfor(feature in features){\n  plotDots(py$nn_pwdata, color_by=feature,\n              plot_global = TRUE,\n              facet_by_group = FALSE,\n              additional_plot_parameters = list(\n                  geom_point_params = list(\n                    size=0.001\n                  ),\n                  scale_bar_params = list(\n                    location = c(5, 0),\n                    width = 2,\n                    n = 3,\n                    height = 0.1,\n                    scale_colors = c(\"black\", \"grey30\"),\n                    label_nudge_y = -0.3\n                  ),\n                  directory = pw_dir,\n                  fileType = \"png\",\n                  dpi = 200,\n                  width = 8, \n                  height = 8,\n                  prefix=paste0(\"plotDots_\", feature)\n                ),\n              additional_ggplot_layers = list(\n                theme_bw(), \n                scale_color_gradient2(low = \"darkblue\", mid = \"white\", high = \"darkred\", midpoint = 0),\n                xlab(\"X (mm)\"),\n                ylab(\"Y (mm)\"), \n                coord_fixed(),\n                theme(legend.position = c(0.8, 0.4))\n              )\n              )\n}\n\n\n\n1\n\nFlipping the y-axis back.\n\n\n\n\n\nPath: AndrogenPath: EGFRPath: EstrogenPath: HypoxiaPath: JAK-STATPath: MAPKPath: NFkBPath: PI3KPath: TGFbPath: TNFaPath: TrailPath: VEGFPath: WNTPath: p53\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.15: Local Androgen pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.16: Local EGFR pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.17: Local Estrogen pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.18: Local Hypoxia pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.19: Local JAK-STAT pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.20: Local MAPK pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.21: Local NFkB pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.22: Local PI3K pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.23: Local TGFb pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.24: Local TNFa pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.25: Local Trail pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.26: Local VEGF pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.27: Local WNT pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.28: Local p53 pathway scores plotted with the plotDots function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 Global: Per Cell Type\nIn addition to plotting the local pathway scores in space with scanpy or plotDots, we can visualize the results summarized across each cell type or each domain. These next two subsections do just that. We‚Äôll use the plotting functionality within the complexHeatmap R package. It can be helpful to plot the average enrichment as well as the Z-scores. The former helps with us understand the overall sense of what is being enriched whereas the latter helps to compare a particular effect size relative to other cell types.\n\n\nR Code\ndf &lt;- py$nn_pwdata$obs %&gt;% select(cell_ID, celltype_broad, celltype_fine)\nexpr &lt;- py$nn_pwdata$X\ncolnames(expr) &lt;- py$nn_pwdata$var_names$to_list()\ndf &lt;- cbind(df, expr)\n\npathway_cols &lt;- setdiff(names(df), c(\"cell_ID\", \"celltype_broad\", \"celltype_fine\"))\nmin_obs = 50\n\nmean_enrich_by_ct &lt;- df %&gt;%\n  group_by(celltype_broad, celltype_fine) %&gt;%\n  summarise(\n    n = n(),\n    across(all_of(pathway_cols), mean, .names = \"{.col}_mean\"),\n    .groups = 'drop'\n  ) %&gt;% \n  filter(n &gt;= min_obs) %&gt;%\n  arrange(celltype_broad, celltype_fine)\n\nscaled_enrich_by_ct &lt;- mean_enrich_by_ct %&gt;%\n  mutate(across(ends_with(\"_mean\"), ~as.numeric(scale(.)))) %&gt;%\n  arrange(celltype_broad, celltype_fine)\n\ncelltype_broad_colors &lt;- results_list[['celltype_broad_colors']]\nnames(celltype_broad_colors) &lt;- results_list[['celltype_broad_names']]\n\ncelltype_fine_colors &lt;- results_list[['celltype_fine_colors']]\nnames(celltype_fine_colors) &lt;- results_list[['celltype_fine_names']]\n\n# Shared Row Annotation\nrow_ha &lt;- HeatmapAnnotation(\n  \"Cell Group\" = scaled_enrich_by_ct$celltype_broad,\n  \"Cell Type\" = scaled_enrich_by_ct$celltype_fine,\n  col = list(\n    \"Cell Group\" = celltype_broad_colors,\n    \"Cell Type\" = celltype_fine_colors\n  ),\n  show_legend = c(\"Cell Group\" = FALSE, \"Cell Type\" = FALSE),\n  which = \"row\"\n)\n\nzscore_col_fun &lt;- colorRamp2(c(-2, 0, 2), c(\"#2166AC\", \"white\", \"#B2182B\"))\n\nheatmap_matrix_z &lt;- scaled_enrich_by_ct %&gt;%\n  select(ends_with(\"_mean\")) %&gt;%\n  as.matrix()\nrownames(heatmap_matrix_z) &lt;- scaled_enrich_by_ct$celltype_fine\ncolnames(heatmap_matrix_z) &lt;- gsub(\"_mean\", \"\", colnames(heatmap_matrix_z))\n\nht_z &lt;- Heatmap(\n  heatmap_matrix_z,\n  name = \"Pathway Z-score\\n(Relative)\",\n  col = zscore_col_fun,\n  \n  left_annotation = row_ha,\n\n  show_row_names = TRUE,\n  row_names_gp = gpar(fontsize = 6),\n\n1  cluster_columns = FALSE,\n  column_names_gp = gpar(fontsize = 7),\n  row_split = scaled_enrich_by_ct$celltype_broad, \n  cluster_row_slices = TRUE,\n  cluster_rows = FALSE,\n  row_title_rot = 0,\n  row_title_gp = gpar(fontsize = 10)\n)\n\nsvglite::svglite(file.path(pw_dir, \"heatmap_by_cell_type_zscore.svg\"), width = 3.5, height = 6)\n  draw(\n    ht_z, \n    heatmap_legend_side = \"bottom\", \n    annotation_legend_side = \"bottom\",\n    merge_legend = TRUE\n  )\ndev.off()\n\npng(file.path(pw_dir, \"heatmap_by_cell_type_zscore.png\"), \n    width=4, height=8, res=350, units = \"in\", type = 'cairo')\n  draw(\n    ht_z, \n    heatmap_legend_side = \"bottom\", \n    annotation_legend_side = \"bottom\",\n    merge_legend = TRUE\n  )\ndev.off()\n\nheatmap_matrix_mean &lt;- mean_enrich_by_ct %&gt;%\n  select(ends_with(\"_mean\")) %&gt;%\n  as.matrix()\nrownames(heatmap_matrix_mean) &lt;- mean_enrich_by_ct$celltype_fine\ncolnames(heatmap_matrix_mean) &lt;- gsub(\"_mean\", \"\", colnames(heatmap_matrix_mean))\n\nquantile_limit &lt;- 0.95\nlimit &lt;- as.numeric(quantile(abs(as.vector(heatmap_matrix_mean)), quantile_limit, na.rm = TRUE))\nmean_col_fun &lt;- colorRamp2(c(-limit, 0, limit), c(\"#2166AC\", \"white\", \"#B2182B\"))\n\nht_mean &lt;- Heatmap(\n  heatmap_matrix_mean,\n  name = \"PROGENy Score\\n(Mean)\",\n  col = mean_col_fun,\n  \n  left_annotation = row_ha,\n\n  show_row_names = TRUE,\n  row_names_gp = gpar(fontsize = 6),\n\n  cluster_columns = FALSE, \n  column_names_gp = gpar(fontsize = 7),\n  row_split = mean_enrich_by_ct$celltype_broad, \n  cluster_row_slices = TRUE,\n  cluster_rows = FALSE,\n  row_title_rot = 0,\n  row_title_gp = gpar(fontsize = 10)\n)\n\nsvglite::svglite(file.path(pw_dir, \"heatmap_by_cell_type_mean.svg\"), width = 3.5, height = 6)\n  draw(\n    ht_mean, \n    heatmap_legend_side = \"bottom\", \n    annotation_legend_side = \"bottom\",\n    merge_legend = TRUE\n  )\ndev.off()\n\npng(file.path(pw_dir, \"heatmap_by_cell_type_mean.png\"), \n    width=4, height=8, res=350, units = \"in\", type = 'cairo')\n  draw(\n    ht_mean, \n    heatmap_legend_side = \"bottom\", \n    annotation_legend_side = \"bottom\",\n    merge_legend = TRUE\n  )\ndev.off()\n\n\n\n1\n\nSet to FALSE to make it easier to compare the mean and the Z-score heatmaps. Set to TRUE to make it easier to group similar pathway signatures.\n\n\n\n\n\nMeanZ-score\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.29: Average pathway enrichment scores by cell type.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.30: Average pathway enrichment scores (z-score) by cell type.\n\n\n\n\n\n\n\n\n\n\n7.5.3 Global: Per Domain\nThis follows a similar procedure as above but summarized across spatial domains.\n\n\nR Code\ndf &lt;- merge(df, py$nn_pwdata$obs %&gt;% select(cell_ID, annotated_domain), by=\"cell_ID\")\ndf &lt;- filter(df, !is.na(annotated_domain))\nmin_obs = 50\n\n# Calculate Mean Scores\nmean_enrich_by_domain &lt;- df %&gt;%\n  group_by(annotated_domain) %&gt;%\n  summarise(\n    n = n(),\n    across(all_of(pathway_cols), mean, .names = \"{.col}_mean\"),\n    .groups = 'drop'\n  ) %&gt;% \n  filter(n &gt;= min_obs, !is.na(annotated_domain)) %&gt;%\n  arrange(annotated_domain)\n\n# Calculate Z-scores (Scale the means)\nscaled_enrich_by_domain &lt;- mean_enrich_by_domain %&gt;%\n  mutate(across(ends_with(\"_mean\"), ~as.numeric(scale(.)))) %&gt;%\n  arrange(annotated_domain)\n\n# Colors\ndomain_colors_df  &lt;- results_list[['domain_colors']]\ndomain_colors &lt;- domain_colors_df$domain_color\nnames(domain_colors) &lt;- domain_colors_df$domain_description\n\n# Common Row Annotation\nrow_ha &lt;- HeatmapAnnotation(\n  \"Spatial Domain\" = mean_enrich_by_domain$annotated_domain,\n  col = list(\"Spatial Domain\" = domain_colors),\n  show_legend = c(\"Spatial Domain\" = FALSE),\n  which = \"row\"\n)\n\n# Color Functions\nzscore_col_fun &lt;- colorRamp2(c(-2, 0, 2), c(\"#2166AC\", \"white\", \"#B2182B\"))\n\n# Z-Score Heatmap\nheatmap_matrix_z &lt;- scaled_enrich_by_domain %&gt;%\n  select(ends_with(\"_mean\")) %&gt;%\n  as.matrix()\nrownames(heatmap_matrix_z) &lt;- scaled_enrich_by_domain$annotated_domain\ncolnames(heatmap_matrix_z) &lt;- gsub(\"_mean\", \"\", colnames(heatmap_matrix_z))\n\nht_z &lt;- Heatmap(\n  heatmap_matrix_z,\n  name = \"Pathway Z-score\\n(Relative)\",\n  col = zscore_col_fun,\n  left_annotation = row_ha,\n  show_row_names = TRUE,\n  row_names_gp = gpar(fontsize = 5.5),\n  cluster_columns = TRUE,\n  column_names_gp = gpar(fontsize = 5.5),\n  row_title_rot = 0,\n  row_title_gp = gpar(fontsize = 8)\n)\n\nsvglite::svglite(file.path(pw_dir, \"heatmap_by_domain_zscore.svg\"), width = 3.5, height = 3)\n  draw(ht_z, heatmap_legend_side = \"bottom\", annotation_legend_side = \"bottom\", merge_legend = TRUE)\ndev.off()\n\npng(file.path(pw_dir, \"heatmap_by_domain_zscore.png\"), width=3.5, height=3.5, res=350, units = \"in\", type = 'cairo')\n  draw(ht_z, heatmap_legend_side = \"bottom\", annotation_legend_side = \"bottom\", merge_legend = TRUE)\ndev.off()\n\n\n# Mean Score Heatmap\nheatmap_matrix_mean &lt;- mean_enrich_by_domain %&gt;%\n  select(ends_with(\"_mean\")) %&gt;%\n  as.matrix()\nrownames(heatmap_matrix_mean) &lt;- mean_enrich_by_domain$annotated_domain\ncolnames(heatmap_matrix_mean) &lt;- gsub(\"_mean\", \"\", colnames(heatmap_matrix_mean))\n\nquantile_limit &lt;- 0.95\nlimit &lt;- as.numeric(quantile(abs(as.vector(heatmap_matrix_mean)), quantile_limit, na.rm = TRUE))\nmean_col_fun &lt;- colorRamp2(c(-limit, 0, limit), c(\"#2166AC\", \"white\", \"#B2182B\"))\n\nht_mean &lt;- Heatmap(\n  heatmap_matrix_mean,\n  name = \"PROGENy Score\\n(Mean)\",\n  col = mean_col_fun,\n  left_annotation = row_ha,\n  show_row_names = TRUE,\n  row_names_gp = gpar(fontsize = 5.5),\n  cluster_columns = TRUE, \n  column_names_gp = gpar(fontsize = 5.5),\n  row_title_rot = 0,\n  row_title_gp = gpar(fontsize = 8)\n)\n\nsvglite::svglite(file.path(pw_dir, \"heatmap_by_domain_mean.svg\"), width = 3.5, height = 3)\n  draw(ht_mean, heatmap_legend_side = \"bottom\", annotation_legend_side = \"bottom\", merge_legend = TRUE)\ndev.off()\n\npng(file.path(pw_dir, \"heatmap_by_domain_mean.png\"), width=3.5, height=3.5, res=350, units = \"in\", type = 'cairo')\n  draw(ht_mean, heatmap_legend_side = \"bottom\", annotation_legend_side = \"bottom\", merge_legend = TRUE)\ndev.off()\n\n\n\nMeanZ-score\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.31: Average pathway enrichment scores by spatial domain. Colors correspond to domains in Figure¬†6.8. Note: columns were clustered and so will have a difference order than that found in Figure¬†7.32.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.32: Average pathway enrichment scores (z-score) by spatial domain. Colors correspond to domains in Figure¬†6.8. Note: columns were clustered and so will have a difference order than that found in Figure¬†7.31.\n\n\n\n\n\n\n\n\nExamining and comparing the spatial plots in Section 7.5.1 with the global heatmaps Figure¬†7.29, Figure¬†7.30, Figure¬†7.31, and Figure¬†7.32 reveals several findings in this tissue.\nFor example:\n\nIn the tumor cells we see little enrichment of the pro-apoptotic TRAIL pathway (mean = 0.0; Z-score = -1.1) but high EGFR enrichment (mean = 2.6; Z-score = 3.7), a pattern associated with increased cell invasion and metastasis5.\nTumor cells are likely a ‚ÄúCMS4‚Äù or mesenchymal colon cancer phenotype. The three signatures of this phenotype are ‚Äòprominent transforming growth factor‚ÄìŒ≤ activation, stromal invasion and angiogenesis‚Äô6. Looking at growth regulation, tumor cells themsevles show little enrichment of TGF-\\(\\beta\\) (mean = -2.3; Z-score = -0.85); however, the CAFs show the highest levels in the dataset (mean = 7.0; Z-score = 3.9). This pattern mirrors the TGF-\\(\\beta\\) exclusion phenotype described in the literature, where stromal activation drives poor prognosis in colon cancer7 8. For stromal invasion, we can see from the spatial plots both at the cell type-level Figure¬†6.4 and the domain-level (Figure¬†6.8) that CAFs and tumors are found in interdigitated domains. And finally, we found a signature of angiogenesis in tumor cells and tumor and stromal domains with the enrichment of VEGF9.\nThere is a strong enrichment of TNF-\\(\\alpha\\) and NF-\\(\\kappa\\)B on the left side of the tissue that is still unresolved. The left side of the tissue is part of the ‚ÄúHeterogeneous‚Äù spatial domain that is found throughout (Chapter 5) that contains a high proportion of undetermined cell types (Figure¬†6.7). Perhaps a follow up analysis would include isolating the cells within this ‚Äúsub-domain‚Äù to understand which cells might be driving the reduction of apoptosis and preventing an effective immune response. This could be done with lasso selecting the region (see our blog post on lasso selecting with napari).",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#summary",
    "href": "pathways.html#summary",
    "title": "7¬† Pathways",
    "section": "7.6 Summary",
    "text": "7.6 Summary\nIn this chapter, we showed a simple nearest-neighbor smoothing technique and scored pathways using one of the available databases (PROGENy; for others see decoupler.op.show_resources()). Then we showed a few ways to pivot the data and visualize the local scores or global aggregates these scores across cell types and spatial domains to guide our inference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Schubert, M. et al. Perturbation-response genes reveal signaling footprints in cancer gene expression. Nature communications 9, (2018).\n\n\n2. Badia-i-Mompel, P. et al. decoupleR: Ensemble of computational methods to infer biological activities from omics data. Bioinformatics Advances https://doi.org/https://doi.org/10.1093/bioadv/vbac016 (2022) doi:https://doi.org/10.1093/bioadv/vbac016.\n\n\n3. Dimitrov, D. et al. Comparison of methods and resources for cell-cell communication inference from single-cell RNA-Seq data. Nat. Commun. 13, 3224 (2022).\n\n\n4. Dimitrov, D. et al. LIANA+ provides an all-in-one framework for cell-cell communication inference. Nat. Cell Biol. 26, 1613‚Äì1622 (2024).\n\n\n5. Sasaki, T., Hiroki, K. & Yamashita, Y. The role of epidermal growth factor receptor in cancer metastasis and microenvironment. Biomed Res. Int. 2013, 546318 (2013).\n\n\n6. Guinney, J. et al. The consensus molecular subtypes of colorectal cancer. Nat. Med. 21, 1350‚Äì1356 (2015).\n\n\n7. Calon, A. et al. Stromal gene expression defines poor-prognosis subtypes in colorectal cancer. Nat. Genet. 47, 320‚Äì329 (2015).\n\n\n8. Ma, M. et al. Prognostic implications and therapeutic opportunities related to CAF subtypes in CMS4 colorectal cancer: Insights from single-cell and bulk transcriptomics. Apoptosis 30, 826‚Äì841 (2025).\n\n\n9. Duffy, A. M., Bouchier-Hayes, D. J. & Harmey, J. H. Vascular endothelial growth factor (VEGF) and its role in non-endothelial cells: Autocrine signalling by VEGF. in VEGF and cancer 133‚Äì144 (Springer US, Boston, MA, 2004).",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "pathways.html#footnotes",
    "href": "pathways.html#footnotes",
    "title": "7¬† Pathways",
    "section": "",
    "text": "To keep this primer clear and tractable, we‚Äôll focus on a smaller pathway database at the single-cell level.‚Ü©Ô∏é",
    "crumbs": [
      "Tertiary Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pathways</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "8¬† Conclusion",
    "section": "",
    "text": "We embarked on this analysis with a stream of millions of RNA transcripts suspended in space. Through rigorous Data Wrangling and Quality Control, we filtered this raw signal to establish a reliable foundation for discovery. In Pre-processing, we navigated the high-dimensional feature space, reducing the data to reveal the underlying biological structure\nWe then labeled our cells, assigning them to Spatial Domains using novae and defining their Cell Types using a combination of Leiden clustering and HieraType. Just as literal rocket ships are specialized vehicles designed to explore the cosmos, the analysis methods we selected were specialized vehicles for this data. Throughout this guide, we prioritized methods fit for direct hybridization data‚Äîsuch as FOV QC, Novae, and HieraType‚Äîrather than applying legacy tools designed for amplification-based technologies.\nYet, our spatial journey has only just begun. So far in this workflow, we have explored Pathway Enrichment within the context of spatial domains. Other tertiary analyses such as ligand-receptor, differential expression, or trajectory inference will be the subject of future chapters in this work, so please check back often.\nIt is important to highlight that the field of spatial biology is a frontier that is actively expanding. As algorithms improve and new tools emerge, the methods detailed here will undoubtedly evolve. For now, I hope that you have gained a suite of tools and tips to navigate your own discoveries.",
    "crumbs": [
      "Conclusion",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Additonal Resources",
    "section": "",
    "text": "Information from Posit on how to use python within Rstudio: https://posit.co/blog/three-ways-to-program-in-python-with-rstudio/\nTo learn about using R and python in Quarto: https://www.r-bloggers.com/2023/01/combining-r-and-python-with-reticulate-and-quarto/\nThe specific version of python I used was 3.10.18 using pyenv.",
    "crumbs": [
      "Additonal Resources"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "1. Dimitrov, D. et al.\nLIANA+ provides an all-in-one framework for cell-cell\ncommunication inference. Nat. Cell Biol. 26,\n1613‚Äì1622 (2024).\n\n\n2. Dimitrov, D. et al. Comparison of\nmethods and resources for cell-cell communication inference from\nsingle-cell RNA-Seq data. Nat. Commun.\n13, 3224 (2022).\n\n\n3. Guinney, J. et al. The consensus\nmolecular subtypes of colorectal cancer. Nat. Med.\n21, 1350‚Äì1356 (2015).\n\n\n4. Calon, A. et al. Stromal gene\nexpression defines poor-prognosis subtypes in colorectal cancer.\nNat. Genet. 47, 320‚Äì329 (2015).\n\n\n5. Sasaki, T., Hiroki, K. & Yamashita, Y. The\nrole of epidermal growth factor receptor in cancer metastasis and\nmicroenvironment. Biomed Res. Int. 2013,\n546318 (2013).\n\n\n6. Ma,\nM. et al. Prognostic\nimplications and therapeutic opportunities related to CAF subtypes in\nCMS4 colorectal cancer: Insights from single-cell and bulk\ntranscriptomics. Apoptosis 30, 826‚Äì841\n(2025).\n\n\n7. Hafemeister, C. & Satija, R. Normalization\nand variance stabilization of single-cell RNA-seq data using regularized negative binomial\nregression. Genome Biol. 20, 296 (2019).\n\n\n8. Blampey, Q., Benkirane, H., Bercovici, N.,\nAndre, F. & Cournede, P.-H. Novae: A graph-based foundation model\nfor spatial transcriptomics data. 2024.09.09.612009 (2024) doi:10.1101/2024.09.09.612009.\n\n\n9. Duffy, A. M., Bouchier-Hayes, D. J. &\nHarmey, J. H. Vascular endothelial growth factor (VEGF) and\nits role in non-endothelial cells: Autocrine signalling by\nVEGF. in VEGF and cancer 133‚Äì144\n(Springer US, Boston, MA, 2004).\n\n\n10. Marconato, L. et al.\nSpatialData: An open and universal data framework for\nspatial omics. Nat. Methods 22, 58‚Äì62\n(2025).\n\n\n11. Palla, G. et al. Squidpy: A scalable\nframework for spatial omics analysis. Nat. Methods\n19, 171‚Äì178 (2022).\n\n\n12. Hao, Y. et al. Dictionary learning for\nintegrative, multimodal and scalable single-cell analysis. Nat.\nBiotechnol. 42, 293‚Äì304 (2024).\n\n\n13. Barrett, T. et al. Data.table:\nExtension of ‚ÄòData.frame‚Äò. (2025).\n\n\n14. Ushey, K. & Wickham, H. Renv: Project\nEnvironments. (2024). doi:10.32614/CRAN.package.renv.\n\n\n15. Lander, E. S. et al. Initial\nsequencing and analysis of the human genome. Nature\n409, 860‚Äì921 (2001).\n\n\n16. Ushey, K., Allaire, J. & Tang, Y. Reticulate:\nInterface to ‚ÄôPython‚Äô. (2025).\n\n\n17. Virshup, I., Rybakov, S., Theis, F. J.,\nAngerer, P. & Wolf, F. A. Anndata: Access and store\nannotated data matrices. Journal of Open Source Software\n9, 4371 (2024).\n\n\n18. Wolf, F. A., Angerer, P. & Theis, F. J.\nSCANPY: Large-scale single-cell gene expression data\nanalysis. Genome Biol. 19, (2018).\n\n\n19. Wickham, H. et al. Welcome to the tidyverse. Journal of Open Source\nSoftware 4, 1686 (2019).\n\n\n20. He,\nS. et al. High-plex imaging of RNA and proteins at\nsubcellular resolution in fixed tissue by spatial molecular imaging.\nNat. Biotechnol. 40, 1794‚Äì1806 (2022).\n\n\n21. The\nR-WASM Team. quarto-live: WebAssembly powered code blocks and\nexercises for R and Python in Quarto. (2024).\n\n\n22. Schubert, M. et al.\nPerturbation-response genes reveal signaling footprints in cancer gene\nexpression. Nature communications 9,\n(2018).\n\n\n23. Badia-i-Mompel, P. et al. decoupleR:\nEnsemble of computational methods to infer biological activities from\nomics data. Bioinformatics Advances https://doi.org/https://doi.org/10.1093/bioadv/vbac016\n(2022) doi:https://doi.org/10.1093/bioadv/vbac016.",
    "crumbs": [
      "References"
    ]
  }
]