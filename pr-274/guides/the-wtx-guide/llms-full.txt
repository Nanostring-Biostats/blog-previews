# Full Text of Project
> Auto-generated context for LLMs.



====================
START OF FILE: cell-typing.html
====================

Okay, let’s chart the course for this crucial phase of our analysis expedition: cell typing. This is where we assign identities to the cell clusters discovered in the previous chapter, transforming abstract groups into recognizable biological entities like T cells, macrophages, or tumor cells.

If pre-processing was about plotting our trajectory through high-dimensional space, cell typing is akin to navigating a dense asteroid field. It’s a critical step, but one fraught with potential obstacles. Assigning definitive labels can be challenging, often requiring careful consideration of marker genes and existing biological knowledge. What constitutes a “correct” cell type label can even be subjective, depending entirely on the resolution needed for your specific biological questions. Are you aiming to distinguish broad categories like “immune” versus “tumor,” or do you need to pinpoint specific T cell subtypes? Like adjusting a microscope’s focus, the level of detail required dictates the approach. Navigating this field requires careful maneuvering and the right instruments. Autopilot hasn’t been invented just yet and so the best recommendation need manual input.

One common hazard is attempting to directly apply analysis pipelines designed for spatially-dissociated scRNA-seq. While scRNA-seq vignettes offer valuable starting points, CosMx SMI data, generated by direct 
in situ
 hybridization, has fundamentally different characteristics. Simply copy-pasting scRNA-seq methods without adaptation can lead to suboptimal or incomplete cell type assignments. Instead, we must employ or adapt methods that leverage the strengths of high-plex, direct hybridization data to achieve reliable annotations. In doing so it’s possible to achieve the most comprehensive and biologically-rich cell typing and sub-typing possible in spatial transcriptomics.

It’s also crucial to remember that cell typing, while essential, isn’t the final destination of our journey. It’s a powerful tool for organizing our cellular map, allowing us to ask spatially-aware questions. However, other organizational frameworks, such as classifying cells based on their spatial neighborhood or “niche,” are equally important for understanding the tissue’s complex ecosystem.

In this chapter, we will navigate the cell typing process in the colon dataset. The main goal is to generate cell type labels that are “close” while also being approachable. I’ll begin (
Section 6.1
) by surveying some of the spatially unaware methods and then summarize the state of the direct hybridization-inspired approaches. Then I will guide you through the specific, hybrid workflow used for this colon dataset. We will start with the broad Leiden clusters defined in the previous chapter, refine them based on spatial observations, and assign primary identities using marker gene analysis. Finally, for the more complex immune populations where standard clustering often struggles, we will employ HieraType, a probabilistic method explicitly designed to handle the specific characteristics of CosMx SMI data.

R code

```
source("./preamble.R")
reticulate::source_python("./preamble.py")
analysis_dir <- file.path(getwd(), "analysis_results")
input_dir <- file.path(analysis_dir, "input_files")
output_dir <- file.path(analysis_dir, "output_files")
analysis_asset_dir <- "./assets/analysis_results"
ct_dir <- file.path(output_dir, "ct")
if(!dir.exists(ct_dir)){
  dir.create(ct_dir, recursive = TRUE)
}
results_list_file = file.path(analysis_dir, "results_list.rds")
if(!file.exists(results_list_file)){
  results_list <- list()
  saveRDS(results_list, results_list_file)
} else {
  results_list <- readRDS(results_list_file)  
}

library(scales)
library(Matrix)
source("./helpers.R")
```

6.1
 Cell Typing Approaches

6.1.1
 Non-spatial Cell Typing Approaches

Before discussing spatially-aware or technology-specific approaches, let’s briefly cover common methods designed for non-spatial, single-cell RNA sequencing analysis. These techniques primarily leverage the gene expression matrix (
adata.X
 and normalized layers) and the cluster assignments (e.g., 
adata.obs['leiden']
) derived in the previous chapter. Many excellent vignettes exist for these methods in popular frameworks like scanpy (Python) and Seurat (R), providing a rough “10,000-foot view” of the data’s cellular composition.

Cluster Marker Gene Identification (Leiden/Louvain):
 This is often a foundational step in scRNA-seq. After obtaining clusters (like the Leiden clusters from 
Chapter 4
), differential expression tests are performed between each cluster and all other cells (or between pairs of clusters). This identifies genes significantly upregulated within a specific cluster. Tools like scanpy’s 
rank_genes_groups
 or Seurat’s 
FindMarkers
 are standard. The resulting lists of marker genes are then manually compared against known canonical markers from literature or cell atlases to assign putative cell type identities (e.g., observing high 
CD3E
, 
CD8A
 suggests a T cell cluster; high 
EPCAM
, 
KRT19
 suggests epithelial cells). While effective, this relies heavily on prior biological knowledge and the quality of the initial clustering. It also assumes that transcripts found in the cell do not arise from any spatial co-localization or imperfect cell-cell segmentation boundaries that can arise when assigning transcripts to cells.

Nested / Hierarchical Clustering Analysis:
 Sometimes, broad initial clusters (like “Immune Cells” or “Fibroblasts”) contain sub-populations that are meaningful for your analysis. A common refinement is then to subset the data to include only cells from a specific Leiden cluster (or set of clusters) and then re-run the clustering process within that subset. Identifying marker genes for these sub-clusters can reveal finer cell types or states (
e.g.
, distinguishing CD4+ from CD8+ T cells, or identifying different fibroblast subtypes. This iterative approach allows for a hierarchical understanding of cell identity; however, the imperfect segmentation noted above is amplified in this approach. Consider a workflow where one uses HVGs to create an initial set of “Elementary” clusters and uses a marker gene-based approach to label these broad clusters. When subsetting down to, say, fibroblasts and rerunning the above HVG -> Leiden -> marker gene workflow, one may get non-fibroblast marker genes returned. The reason for this is twofold. First the general fibroblast marker genes are no longer as differentially expressed in the subset of Fibroblasts as they were in the full data and 2) if there are cell segmentation errors of fibroblast sub-populations that are spatially-associated with unrelated cell types – like plasma cells – the HVG algorithm may identify spurious gene markers as highly variable. The result would be markers like 
JCHAIN
 in fibroblasts that happen to be located near a germinal center, tertiary lymphoid structure, or similar. Thus, while this nested approach can be valuable, it should be used with caution.

Reference-Based Annotation:
 Instead of relying solely on 
de novo
 marker finding, many methods leverage existing annotated single-cell datasets (atlases) as references. These algorithms typically project the query data onto the reference or use statistical models trained on the reference to directly assign cell type labels to your individual cells or clusters. Popular tools include:

scanpy.tl.ingest
: Integrates query data onto an existing annotated AnnData object.

Seurat’s 
FindTransferAnchors
 and 
TransferData
: A widely used method in the R ecosystem.

InSituType’s fully supervised method: InSituType – while designed for spatial data – can be used as a fully supervised classifier. I’m including it here since many reference datasets and atlases at the time of writing are based on scRNA-seq data.

6.1.2
 Spatially-Informed and Hybridization-Aware Methods

Unlike standard scRNA-seq workflows, these approaches leverage the unique features of 
in situ
 data: specifically the spatial coordinates, the negative probe background, and the available protein data.

Background-Aware Modeling
. Methods like 
InSituType
 explicitly model the background noise using the negative control probes. This allows for more accurate classification of cells with low transcript counts that might be discarded or misclassified by standard scRNA-seq tools

Spatial-Molecular Joint Inference
. Tools like 
Banksy
 utilize the expression of a cell’s physical neighbors to inform its identity. This leverages the biological reality that cells of the same type often cluster spatially, helping to smooth out technical noise in individual cells.

Multi-modal Integration
. CosMx SMI often includes protein markers (e.g., CD45, PanCK) in the form of IF markers or – more recently – with true RNA and protein same-slide multiomics. “Dual-mode” typing strategies use these robust protein signals to define major lineages (e.g., “This cell is definitely CD45+ Immune”) before using the RNA data to determine the specific subtype (e.g., “It is a CD8+ T Cell”). Similarly, 
HieraType
 is a new R package for supervised classification that can combine multi-omics information to cell type. HieraType also classifies RNA-only data (as we’ll see below).

Reference-Based Annotation:
 Reference profiles based on CosMx SMI can be used to more quickly cell type new datasets. This approach can be much faster than cell typing 
de novo
 but requires such annotations to be available.

6.2
 Cell Type Determination

Just like there are many paths through an asteroid field, there are many ways to navigate cell typing. I find the following approach makes a good starting place for any analysis as it’s relatively fast while still allowing for human intervention.

Use Leiden clusters identified in 
Chapter 4
 as the basis. 1.1. 
Optional
: refine Leiden clusters based on discovered biology. For example, there may be some Leiden clusters that makes sense to merge together or some evidence that splitting a Leiden cluster into two or splitting a given Leiden cluster into multiple sub-clusters based on the spatial layout of cells.

Run HieraType to classify cells and use its integration function to merge its supervised classifications with the unsupervised Leiden clusters.

Of the remaining unclassified cells, use marker genes to infer the most likely cell type.

6.2.1
 Step 1: Read Leiden clusters

Load the data and make a copy of the 
leiden_pr
 metadata column that we’ll use.

Python Code

```
adata = ad.read_h5ad(os.path.join(r.analysis_dir, "anndata-2-leiden.h5ad"))

cluster_renaming = {}
initial = "C"
for name in adata.obs['leiden_pr'].unique():
  cluster_renaming[name] = f"{initial}-{name}"
adata.obs['leiden'] = adata.obs['leiden_pr'].map(cluster_renaming)
```

6.2.2
 Step 2: Run HieraType

Install the HieraType package (and remotes), if needed. Then extract the lists of marker genes.

R Code

```
install.packages("mvtnorm")

remotes::install_github("Nanostring-Biostats/CosMx-Analysis-Scratch-Space",
                         subdir = "_code/HieraType", ref = "Main")

library(HieraType)

markerg <- unlist(lapply(c(
  HieraType::markerslist_l1
  ,HieraType::markerslist_immune
  ,HieraType::markerslist_cd8tminor
  ,HieraType::markerslist_cd4tminor
  ,HieraType::markerslist_tcellmajor
), "[[", "predictors"))

marker_genes <- as.character(markerg)
```

Convert data to R.

Python Code

```
total_counts_per_cell = adata.layers['counts'].sum(axis=1)
total_counts_per_cell = np.asarray(total_counts_per_cell).flatten()

total_counts_per_target = adata.layers['counts'].sum(axis=0)
total_counts_per_target = np.asarray(total_counts_per_target).flatten()

target_frequencies = total_counts_per_target / total_counts_per_target.sum()

# Include all HVGs and marker genes (even if not in the HVGs)
marker_genes = r.marker_genes
marker_mask = adata.var.index.isin(marker_genes)
highly_variable_mask = adata.var['highly_variable'].to_numpy()
adata.var['hieratype_target'] = (highly_variable_mask | marker_mask)

adata_ht = adata[:, adata.var.hieratype_target].copy()
1ht_counts = adata_ht.layers['counts'].copy().astype(np.int64)
```

1

In order to use this matrix in R, we need to convert the 32 bit integer counts into 64 bit integers.

Follow 
this tutorial
 to refine Leiden clusters with immune cells.

R Code

```
ht_counts <- py$ht_counts
rownames(ht_counts) <- py$adata_ht$obs_names$to_list()
colnames(ht_counts) <- py$adata_ht$var_names$to_list()
ht_counts <- as(ht_counts, "CsparseMatrix")

pca_embeddings <- py$adata_ht$obsm['X_pca_pr'] # n_cells x n_pcs

target_frequencies <- py$target_frequencies 
names(target_frequencies) <- py$adata$var_names$to_list()
target_frequencies <- target_frequencies[colnames(ht_counts)] 

total_counts_per_cell <- py$total_counts_per_cell

# Assumes this was based on cosine.
sim_graph <- py$adata_ht$obsp['neighbors_pr_connectivities']
sim_graph <- as(sim_graph, "CsparseMatrix")
rownames(sim_graph) <- colnames(sim_graph) <- rownames(ht_counts)
```

Run the pipeline.

R Code

```
pipeline <- HieraType::make_pipeline(
  markerslists = list(
    "l1" = HieraType::markerslist_multiomic_l1
    ,"l2" = HieraType::markerslist_multiomic_immune
    ,"lt" = HieraType::markerslist_multiomic_tcellmajor
    ,"lt4minor" = HieraType::markerslist_multiomic_cd4tminor
    ,"lt8minor" = HieraType::markerslist_multiomic_cd8tminor
  )
  ,priors = list(
    "l2" = "l1"
    ,"lt" = "l2"
    ,"lt4minor" = "lt"
    ,"lt8minor" = "lt"
  )
  ,priors_category = list(
    "l2" = "immune"
    ,"lt" = "tcell"
    ,"lt4minor" = "cd4t"
    ,"lt8minor" = "cd8t"
  )
)

rnactobj <- HieraType::run_pipeline(
  pipeline = pipeline,
  counts_matrix = ht_counts,
  adjacency_matrix = sim_graph[rownames(ht_counts), rownames(ht_counts)],
  totalcounts = total_counts_per_cell,
  gene_wise_frequency = target_frequencies
)
saveRDS(rnactobj, file=file.path(ct_dir, "rnactobj.rds"))
```

Merge the Leiden cluster calls with the HieraType results. There are several ways we could do this but for this tutorial we’ll use HieraType’s built-in 
celltype_label_integration
 function using the default parameters. 
celltype_label_integration
 integrates the immune celltype annotations from HieraType with unsupervised cluster labels. The goal of this step is to enable granular detection of novel or tissue-specific cell types (unsupervised), along with well known immune cell types (HieraType). The logic for merging these annotations works like this:

All cells which are annotated with an immune-celltype HieraType label keep their label.

All cells with a non-immune HieraType label take the unsupervised cluster label.

Unsupervised clusters that had a high rate of cells taking immune labels (say 90%), and make up only a small proportion of all cells (say 1%) after step 1 are ‘dissolved’. These dissoved cells are assigned the most common cluster label (could be immune or unsupervised) amongst most the similar neighboring cells. Here we used the neighbor cells from the adjacency matrix that was used to run HieraType.

R Code

```
cell_type_dt <- rnactobj$post_probs$l1
1cell_type_dt <- rename(cell_type_dt, cell_id = cell_ID,
                       Hieratype_celltype_fine = celltype_granular)

to_merge <- py$adata$obs %>% select(leiden)

cell_type_dt$Leiden <- to_merge$leiden[match(rownames(to_merge), cell_type_dt$cell_id)]

cell_type_dt <- celltype_label_integration(
  metadata = cell_type_dt, 
  adjacency_mat = sim_graph[rownames(ht_counts), rownames(ht_counts)],
  cellid_colname = 'cell_id',
  supervised_colname = 'Hieratype_celltype_fine',
  unsupervised_colname = 'Leiden')

cell_type_dt <- rename(cell_type_dt, merged = celltype)

saveRDS(cell_type_dt, file=file.path(ct_dir, "cell_type_dt.rds"))
```

1

cell_id here is the row name from the anndata object (as opposed to the c_i_j_k cell_ID notation that is sometimes used).

Save the new calumns back to the anndata object.

Python Code

```
cell_type_df = r.cell_type_dt

adata.obs = adata.obs.join(cell_type_df[['cell_id', 'Hieratype_celltype_fine', 'merged']].set_index('cell_id'))
```

6.2.3
 Step 3: Classify remaining cells using marker genes

For the cells still assigned a Leiden cluster label, run a marker gene analysis to determine the dominant cell type per cluster. We’ll subset larger clusters down to 10,000 cells to speed up the computation. Since scanpy’s 
tl.rank_genes_groups
 function needs normalizaed data, we’ll use the log1p-transformed matrix that we generated in 
Chapter 4
.

```
bdata = adata[adata.obs['leiden']==adata.obs['merged'], :].copy()

random_seed = 98103
np.random.seed(random_seed)

target_cells_per_cluster = 10000
cells_to_keep_indices = []
cluster_counts = bdata.obs['merged'].value_counts()

for cluster_label in cluster_counts.index:
    cluster_cells = bdata.obs_names[bdata.obs['merged'] == cluster_label]
    num_cells_in_cluster = len(cluster_cells)

    if num_cells_in_cluster > target_cells_per_cluster:
        print(f"Cluster '{cluster_label}' has {num_cells_in_cluster} cells, subsampling to {target_cells_per_cluster}.")
        subsampled_cells = np.random.choice(
            cluster_cells,
            size=target_cells_per_cluster,
            replace=False
        )
        cells_to_keep_indices.extend(subsampled_cells)
    else:
      cells_to_keep_indices.extend(cluster_cells)

bdata_subsampled = bdata[cells_to_keep_indices, :].copy()

1bdata_subsampled.X = bdata_subsampled.layers['TC'].copy()
```

1

If you do not have the log1p-transformed total counts layer ‘TC’ saved, run 
sc.pp.normalize_total
 and 
sc.pp.log1p
 (see 
?sec-tc-workflow
).

Run 
rank_genes_groups
 and save results.

```
ct_dir = r.ct_dir
sc.settings.figdir = ct_dir

sc.tl.rank_genes_groups(bdata_subsampled, 'leiden', method='wilcoxon',
  solver='saga', max_iter=200, pts=True) # ~an hour using logreg
sc.pl.rank_genes_groups(bdata_subsampled, n_genes=8, sharey=True, fontsize=10, save="_marker_gene_ranks_global.png")
sc.pl.rank_genes_groups_dotplot(bdata_subsampled, n_genes=8, save="_marker_gene_dotplot_global.png")

filename = os.path.join(r.analysis_dir, "anndata-5-subset-marker-genes.h5ad")

bdata_subsampled.write_h5ad(
  filename,
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

The next task is determine from the marker gene results the dominant cell types that are likely found within each Leiden cluster. While some Leiden clusters will have a high proportion of cells that are of the same type or state, keep in mind that other Leiden clusters might be composites of cell types. The tools we have for this exercise are:

visual aids from the marker gene results and

compare with external sources. The literature and subject matter expertise is the gold-standard for this.

Figure 6.1: Marker gene ranks by Leiden cluster (global).

Figure 6.2: Marker gene dot plot by Leiden cluster (global).

Examine the clusters by extracting the top 25 markers and their relative scores and comparing to the literature. Large Language Models can provide supportive information here but it’s always recommended to use LLMs with caution and to verify any of the results. In other words, LLMs can be fast but at the cost of accuracy. In the example below, I created an LLM prompt that includes the top marker gene statistics. Let’s see what it generates.

```
marker_dict, marker_df = format_ranked_genes(bdata_subsampled, 25)

csv_file_path = os.path.join(ct_dir, "colon_cancer_top_marker_genes_global.csv")
marker_df.to_csv(csv_file_path, index=True)

print(f"I am analyzing a CosMx SMI dataset of from Colon cancer and have run Leiden clustering.\nI have already classified several of the immune cells within the larger dataset and now I would like your help in predicting the most like cell type given the marker gene profile from this subset of data.\nBelow is a dictionary of results where the key represents the Leiden cluster\nname and its corresponding item is a list of ordered tuples where each tuple\nprovides the marker name and the relative score for that marker.\n\n Please provide a table with the columns that represent 1. inferred cell type 2. your confidence in that cell type 3. up to five markers from the list that are key to your result and 4. a brief justification of your result. Please present the results in a markdown table format to make it easier to copy and paste.\n\n{marker_dict}")
```

Table 6.1: Estimating most likely cell type from Leiden clusters’ marker gene rankings. Note: predictions were generated with the aid of an LLM.

Cluster

Inferred Cell Type

Confidence

Top 5 Key Markers

Brief Justification

C-0

Epithelial (Goblet/Secretory)

High

PIGR, MUC2, EPCAM, KRT8, CLDN7

Expresses broad epithelial markers (
EPCAM, KRT8
) alongside specific secretory/mucosal markers (
PIGR, MUC2
) typical of normal or well-differentiated colon epithelium.

C-3

Plasma Cells (IgG)

High

IGHG1, IGKC, MZB1, JCHAIN, XBP1

Defined by very high expression of Immunoglobulin G heavy chains (
IGHG1
) and plasma cell maturation factors (
MZB1, JCHAIN
).

C-4

CAF

High

MMP14, MMP2, FN1, COL1A1, SPARC

Spatially coincident with tumor. The high levels of matrix metalloproteinases (MMP14, MMP2) and Fibronectin (FN1) identify these as the activated myofibroblasts driving tumor desmoplasia.

C-5

Unclassified

Low

MPV17L, ZNF91, DUX4, CXCL8, USP17L

Lacks clear lineage markers (No 
EPCAM, CD45,
 or 
COL1A1
).

C-6

Immune (Mixed)

Moderate

KIR3DL1, CD79A, CSF2, CD53, RAG1

Contains conflicting a mix of immune markers: NK cell (
KIR3DL1
) and B cell (
CD79A
) markers appear together. Likely represents lymphoid aggregates.

C-7

Endothelial Cells

High

PECAM1, VWF, PLVAP, EGFL7, SHANK3

Distinct expression of vascular endothelium markers, including 
PECAM1
 (CD31) and 
VWF
. 
PLVAP
 suggests fenestrated capillaries common in the gut.

C-8

Plasma Cells (IgA)

High

IGHA1, JCHAIN, IGKC, GRP, MZB1

Similar to C-3 but distinguished by the specific expression of IgA (
IGHA1
), the dominant isotype in mucosal immunity of the colon.

C-9

Tumor Epithelial (Invasive)

High

CEACAM5, MMP7, LCN2, KRT8, CLDN4

Malignant epithelial profile (
EPCAM, KRT8
) with high expression of tumor markers (
CEACAM5/CEA
) and invasion/stress markers (
MMP7, LCN2
).

C-10

Structural Fibroblasts 

High

SFRP2, MGP, FBLN1, C3, CXCL12

Spatially coincident with muscle (SMC). The profile (SFRP2+, MGP+, FBLN1+) matches “Adventitial” or “Universal” fibroblasts that act as the structural scaffold for muscle layers and vessels.

C-11

Tumor Epithelial (High Cycling)

High

RPS19, CEACAM5, EPCAM, RPS18, PIGR

Epithelial tumor cells (
CEACAM5
) dominated by ribosomal proteins (
RPS/RPL
), indicating high protein synthesis and rapid cell cycling.

C-12

Smooth Muscle Cells

High

MYH11, ACTG2, DES, CNN1, MYLK

Expression of contractile proteins (
MYH11, ACTG2
) and Desmin (
DES
) identifies these as mural smooth muscle cells (muscularis mucosae/propria).

C-13

Enteric Glia / Schwann Cells

High

CDH19, PMP22, SCN7A, LGI4, CLU

Presence of peripheral nervous system markers (
PMP22, CDH19, SCN7A
) identifies these as supportive glial cells of the Enteric Nervous System.

C-14

Pericytes

High

NOTCH3, PDGFRB, MCAM, COL4A1, RGS5

Expresses pericyte markers (
PDGFRB, MCAM, NOTCH3
) and basement membrane collagen (
COL4A1
), distinguishing them from the broader fibroblast clusters.

Following a little back and forth and helping provide the LLM with additional spatial context, we have the marker gene results in 
Table 
6.1
, we have most of the structural cell types identified from the remaining clusters. Cluster C-5 lacks a clear and dominant lineage signature. This cluster also occupies roughly the center of the UMAP where poorer quality cells sometimes occupy. For the purposes of this tutorial and the downstream questions, we’ll leave those cells unclassified and label them as “undetermined”. Similarly, cluster C-6 showed two distinct lienage markers for NK cells (
KIR3DL1
) and B cells (
CD79A
). Since these markers are unlikely to be present in the same cell it is likely that C-6 comprises a composite of NK and lymphoid cell types. Interestingly, HieraType did not classify the cells within as either NK or B cell. Since our primary interest are on tumor and CAFs, we’ll not unravel this cluster any further and instead label it as a mix of cell types.

From the HieraType-derived merged data, map these new cell type labels.

```
remap = {
    'C-0': 'epithelial',
    'C-3': 'plasma_IgG',
    'C-4': 'CAF',
    'C-5': 'undetermined',
    'C-6': 'mix_NK_Lymphoid',
    'C-7': 'endothelial',
    'C-8': 'plasma_IgA',
    'C-9': 'tumor',
    'C-10': 'fibroblast',
    'C-11': 'tumor_cyling',
    'C-12': 'smc',
    'C-13': 'glial',
    'C-14': 'pericyte'
}

adata.obs['celltype_fine'] = adata.obs['merged'].astype(str).replace(remap)
```

Often we want to plot or work with broader classifications of cell types. The code below combines, for example, all the various T cell subtypes into a single group.

Python Code

```
broad_map = {
    'cd8_tem': 'tcell',
    'cd4_treg': 'tcell',
    'cd4_tem': 'tcell',
    'cd8_cytotoxic': 'tcell',
    'cd8_naive': 'tcell',
    'cd8_exhausted': 'tcell',
    'cd4_tcm': 'tcell',
    'cd4_th2': 'tcell',
    'cd4_th17': 'tcell',
    'cd4_naive': 'tcell',
    'cd4_th1': 'tcell',
    'cd8_tcm': 'tcell',

    'bcell': 'bcell',
    'plasma_IgA': 'plasma',
    'plasma_IgG': 'plasma',

    'tumor': 'tumor',
    'tumor_cyling': 'tumor',
    'epithelial': 'epithelial',

    'CAF': 'CAF',
    'fibroblast': 'fibroblast',
    'smc': 'smc',
    'pericyte': 'pericyte',
    'endothelial': 'endothelial',
    'glial': 'glial',

    'macrophage': 'macrophage',
    'monocyte': 'monocyte',
    'dendritic': 'dendritic',
    'mast': 'mast',
    'neutrophil': 'neutrophil',
    'nk': 'nk',
    'mix_NK_Lymphoid': 'mix_NK_Lymphoid',

    'undetermined': 'undetermined'
}

adata.obs['celltype_broad'] = adata.obs['celltype_fine'].map(broad_map)
```

Which provides 18 broad cell types and 32 fine cell types.

Save the results to disk.

R Code

```
filename = os.path.join(r.analysis_dir, "anndata-6-celltypes.h5ad")
adata.write_h5ad(
  filename,
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

6.3
 Cell Type Visualization

It is useful at this point to visualize the distributions of cells in a variety of ways to get an understanding of their composition. We can visualize these cell types in UMAP space and XY space.

6.3.1
 Broad cell types

Instead of the default colors in 
plotDots
, let’s create manual ones.

R Code

```
# define colors semi-manually instead of using the default colors
column <- 'celltype_broad'
column_levels <- levels(py$adata$obs[[column]])
n_levels <- length(column_levels)

if(n_levels<27){
  colors_use <- pals::alphabet(n_levels)
} else if(n < 53){
  colors_use <- c(pals::alphabet(26), pals::alphabet2(n_levels-26))
} else {
  stop("consider fewer groups")
}

names(colors_use) <- column_levels

colors_use['mast'] = "#FFCC99"
colors_use['tumor'] = "#C20088"
colors_use['undetermined'] = "#808080"
colors_use['mix_NK_Lymphoid'] = "#8080FF"

# saving colors for later
results_list[['celltype_broad_names']] <- names(colors_use)
results_list[['celltype_broad_colors']] <- as.character(colors_use)
saveRDS(results_list, results_list_file)
```

Plot the cells in XY space and UMAP space and color based on 
celltype_broad
.

R Code

```
1group_prefix <- "broad"

ct_assets_dir <- file.path(analysis_asset_dir, "ct")

# XY (global only)
plotDots(py$adata, color_by='celltype_broad',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
              )

# XY (facets only)
plotDots(py$adata, color_by='celltype_broad',
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 100,
                  width = 5,
                  height = 5,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
              )

# UMAP (global only)
plotDots(py$adata, 
              obsm_key = "umap_pr",
              color_by='celltype_broad',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001, alpha=0.1
                  ),
                  geom_label_params = list(
                    size = 2
                  ),
                  labels_on_plot = data.frame(),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8,
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("UMAP 1"),
                ylab("UMAP 2"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                # guides(color = guide_legend(
                #   title="Cell Type",
                #   override.aes = list(size = 3) ) ), 
                theme(legend.position = "none")
              )
            )

# UMAP (facets only)
plotDots(py$adata, 
              obsm_key = "umap_pr",
              color_by='celltype_broad',
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001, alpha=0.1
                  ),
                  geom_label_params = list(
                    size = 2
                  ),
                  labels_on_plot = data.frame(),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 100,
                  width = 5,
                  height = 5,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("UMAP 1"),
                ylab("UMAP 2"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
            )
```

1

in the plotting below, we will use this name to parse out files.

Here are the overall (global) plots.

Cell Type Broad - UMAP
Cell Type Broad - XY

Figure 6.3: UMAP with broad cell type in the full dataset.

Figure 6.4: XY with broad cell type in the full dataset.

And here are the facetted plots.

CAF
bcell
dendritic
endothelial
epithelial
fibroblast
glial
macrophage
mast
mix_NK_Lymphoid
monocyte
neutrophil
nk
pericyte
plasma
smc
tcell
tumor
undetermined

6.3.2
 Fine cell types

This section performs a similar routine as above but with the fine cell type classifications.

For the fine cell types, we’ll create colors that are various shades of the parent type.

R Code

```
broad_map <- unlist(py$broad_map)

generate_fine_colors <- function(mapping, broad_colors, mode = "shades") {
  groups <- split(names(mapping), mapping)
  fine_colors <- c()
  for (broad_name in names(groups)) {
    subtypes <- groups[[broad_name]]
    n <- length(subtypes)
    base_col <- broad_colors[broad_name]
    if (n == 1) {
      cols <- base_col
      names(cols) <- subtypes
    } else {
      if (mode == "shades") {
        ramp_func <- colorRampPalette(c(
          adjustcolor(base_col, transform=diag(c(1,1,1,1))*1.4), # Lighten
          base_col,
          adjustcolor(base_col, transform=diag(c(1,1,1,1))*0.6)  # Darken
        ))
        cols <- ramp_func(n)
      } else {
        ramp_func <- colorRampPalette(c("#FFFFFF", base_col, "#000000"))
        cols <- ramp_func(n + 2)[2:(n + 1)]
      }
      names(cols) <- subtypes
    }
    fine_colors <- c(fine_colors, cols)
  }
  return(fine_colors)
}

fine_colors <- generate_fine_colors(broad_map, colors_use)

results_list[['celltype_fine_names']] <- names(fine_colors)
results_list[['celltype_fine_colors']] <- as.character(fine_colors)

saveRDS(results_list, results_list_file)
```

R Code

```
group_prefix <- "fine"

ct_assets_dir <- file.path(analysis_asset_dir, "ct")

# XY (global only)
plotDots(py$adata, color_by='celltype_fine',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = fine_colors),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
              )

# XY (facets only)
plotDots(py$adata, color_by='celltype_fine',
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 100,
                  width = 5,
                  height = 5,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = fine_colors),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
              )

# UMAP (global only)
plotDots(py$adata, 
              obsm_key = "umap_pr",
              color_by='celltype_fine',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001, alpha=0.1
                  ),
                  geom_label_params = list(
                    size = 2
                  ),
                  labels_on_plot = data.frame(),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8,
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("UMAP 1"),
                ylab("UMAP 2"), 
                coord_fixed(),
                scale_color_manual(values = fine_colors),
                # guides(color = guide_legend(
                #   title="Cell Type",
                #   override.aes = list(size = 3) ) ), 
                theme(legend.position = "none")
              )
            )

# UMAP (facets only)
plotDots(py$adata, 
              obsm_key = "umap_pr",
              color_by='celltype_fine',
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001, alpha=0.1
                  ),
                  geom_label_params = list(
                    size = 2
                  ),
                  labels_on_plot = data.frame(),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 100,
                  width = 5,
                  height = 5,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("UMAP 1"),
                ylab("UMAP 2"), 
                coord_fixed(),
                scale_color_manual(values = fine_colors),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
            )
```

Cell Type Fine - UMAP
Cell Type Fine - XY

Figure 6.5: UMAP with fine cell type labels.

Figure 6.6: XY with fine cell type labels.

And here are the facetted plots.

CAF
bcell
cd4_naive
cd4_tcm
cd4_tem
cd4_th1
cd4_th17
cd4_th2
cd4_treg
cd8_cytotoxic
cd8_exhausted
cd8_naive
cd8_tcm
cd8_tem
dendritic
endothelial
epithelial
fibroblast
glial
macrophage
mast
mix_NK_Lymphoid
monocyte
neutrophil
nk
pericyte
plasma_IgA
plasma_IgG
smc
tumor
tumor_cyling
undetermined

Note that within the SMC XY plots we can see an “outline” that appears to be the muscularis mucosa.

6.4
 Integration with Spatial Domains

Recall in 
Chapter 5
 that we used 
novae
 to define spatial domains. Now that we have cell type information, let’s look at the composition of cell types within each domain and assign a biological function to them.

Since we only need the metadata associated with the spatial domain results, we’ll only load the obs.

Python Code

```
focal_domain_resolution = 'novae_domains_6'

if 'adata_domains' not in dir():
  filename = os.path.join(r.analysis_dir, "anndata-3-novae.h5ad")
  adata_domains = ad.read_h5ad(filename, backed='r')

meta_domains = adata_domains.obs.copy()
columns_to_copy = [focal_domain_resolution]

adata.obs[columns_to_copy] = meta_domains[columns_to_copy]
```

Create a contingency table for the domain and cell type assignments.

R Code

```
focal_domain_resolution <- py$focal_domain_resolution
focal_celltype_resolution <- "celltype_fine"

df <- py$adata$obs %>% select(
    all_of(focal_domain_resolution), 
    all_of(focal_celltype_resolution))

plot_data <- df %>% 
  group_by(.data[[focal_domain_resolution]], 
           .data[[focal_celltype_resolution]]) %>% 
  summarise(count = n()) %>% 
  mutate(proportion = count / sum(count))

# Create the geom_tile plot
p <- ggplot(plot_data, aes(x = .data[[focal_domain_resolution]],
                           y = .data[[focal_celltype_resolution]], 
                           fill = proportion)) +
  geom_tile(color = "white") +
  geom_text(aes(label = paste0(round(100*proportion, 3), "%")), color = "black", size=2) +
  scale_fill_gradient(low = "white", high = "dodgerblue") +  # Set color scale
  labs(y = "Cell Type", x = "Spatial Domain", fill = "Proportion") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

ggsave(p, filename = file.path(ct_dir, "contingency_table.png"), 
       width=5, height=7)
write.table(plot_data, "./tmp.csv", col.names=T, row.names=F, quote=F)
```

Figure 6.7: The proportion of a given cell type found in each domain. For example, domain D1015 is comprised of 65.3% smooth muscle cells (SMCs).

From this information and the spatial layout of domains we can assign a function names 
Table 
6.2
. Just looking at the composition, the differences between three of the domains (D1011, D1015, and D1016) appear to have varying degrees of tumor, cycling tumor, and CAFs. D1015 has relatively more CAFs so let’s call that a Desmoplastic Stroma domain and let’s label D1016, which has the highest concentration of tumor cells, the Tumor Core. D1011 has abundant tumor (cycling, specifically) and also 12% B cell and 20% (normal) epithelial cells. Spatially, D1011 occurs throughout lymphoid structures within the epithelium and around the tumor region (invasive margin).

Table 6.2: Functional names associated with each 
novae
 domain.

Domain

Inferred Biological Identity

Top 3 Cell Types (Proportion)

D1000

Normal Mucosa

1. epithelial (53.4%), 2. plasma_IgA (17.2%), 3. mix_NK_Lymphoid (6.8%)

D1003

Muscularis Layer

1. smc (65.3%), 2. fibroblast (7.7%), 3. macrophage (6.2%)

D1011

Invasive Margin (Immune-Rich)

1. epithelial (20.4%), 2. tumor_cyling (18.5%), 3. bcell (12.0%)

D1015

Desmoplastic Stroma

1. CAF (34.7%), 2. tumor_cyling (11.6%), 3. monocyte (8.3%)

D1016

Tumor Core

1. tumor_cyling (31.8%), 2. CAF (22.2%), 3. tumor (15.4%)

D1017

Heterogeneous

1. tumor_cyling (16.1%), 2. undetermined (12.2%), 3. epithelial (12.1%)

Let’s add a new column in the metadata with these values.

Python Code

```
domain_map = {
    'D1000': 'Normal Mucosa',
    'D1003': 'Muscularis Layer',
    'D1011': 'Invasive Margin',
    'D1015': 'Desmoplastic Stroma',
    'D1016': 'Tumor Core',
    'D1017': 'Heterogeneous'
}

adata.obs['annotated_domain'] = adata.obs[focal_domain_resolution].map(domain_map)

filename = os.path.join(r.analysis_dir, "anndata-7-domain_annotations.h5ad")
adata.write_h5ad(
  filename,
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

And while were at it, let’s plot the domains in XY space using 
plotDots
 with the new labels.

R Code

```
domain_colors <- results_list[['novae_model_1_domain_colors']]
names(domain_colors) <- results_list[['novae_model_1_domain_names']]
  
domain_map <- py$domain_map
domain_map <- data.frame('domain_id' = names(domain_map), 
                         'domain_description'=unlist(domain_map))

domain_colors <- domain_colors[match(domain_map$domain_id, names(domain_colors))]
domain_map$domain_color <- domain_colors

results_list[['domain_colors']] <- domain_map
saveRDS(results_list, results_list_file)

colors_use <- domain_map$domain_color
names(colors_use) <- domain_map$domain_description

group_prefix <- "annotated_domain"

plotDots(py$adata, color_by='annotated_domain',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = ct_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Spatial Domain",
                  override.aes = list(size = 3) ) )
              )
              )
```

Figure 6.8: XY with spatial domains.

6.5
 Conclusion

We have now mapped the cellular landscape of our tissue. By combining broad unsupervised clustering and the specialized HieraType algorithm, we have moved from a matrix of counts to a spatially annotated map. Then we used this information to create functional names to the domains that we found in 
Chapter 5
.

It is important to recognize that this cell typing workflow is a foundational draft. Depending on your specific research questions, such as defining specialized epithelial cell types or mapping complex stromal niches, more advanced methods may be required.

With our cells now labeled with a type and a domain, we are ready to ask “tertiary” questions. At the moment, this includes an analysis on pathway enrichment but more analysis chapters are in the works.


====================
START OF FILE: conclusion.html
====================

We embarked on this analysis with a stream of millions of RNA transcripts suspended in space. Through rigorous Data Wrangling and Quality Control, we filtered this raw signal to establish a reliable foundation for discovery. In Pre-processing, we navigated the high-dimensional feature space, reducing the data to reveal the underlying biological structure

We then labeled our cells, assigning them to Spatial Domains using 
novae
 and defining their Cell Types using a combination of Leiden clustering and HieraType. Just as literal rocket ships are specialized vehicles designed to explore the cosmos, the analysis methods we selected were specialized vehicles for this data. Throughout this guide, we prioritized methods fit for direct hybridization data—such as FOV QC, Novae, and HieraType—rather than applying legacy tools designed for amplification-based technologies.

Yet, our spatial journey has only just begun. So far in this workflow, we have explored Pathway Enrichment within the context of spatial domains. Other tertiary analyses such as ligand-receptor, differential expression, or trajectory inference will be the subject of future chapters in this work, so please check back often.

It is important to highlight that the field of spatial biology is a frontier that is actively expanding. As algorithms improve and new tools emerge, the methods detailed here will undoubtedly evolve. For now, I hope that you have gained a suite of tools and tips to navigate your own discoveries.


====================
START OF FILE: data-ingestion.html
====================

R code

```
source("./preamble.R")
reticulate::source_python("./preamble.py")
analysis_dir <- file.path(getwd(), "analysis_results")
input_dir <- file.path(analysis_dir, "input_files")
output_dir <- file.path(analysis_dir, "output_files")
1analysis_asset_dir <- "./assets/analysis_results"
qc_dir <- file.path(output_dir, "output_files")
if(!dir.exists(qc_dir)){
  dir.create(qc_dir, recursive = TRUE)
}
results_list_file = file.path(analysis_dir, "results_list.rds")
if(!file.exists(results_list_file)){
  results_list <- list()
  saveRDS(results_list, results_list_file)
} else {
  results_list <- readRDS(results_list_file)  
}
```

1

This puts select images into the projects assets directory in enhance portability.

No data analysis journey can truly begin without first converting 
something
 and our task for this chapter is simple: take the flat files that are exported from AtoMx SIP into a usable format. That format is primarily python’s anndata format but, interestingly enough, we’ll take advantage of R’s 
data.table
1
 package to efficiently read in the expression matrix file. I find this is much faster than reading in the expression matrix into pandas.

Alternative Approach

While this chapter focusing on converting the flat files into anndata format, it skips over other types of data that we can convert and use – such as the imaging data. Both Squidpy
2
 and SpatialData
3
 offer ways to include composite images[^these are single images per FOV that combine the various IF channels together] into anndata objects. One limitation of these approaches – at the time of writing – is that they treat each FOV separately making it difficult to view results when you working with several hundred FOVs. For a tutorial on how to visualize the per-channel images across the entire sample with Napari, see this 
Scratch Space Blog
. 
 In addition to processing and analyzing with python, R offers ways to analyze CosMx SMI data using packages like 
Seurat
4
. For an example on how to use Seurat for visualization, see Claire William’s 
Blog post
 and other vignettes.

Split the expression data into targets, negatives, and system controls. Read in the metadata and add columns that represent the slide position in micrometers.

```
tmp_dir <- "./tmp_dir"
1dir.create(tmp_dir, showWarnings = FALSE)
flat_file_dir <- file.path(input_dir, "Run_b8806732_S2_Colon")
expression_dt <- data.table::fread(
  file.path(flat_file_dir, "S0_exprMat_file.csv.gz"),
  tmpdir = tmp_dir)

colnames(expression_dt)[which(colnames(expression_dt) == "cell_ID")] <- 'cell'
expression_dt <- expression_dt %>% arrange(fov, cell)
expression_dt <- expression_dt %>% mutate('cell_ID' = paste0("c_1_", fov, "_", cell))
cell_ids_vector_r <- expression_dt$cell_ID

2all_feature_names <- setdiff(names(expression_dt), c("fov", "cell_ID", "cell"))

neg_indices_r <- which(startsWith(all_feature_names, "Negative") | startsWith(all_feature_names, "NegPr"))
sys_indices_r <- which(startsWith(all_feature_names, "System") | startsWith(all_feature_names, "False"))
gene_indices_r <- which(!startsWith(all_feature_names, "Negative") &
                          !startsWith(all_feature_names, "System") &
                          !startsWith(all_feature_names, "NegPr") &
                          !startsWith(all_feature_names, "False"))

neg_probe_names_vector_r <- all_feature_names[neg_indices_r]
sys_probe_names_vector_r <- all_feature_names[sys_indices_r]
gene_probe_cols <- all_feature_names[gene_indices_r]

neg_mat_r <- as.matrix(expression_dt[, ..neg_probe_names_vector_r])
sys_mat_r <- as.matrix(expression_dt[, ..sys_probe_names_vector_r])
3gene_mat_r <- as.matrix(expression_dt[, ..gene_probe_cols])

meta <- data.table::fread(file.path(flat_file_dir, "S0_metadata_file.csv.gz"))

meta$tmp <- meta$cell_ID
meta$cell_ID <- meta$cell_id
meta$cell_id <- meta$tmp
meta$tmp <- NULL

meta <- meta %>% arrange(fov, cell_id)
4um_per_px = 0.1203
meta$x_slide_mm <- um_per_px*meta$CenterX_global_px/1e3
meta$y_slide_mm <- um_per_px*meta$CenterY_global_px/1e3

if(nrow(meta) != nrow(gene_mat_r)){
  stop("Error. Check file inputs.")
}
```

1

My EC2 instance only has 100 GBs of storage. Setting it to a mounted drive without such restriction avoids low disk space warnings or complications.

2

This includes targets, negatives, and system controls

3

Keep dense. Avoid passing sparse matrices from/to R/python via reticulate

4

Conversion: 0.1203 µm per pixel

While the matrix and metadata information do not contain cell segmentation detail, it’s always a good idea to plot the cells in space to ensure they match our expected orientation.

```
p <- ggplot(data=meta) +
  geom_point(
    aes(x=x_slide_mm, y=y_slide_mm),
    size=0.001, alpha=0.1) + 
  coord_fixed() + theme_bw()

ggsave(filename = file.path(qc_dir, "xy_cells_initial_lowres.png"), p,
1       width=8, height=8, dpi=80, type = 'cairo')
ggsave(filename = file.path(qc_dir, "xy_cells_initial_highres.png"), p,
       width=8, height=8, dpi=400, type = 'cairo')
```

1

I tend to plot lower-resolution versions of pngs to make the Quarto book light weight.

Figure 
2.1
 confirms the expected orientation and alignment from the flat files.

```
render(file.path(analysis_asset_dir, 'qc'), "xy_cells_initial_lowres.png", source_parent_folder=qc_dir)
```

Figure 2.1: Spatial oreientation of cells.

With that confirmation, create the initial anndata object. Specifically, we’ll start with dense
1
 matrices of expression, system controls (
i.e.
, “false codes”), and negative probes, and add these into the 
X
 elment and into 
obsm
, respectively. We’ll place the metadata into the 
obs
 and we’ll also create a matrix of (X, Y) coordinates into their own 
obsm
.

When analyzing interactively I switch between R and python blocks explicitly with 
reticulate::reply_python()
 to enter python and type 
exit()
 to return back to R.

```
filename = os.path.join(r.analysis_dir, "anndata-0-initial.h5ad")

if not os.path.exists(filename):
  # 1 Initial construction
  adata = ad.AnnData(
    X=r.gene_mat_r,
    obsm={'counts_neg': sp.sparse.csr_matrix(r.neg_mat_r), 'counts_sys': sp.sparse.csr_matrix(r.sys_mat_r)},
    obs=r.meta, 
    var=pd.DataFrame(index=r.gene_probe_cols),
  )
  adata.X = sp.sparse.csr_matrix(adata.X)
  adata.uns['neg_col_names'] = r.neg_probe_names_vector_r
  adata.uns['sys_col_names'] = r.sys_probe_names_vector_r
  
  # 2. add coordinates in the 'spatial' obsm
1  coordinates = adata.obs[['x_slide_mm', 'y_slide_mm']].to_numpy()
  adata.obsm['spatial'] = coordinates
  
  # 3. Save object to disk
  adata.write_h5ad(
      filename,
      compression=hdf5plugin.FILTERS["zstd"],
      compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
  )
```

1

Some packages expect the xy coordinates as a numpy array in obsm.

And that’s it! Our data have been converted into anndata format and now we’re ready to assess the quality.

1. 
Barrett, T. 
et al.
 
Data.table: Extension of ‘Data.frame‘
. (2025).

2. 
Palla, G. 
et al.
 Squidpy: A scalable framework for spatial omics analysis. 
Nat. Methods
 
19
, 171–178 (2022).

3. 
Marconato, L. 
et al.
 
SpatialData
: An open and universal data framework for spatial omics. 
Nat. Methods
 
22
, 58–62 (2025).

4. 
Hao, Y. 
et al.
 Dictionary learning for integrative, multimodal and scalable single-cell analysis. 
Nat. Biotechnol.
 
42
, 293–304 (2024).

I generally avoid handing off sparse matrices from R to python and 
vice versa
 and since the data were dense to begin with (
i.e.
, it was a CSV file), we’ll make it sparse in with python.
↩︎


====================
START OF FILE: how-to-use.html
====================

Who This Book Is For 🔬

This guide is for any scientist or bioinformatician interested in analyzing CosMx
®
 Spatial Molecular Imager (SMI) data. It is designed to be accessible for newcomers while also providing a robust, reproducible workflow for experienced users.

While our primary focus will be on a single-slide, subcellular Whole Transcriptome (WTX) dataset, the principles and code are broadly applicable to other RNA panels (like the 1K or 6K panels). Larger, multi-slide experiments have additional considerations that will be a topic for another day. While this book demonstrates a complete analysis from start to finish, its chapters are also designed to be modular. This structure allows you to either follow the entire workflow linearly or to treat it as a “choose your own adventure” guide—jumping directly to the sections most relevant to your specific questions and data.

Navigating This Guide 🗺️

This content is structured as a 
Quarto Book
, with several features to help you find information:

Left Sidebar:
 Provides navigation between the main chapters of the book.

Right Sidebar:
 Shows a table of contents for the sections within the current chapter.

</> Code
 Button:
 Located in the top-right corner of many pages, this button will show or hide the source code used to generate the outputs in a given section, programmatic formatting of 
tabs
 of plots, Observable JS code blocks of interactive plots that are not otherwise shown directly, 
etc
.

The Analytical Philosophy 🧠

There is no single “correct” way to analyze spatial data, just as there is no single, linear path that individual cells interact. The most powerful analysis is always driven by the specific biological questions and hypotheses of your study and even then there are multiple statistical approaches that can work. This book does not present a rigid, one-size-fits-all pipeline. Instead, it provides a comprehensive and adaptable foundation. The goal is to equip you with the tools and intuition needed to confidently explore your own data and tailor the analysis to your unique research goals.

Alternative Approach

There are so many ways to analyze CosMx SMI data. While this book shows a few such solutions, there are some other methods that may be worth considering. I’ll make use of these 
Alternative Approach
 boxes like this to suggest additional ways to tackle a given problem. If there are two approaches that are helpful to show side-by-side I’ll show those in the main text.

Deep Dives

Readers who are interested in learning additional details about a particular topic, such as how certian function parameters effect a result, can learn more in boxes with the gear icon. These sections can be expanded or collapsed by clicking on the arrow on the top right of the box.

If an interactive visualization is needed to help us understand a particular topic, I may make use of serverless webassembly techniques such as those found in the fantastic 
quarto-live
1
 quarto extension. In a nutshell, the quarto-live extension provide instructions to your browser on how to run R or python content. This integrates well with Observable JS and quarto. For more information on 
quarto-live
, see their 
online documentation
.

feel free to adjust the code and run it.

Technical Approach and Reproducibility 🛠️

This guide uniquely leverages the combined strengths of both 
R
 and 
Python
, as both languages offer exceptional, complementary ecosystems for spatial analysis. I primarily use Python’s 
AnnData
2
 and 
scanpy
3
 packages for their performance and scalability, while relying on R’s 
tidyverse
4
 for specific statistical methods, data wrangling, and visualization. RStudio’s integrated support for both languages via 
reticulate
5
 makes this hybrid approach surprisingly seamless. To ensure a fully reproducible analysis environment, the project repository for this book includes:

renv.lock
:
 A file to restore the exact R package library using the 
renv
 package.

requirements.txt
:
 A file to recreate the Python environment using 
pip
. Instructions for setting up the complete, combined environment can be found in the project’s README file on GitHub.

Since this book was written in the Quarto book format, individual chapters are executed “in isolation” from one another. This means its necessary to write data to disk in order for a subsequent chapter to be able to use it. Certain computations can take hours as well and so it’s not ideal to try to unnecessarily re-compute these each time I “build” (render) this book. My technical approach here – and indeed in most of my daily analyses – is to analyze code blocks interactively and then only evaluate code blocks that are absolutely necessary for rendering the documnet such as including and formatting a pre-computed image. More information about this analysis system can be found in the 
Introduction
.

Throughout this book I work with a particular dataset to show an end-to-end analysis. There are some 
asides
 that are not part of the analysis but rather to illustrate an idea or provide supporting materal. For code blocks that are not part of the main analysis, I’ll mark the a “Python - supporting” tag like so:

Python - supporting

```
# Code used for supporting material
```

If you are interested in adapating this environment to your own workflow, please see more information 
Setting up Your Own Analysis Environment
.

I should note that CosMx SMI data analysis can be quite resource demanding. The analysis within this book was created on Amazon g6.16xlarge 
EC2 instance
 equipped with one L4 NVIDIA GPU (24 GB RAM) and 64 vCPUs (256 GB RAM). The operating system that was used was Ubuntu 24.04.1 LTS.

1. 
The R-WASM Team. 
quarto-live: WebAssembly powered code blocks and exercises for R and Python in Quarto
. (2024).

2. 
Virshup, I., Rybakov, S., Theis, F. J., Angerer, P. & Wolf, F. A. 
Anndata: Access and store annotated data matrices
. 
Journal of Open Source Software
 
9
, 4371 (2024).

3. 
Wolf, F. A., Angerer, P. & Theis, F. J. 
SCANPY
: Large-scale single-cell gene expression data analysis. 
Genome Biol.
 
19
, (2018).

4. 
Wickham, H. 
et al.
 
Welcome to the 
tidyverse
. 
Journal of Open Source Software
 
4
, 1686 (2019).

5. 
Ushey, K., Allaire, J. & Tang, Y. 
Reticulate: Interface to ’Python’
. (2025).


====================
START OF FILE: index.html
====================

Preface

Someone once described the analysis of spatial transcriptomics as “rocket science,” and I remember balking at the comparison. In some ways, I thought, it’s far more complex. Humanity’s first steps on the moon were guided by software engineering that was itself 
a new frontier
, yet it was built upon a foundation of physics understood for centuries. Even the first draft of the human genome, a monumental achievement from nearly a generation ago
1
, was a challenge of reading a single, linear code. Our task today is to interpret an entire library of those codes being read simultaneously across a bustling city of cells. This is the distinctly 21st-century frontier we now face.

This guide is the resource I wish I had when I first faced that frontier. It was born from my own journey of piecing together workflows from open-sourced code and gradually building an intuition for what this beautiful and complex data was revealing. My goal is not simply to provide a set of computational recipes, but to walk alongside you through a complete, end-to-end analysis of CosMx SMI Whole Transcriptome data. We will start with the raw files and move step-by-step through quality control, cell typing, and downstream analysis.

Along the way, we will move beyond static figures. This guide is designed to be an active learning experience, encouraging you to engage directly with the dataset to develop your own tactile feel for the analysis. This work is also dynamic in the approaches and content that is presented. New tertiary analyses are already in the works including ligand-receptor and trajectory analyeses. My hope is that by the end, you will have not only a robust workflow but also the confidence to adapt it to answer your own unique biological questions. That confidence is essential, because this is the landscape that Whole Transcriptome CosMx SMI data invites us into: a territory of discovery where the rules are still being written. Our challenge is not one of engineering known forces, but of interpreting a biological language we are only beginning to understand. This guide provides the tools to begin that translation.

1. 
Lander, E. S. 
et al.
 Initial sequencing and analysis of the human genome. 
Nature
 
409
, 860–921 (2001).


====================
START OF FILE: introduction.html
====================

Our journey into the frontier of spatial biology begins! But before we jump right into the code, it’s important to build a foundational understanding of the technology that we’re analyzing data from, how to access data, and the biological context of the sample we’ll be analyzing throughout this guide.

1.1
 What is the CosMx
®
 Spatial Molecular Imager?

Traditional methods like bulk and single-cell RNA sequencing have revolutionized biology, but they come with a critical limitation: by dissociating tissue into a suspension, they erase all spatial context. We learn 
which
 cells are present, but not 
where
 they were or how they were organized.

The CosMx SMI is an 
in-situ imaging
 technology designed to overcome this challenge. Instead of removing cells from the tissue, it measures RNA or protein molecules directly in their native environment, providing a high-plex, high-resolution map of cellular activity.

The underlying chemistry and hardware, detailed by He et al.
1
, enables a multi-step process:

Labeling:
 Tissue sections on a glass slide are treated with a cocktail of probes designed to bind to specific target RNA molecules. These probes act as unique, programmable labels.

Imaging Cycles:
 The slide is placed in the instrument and imaged in a series of cycles. In each cycle, fluorescent “reporter” probes are washed over the tissue, lighting up a subset of the molecular labels.

Barcode Reading:
 An image is captured in each cycle. The pattern of “on” and “off” signals for a single RNA molecule across all cycles creates a unique optical barcode that identifies the gene target. The molecule’s 
(X, Y, Z)
 coordinates are precisely measured from its position in the high-resolution images.

Cell Segmentation:
 Finally, the identified transcripts and protein markers are assigned to individual cells. This segmentation process relies on immunofluorescence (IF) stains—such as DAPI to visualize nuclei and antibodies against proteins like CD298 to visualize cell membranes—that allow algorithms to accurately draw cell boundaries.

The final output is a rich suite of data tables, including the foundational gene-by-cell expression matrix, spatial coordinates, and morphological features for every cell. This is complemented by the raw imaging data, which enables deeper quality control and visualization, as we’ll explore in later chapters.

1.2
 Accessing CosMx SMI Data

After a CosMx experiment, the instrument uploads raw imaging data to the 
AtoMx
®
 Spatial Informatics Platform (SIP)
, a cloud-based environment where the heavy computation of barcode decoding and cell segmentation occurs. Once this primary processing is complete, the data can be explored within the AtoMx SIP ecosystem or, as we will do, exported for custom downstream analysis.

Tip
Exporting from AtoMx
®
 SIP

For a detailed guide on navigating the AtoMx SIP interface and exporting your processed data, see the post: 
Using Squidpy with AtoMx
®
 SIP exports
.

Public datasets are another invaluable resource. For example, 
Bruker provides a list of FFPE datasets
, and indeed for this guide, we will be analyzing the 
human colon cancer dataset
 featured on that site.

1.3
 Setting up Your Own Analysis Environment

This subsection in primarily for those who wish to use this book as a springboard for their own analysis.

When working in a mixed R and python environment, I make use of RStudio IDE and work within an analysis “Project”. While your version of R will likely be different, this particular version is R version 4.5.1 (2025-06-13) and managing packages with 
renv
2
. Similarly, I’m using a virtual environment within 
pyenv
 that’s based on Python 3.10.18.

I highly recommend maintaining packages within your project as this field is moving at a very rapid pace and package versions can quickly create issues and conflicts. To “restore” the R packages use 
renv::restore()
 within the project folder. To create the python virtual environment using 
pyenv
, type this into your terminal:

```
1pyenv install 3.10.18
pyenv virtualenv 3.10.18 pyenv_simple
pyenv activate pyenv_simple
pip install -r requirements.txt
```

1

assumes you have 
pyenv
 installed. See 
Additional Resources
 for more information on 
pyenv
.

To link this virtual environment to our project, I make use of symbolic links and add the path to my 
.Renviron
 project file.

For example, typing

```
pyenv versions
```

in the terminal will reveal the specific path that 
pyenv
 placed the virtual environment. For me it was:

```
 pyenv versions
  system
  3.10.18/envs/pyenv_simple
* pyenv_simple --> /opt/pyenv/versions/3.10.18/envs/pyenv_simple (set by /opt/pyenv/version)
```

and then within the project directory I can add 
pyenv_simple
 to the folder like so:

```
ln -s /opt/pyenv/versions/3.10.18/envs/pyenv_simple ./pyenv_simple
```

Now that a symbolic link to the virtual environment is present in the project directory, add this line to 
.Renviron
 and restart Rstudio.

```
RETICULATE_PYTHON=pyenv_simple/bin/python
```

The organizational structure of the data itself is as follows: within the 
analysis_results
 folder there is a folder for 
input_files
 and another folder for 
output_files
. Within the 
output_files
 folder there will be a series of sub-folders with data as well as a file is named 
results_list.rds
 that I’ll populate throughout and use to – for example – reference the number of cells or other “small” statistics that will be handy.

Finally, since Quarto renders each chapter in isolation, at the beginning of analysis chapters we will add a “preamble” that loads common R scripts, python functions, and the 
results_file.rds
 file.

1.4
 Our Example Dataset

Thoughout this book, we’ll examine these foundational WTX analyses by looking at a 400-field-of-view (FOV) section of FFPE colon adenocarcinoma. This tissue was analyzed using Bruker Spatial Biology’s pre-commercial WTX CosMx
®
 SMI assay and is 
available online
. Our primary biological questions driving this analysis are:

What are the major spatial domains within this sample and what cell types do they contain?

What pathways are enriched within these domains?

1. 
He, S. 
et al.
 High-plex imaging of 
RNA
 and proteins at subcellular resolution in fixed tissue by spatial molecular imaging. 
Nat. Biotechnol.
 
40
, 1794–1806 (2022).

2. 
Ushey, K. & Wickham, H. 
Renv: Project Environments
. (2024). doi:
10.32614/CRAN.package.renv
.


====================
START OF FILE: pathways.html
====================

R code

```
source("./preamble.R")
library(ggplot2)
library(stringr)
reticulate::source_python("./preamble.py")
analysis_dir <- file.path(getwd(), "analysis_results")
input_dir <- file.path(analysis_dir, "input_files")
output_dir <- file.path(analysis_dir, "output_files")
analysis_asset_dir <- "./assets/analysis_results"
ct_dir <- file.path(output_dir, "ct")
pw_dir <- file.path(output_dir, "pathways")
if(!dir.exists(pw_dir)){
  dir.create(pw_dir, recursive = TRUE)
}
results_list_file = file.path(analysis_dir, "results_list.rds")
if(!file.exists(results_list_file)){
  results_list <- list()
  saveRDS(results_list, results_list_file)
} else {
  results_list <- readRDS(results_list_file)  
}
# results_list$run_explainer <- TRUE 
source("./helpers.R")
library(ComplexHeatmap)
library(circlize)
```

7.1
 Introduction

In the previous chapters, we defined “who” is in the tissue (cell types) and where they are located (spatial domains). The next logical step is to ask: “what are they doing?”. This is a particularly exciting and open-ended question. Since we have access to the whole transcriptome, we can measure biological activity with unparalleled precision and down to the subcellular level, if desired.
1

Pathway analysis allows us to move beyond simple identity markers to infer the active biological processes driving the tissue’s organization. For example, identifying a cell as a “fibroblast” tells us its lineage, but pathway analysis tells us if that fibroblast is actively building scar tissue (TGF-
\(\beta\)
 signaling) or recruiting immune cells (NF-
\(\kappa\)
B signaling).

While we can measure thousands of pathways from any number of databases, in this primer we’ll keep things tractable and estimate the activity of 14 cancer-relevant signaling pathways using the PROGENy
1
 database.

Here is our approach:

Smoothing: We will apply nearest neighbor smoothing to borrow information from similar cells, overcoming the sparsity of single-cell data.

Scoring: We will calculate an activity score for each pathway in every single cell using the python package decoupler
2
.

Inference: We will aggregate these scores by cell type and spatial domain to interpret signaling landscapes that define dominant biological programs and their spatial context within the tissue.

This workflow will allow us to answer questions like:

Is the tumor driving angiogenesis, or is the stroma?

Which immune cells are actively inflamed versus suppressed?

Does the “Desmoplastic Stroma” domain have a distinct signaling signature?

7.2
 Processing

Read the annData object.

```
if 'adata' not in dir():
  filename = os.path.join(r.analysis_dir, "anndata-7-domain_annotations.h5ad")
  adata = ad.read_h5ad(filename)

1adata.obsm['spatial'][:,1] *= -1
```

1

flipping the y-axis so that the tissue is in the same orientation as the rest of the analysis.

We’ll use the PROGENy
1
 database available within decoupler
2
 to estimate the single cell enrichment scores of each of the 14 cancer-relevant pathways and their significant values. The code below adapts 
decoupler’s tutorial
 which uses the 
univarte linear model method (ulm) function
. PROGENy can provide a high-level overview of the tissue’s molecular functions distilled down to a handful of pathways – which is relatively quick. For non-cancer systems, or if greater resolution is desired, other databases can be used with the 
ulm
 approach. If you are interested in exploring other databases within decoupler, run 
decoupler.op.show_resources()
.

Here’s a description of those pathways from decoupler’s website.

```
- Androgen: involved in the growth and development of the male reproductive organs.
- EGFR: regulates growth, survival, migration, apoptosis, proliferation, and differentiation in mammalian cells
- Estrogen: promotes the growth and development of the female reproductive organs.
- Hypoxia: promotes angiogenesis and metabolic reprogramming when O2 levels are low.
- JAK-STAT: involved in immunity, cell division, cell death, and tumor formation.
- MAPK: integrates external signals and promotes cell growth and proliferation.
- NFkB: regulates immune response, cytokine production and cell survival.
- p53: regulates cell cycle, apoptosis, DNA repair and tumor suppression.
- PI3K: promotes growth and proliferation.
- TGFb: involved in development, homeostasis, and repair of most tissues.
- TNFa: mediates haematopoiesis, immune surveillance, tumour regression and protection from infection.
- Trail: induces apoptosis.
- VEGF: mediates angiogenesis, vascular permeability, and cell migration.
- WNT: regulates organ morphogenesis during development and tissue repair.
```

Let’s load the PROGENy dataset.

Python Code

```
import decoupler as dc

progeny = dc.op.progeny(organism='human', top=500, license="commercial")
progeny_genes = progeny['target'].unique()
```

```
results_list['n_progeny_genes'] = length(py$progeny_genes)
saveRDS(results_list, results_list_file)
```

For the analysis below we’ll need normalized data. As we saw in 
Chapter 4
, we bypassed the creation of the dense Pearson Residuals normalization matrix and used the PCs instead for nearest neighbors calculations, Leiden, 
etc
. The main reason for this was computational tractability (>400,000 cells by 
ca
. 19,000 targets). That issue is still present here. There are only 5276 genes in the pathway database that we chose and so we do not necessarily need to normalized the entire matrix. Scanpy has a method for Pearson Residuals normalization (
sc.experimental.pp.normalize_pearson_residuals
) but there’s a catch: ideally we would 
not
 run Pearson Normalization on a subset of features. Instead, we would like the non-truncated transcript totals to factor into the normalization procedure. We can achieve this by creating a custom code.

Python Code

```
# 1. Get valid genes
# these are the ones that are in BOTH the progeny dataset and in the anndata, adata
valid_genes = [g for g in progeny_genes if g in adata.var_names]

# 2. Get GLOBAL Stats (before subsetting)
counts_layer = adata.layers['counts'] if 'counts' in adata.layers else adata.X
global_cell_sums = np.array(counts_layer.sum(axis=1)).flatten() # or just from nCount_RNA
total_count = global_cell_sums.sum() # i.e., sum(obs$nCount_RNA)

# 3. Get GENE Stats (Just for the subset is all that's necessary)
gene_indices = [adata.var_names.get_loc(g) for g in valid_genes]
subset_gene_sums = np.array(counts_layer.sum(axis=0)).flatten()[gene_indices]

# 4. Create the Subset
adata_sub = adata[:, valid_genes].copy()
# Ensure we are using raw counts for the calculation
if 'counts' in adata_sub.layers:
    adata_sub.X = adata_sub.layers['counts'].copy()

# 5. Expected counts based on global depth (from the full dataset)
mu = np.outer(global_cell_sums, subset_gene_sums) / total_count

# Pearson Residuals: (Observed - Expected) / StdDev
theta = 100
observed = adata_sub.X.toarray()
residuals = (observed - mu) / np.sqrt(mu + mu**2 / theta)

# Clip outliers (similar to what scanpy does)
clip_val = np.sqrt(adata_sub.shape[0])
residuals = np.clip(residuals, -clip_val, clip_val)

# 6. Save results
adata_sub.X = residuals
del adata
adata = adata_sub 

# Clean up
import gc
del adata_sub, mu, observed, residuals, global_cell_sums, subset_gene_sums
gc.collect()
```

At this point the anndata object has many components that are not needed. Let’s reduce the size of this object to reduce the memory footprint.

Python Code

```
# Clean up obsm
obsm_delete = ['X_pca_TC', 'counts_neg', 'counts_sys', 'umap_TC']
for x in obsm_delete:
    if x in adata.obsm:
        del adata.obsm[x]

# Clean up obsp
obsp_delete = ['neighbors_TC_connectivities', 'neighbors_TC_distances']
for x in obsp_delete:
    if x in adata.obsp:
        del adata.obsp[x]

gc.collect()

1adata.layers['pr_norm'] = adata.X.astype('float32').copy()
```

1

Convert from float 64 bit to float 32 bit Optional step for systems with less RAM.

7.3
 Smoothing Expression

One attribute of all spatial single cell datasets relative to non-spatial method is sparsity. Even for technologies with high-sensitivity detection, individual cells may lack the detection of every transcript required to precisely score pathways. To overcome this, tools like decoupler and liana
3
 
4
 utilize 
smoothing
 – a process of borrowing information from neighboring cells to impute missing values and stabilize pathway scores. However, the term “neighbor” here can be ambiguous. Many of the existing tutorials for these tools were developed with spot-based technologies (like Visium) in mind where 
spatial smoothing
 is used because spots are already multi-cellular mixtures. For single-cell resolution data like CosMx SMI, the choice of using spatial smoothing depends on the types of biological questions you have 
Table 
7.1
. For pathway analysis, we recommend smoothing based on nearest expression neighbors (NN). Check back later when we release a chapter on ligand-receptor analysis for an example of spatial smoothing.

Table 7.1: Two types of smoothing and when to use them.

Feature

Nearest Expression Neighbors (NN)

Spatial Neighbors (SN)

Definition

Averages signal from cells with similar gene expression profiles (
e.g.
, neighbors in PCA space).

Averages signal from cells physically touching or near the target cell (XY space).

Primary Benefit

Preserves Cell Identity.
 A T cell is smoothed with other T cells, maintaining lineage-specific signals.

Visualizes Zones.
 Highlights continuous tissue gradients and regional (
i.e.
, multiple domain) behaviors. 
Analyzing Larger Spatial Patterns
 When examining zonal, regional (
e.g.
, hypoxia), or other larger effects, cells are responding by an interaction of their lineage and their spatial position. Spatial smoothing in this scenario can aid in quantifying the metabolic spatial neighborhood by denoising cells with sparse data. 
Ligand Receptor Analysis.
 While we might not want to spatially smooth a CD4 T cell with, say, a Tumor cell, for certain analyses, this computational approach can be effective in analyzing 
ligand-receptor relationships
. Essentially, if we borrow the receptor expression of nearby cells, we can then test if that receptor is correlated with the focal cells’ corresponding ligand receptor expression.

Drawback

May erode any cell type by specific local/regional interaction effect.

Signal Bleeding
 Can artificially blend high-expression markers (e.g., 
PTPRC
) into neighboring negative cells (e.g., Tumor). 
Tuning
 The degree (
e.g.
, radius, Gaussian kernel) that is used for spatial smoothing is a tuning parameter that, ideally, should align the observational scale with the functional scale.

Best Use Case

Lineage-specific pathways (e.g., TCR signaling, Cell Cycle, B cell activation).

Environmental gradients that occur at regional levels not captured by expression-based domain assignments (e.g., Hypoxia, Nutrient Deprivation, pH levels).

Example

See 
Section 7.4
 below

See upcoming ligand-receptor chapter (expected early 2026)

Let’s apply nearest neighbor smoothing. Recall in 
Chapter 4
 we created a neighbor graph based on pearson residuals PC values derived using the scPearsonPCA package. This produced the 
neighbors_pr_connectivities
 connectivity matrix in 
obsp
. We’ll use this to smooth our cells’ expression.

Python Code

```
adata.layers['nn_smooth'] = adata.obsp['neighbors_pr_connectivities'] @ adata.layers['pr_norm']
```

7.4
 Pathway Enrichment

Run the univariate linear model from 
decoupler
 using the PROGENy database with this smoothed expression matrix to generate pathway scores. Save the results.

Python Code

```
dc.mt.ulm(
  data=adata, 
  net=progeny, 
  verbose=True, 
  layer=f'nn_smooth',
  bsize=80000
  )
  
filename = os.path.join(r.analysis_dir, "anndata-8-pathways-nn.h5ad")
adata.write_h5ad(
  filename,
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

7.5
 Visualizing Pathway Enrichment

We’ll visualize the pathways “locally” on the tissue as well as “globally” by creating heatmaps per cell type and domain.

7.5.1
 Local: spatial visualizations

The local plots provide fine-resolution maps of pathway scores on the tissue. The simplest way to do this is to use scanpy’s 
pl.spatial
 method. If you want greater flexibility in the plotting aesthetics, we can use the 
plotDots
 function in R that we have used throughout this book. Below we’ll show code and results for both approaches.

Using Scanpy’s built-in spatial plotting function
Using 
plotDots
 in R

We can convert the scores themselves into a new annData object and then use scanpy’s functions to plot the individual pathways (features).

Python Code

```
sc.settings.figdir = r.pw_dir
sc.settings.set_figure_params(dpi_save=200, frameon=False)

nn_pwdata = dc.pp.get_obsm(adata=adata, key=f'score_ulm')
nn_pwdata.obsm[f'padj_ulm'] = adata.obsm[f'padj_ulm']

for x in nn_pwdata.var_names:
  sc.pl.spatial(
      nn_pwdata,
      color=[x],
      cmap='RdBu_r',
      vcenter=0,
      size=1.5,
      spot_size=0.01, show=False,
      save="_nn_pathway_Scanpy_" + str(x) + "_xy.png",
      alpha_img=1
  )
```

Path: Androgen
Path: EGFR
Path: Estrogen
Path: Hypoxia
Path: JAK-STAT
Path: MAPK
Path: NFkB
Path: PI3K
Path: TGFb
Path: TNFa
Path: Trail
Path: VEGF
Path: WNT
Path: p53

Figure 7.1: Local Androgen pathway scores plotted with sc.pl.spatial.

Figure 7.2: Local EGFR pathway scores plotted with sc.pl.spatial.

Figure 7.3: Local Estrogen pathway scores plotted with sc.pl.spatial.

Figure 7.4: Local Hypoxia pathway scores plotted with sc.pl.spatial.

Figure 7.5: Local JAK-STAT pathway scores plotted with sc.pl.spatial.

Figure 7.6: Local MAPK pathway scores plotted with sc.pl.spatial.

Figure 7.7: Local NFkB pathway scores plotted with sc.pl.spatial.

Figure 7.8: Local PI3K pathway scores plotted with sc.pl.spatial.

Figure 7.9: Local TGFb pathway scores plotted with sc.pl.spatial.

Figure 7.10: Local TNFa pathway scores plotted with sc.pl.spatial.

Figure 7.11: Local Trail pathway scores plotted with sc.pl.spatial.

Figure 7.12: Local VEGF pathway scores plotted with sc.pl.spatial.

Figure 7.13: Local WNT pathway scores plotted with sc.pl.spatial.

Figure 7.14: Local p53 pathway scores plotted with sc.pl.spatial.

This block runs the 
plotDots
 function that we have used in previous chapters on the objects that we create in the previous subsection, 
nn_pwdata
.

R Code

```
1py$nn_pwdata$obsm['spatial'][,2] <- py$nn_pwdata$obsm['spatial'][,2] * -1

features <- py$nn_pwdata$var_names$to_list()

for(feature in features){
  plotDots(py$nn_pwdata, color_by=feature,
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = pw_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=paste0("plotDots_", feature)
                ),
              additional_ggplot_layers = list(
                theme_bw(), 
                scale_color_gradient2(low = "darkblue", mid = "white", high = "darkred", midpoint = 0),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                theme(legend.position = c(0.8, 0.4))
              )
              )
}
```

1

Flipping the y-axis back.

Path: Androgen
Path: EGFR
Path: Estrogen
Path: Hypoxia
Path: JAK-STAT
Path: MAPK
Path: NFkB
Path: PI3K
Path: TGFb
Path: TNFa
Path: Trail
Path: VEGF
Path: WNT
Path: p53

Figure 7.15: Local Androgen pathway scores plotted with the plotDots function.

Figure 7.16: Local EGFR pathway scores plotted with the plotDots function.

Figure 7.17: Local Estrogen pathway scores plotted with the plotDots function.

Figure 7.18: Local Hypoxia pathway scores plotted with the plotDots function.

Figure 7.19: Local JAK-STAT pathway scores plotted with the plotDots function.

Figure 7.20: Local MAPK pathway scores plotted with the plotDots function.

Figure 7.21: Local NFkB pathway scores plotted with the plotDots function.

Figure 7.22: Local PI3K pathway scores plotted with the plotDots function.

Figure 7.23: Local TGFb pathway scores plotted with the plotDots function.

Figure 7.24: Local TNFa pathway scores plotted with the plotDots function.

Figure 7.25: Local Trail pathway scores plotted with the plotDots function.

Figure 7.26: Local VEGF pathway scores plotted with the plotDots function.

Figure 7.27: Local WNT pathway scores plotted with the plotDots function.

Figure 7.28: Local p53 pathway scores plotted with the plotDots function.

7.5.2
 Global: Per Cell Type

In addition to plotting the local pathway scores in space with scanpy or 
plotDots
, we can visualize the results summarized across each cell type or each domain. These next two subsections do just that. We’ll use the plotting functionality within the 
complexHeatmap
 R package. It can be helpful to plot the average enrichment as well as the Z-scores. The former helps with us understand the overall sense of what is being enriched whereas the latter helps to compare a particular effect size relative to other cell types.

R Code

```
df <- py$nn_pwdata$obs %>% select(cell_ID, celltype_broad, celltype_fine)
expr <- py$nn_pwdata$X
colnames(expr) <- py$nn_pwdata$var_names$to_list()
df <- cbind(df, expr)

pathway_cols <- setdiff(names(df), c("cell_ID", "celltype_broad", "celltype_fine"))
min_obs = 50

mean_enrich_by_ct <- df %>%
  group_by(celltype_broad, celltype_fine) %>%
  summarise(
    n = n(),
    across(all_of(pathway_cols), mean, .names = "{.col}_mean"),
    .groups = 'drop'
  ) %>% 
  filter(n >= min_obs) %>%
  arrange(celltype_broad, celltype_fine)

scaled_enrich_by_ct <- mean_enrich_by_ct %>%
  mutate(across(ends_with("_mean"), ~as.numeric(scale(.)))) %>%
  arrange(celltype_broad, celltype_fine)

celltype_broad_colors <- results_list[['celltype_broad_colors']]
names(celltype_broad_colors) <- results_list[['celltype_broad_names']]

celltype_fine_colors <- results_list[['celltype_fine_colors']]
names(celltype_fine_colors) <- results_list[['celltype_fine_names']]

# Shared Row Annotation
row_ha <- HeatmapAnnotation(
  "Cell Group" = scaled_enrich_by_ct$celltype_broad,
  "Cell Type" = scaled_enrich_by_ct$celltype_fine,
  col = list(
    "Cell Group" = celltype_broad_colors,
    "Cell Type" = celltype_fine_colors
  ),
  show_legend = c("Cell Group" = FALSE, "Cell Type" = FALSE),
  which = "row"
)

zscore_col_fun <- colorRamp2(c(-2, 0, 2), c("#2166AC", "white", "#B2182B"))

heatmap_matrix_z <- scaled_enrich_by_ct %>%
  select(ends_with("_mean")) %>%
  as.matrix()
rownames(heatmap_matrix_z) <- scaled_enrich_by_ct$celltype_fine
colnames(heatmap_matrix_z) <- gsub("_mean", "", colnames(heatmap_matrix_z))

ht_z <- Heatmap(
  heatmap_matrix_z,
  name = "Pathway Z-score\n(Relative)",
  col = zscore_col_fun,
  
  left_annotation = row_ha,

  show_row_names = TRUE,
  row_names_gp = gpar(fontsize = 6),

1  cluster_columns = FALSE,
  column_names_gp = gpar(fontsize = 7),
  row_split = scaled_enrich_by_ct$celltype_broad, 
  cluster_row_slices = TRUE,
  cluster_rows = FALSE,
  row_title_rot = 0,
  row_title_gp = gpar(fontsize = 10)
)

svglite::svglite(file.path(pw_dir, "heatmap_by_cell_type_zscore.svg"), width = 3.5, height = 6)
  draw(
    ht_z, 
    heatmap_legend_side = "bottom", 
    annotation_legend_side = "bottom",
    merge_legend = TRUE
  )
dev.off()

png(file.path(pw_dir, "heatmap_by_cell_type_zscore.png"), 
    width=4, height=8, res=350, units = "in", type = 'cairo')
  draw(
    ht_z, 
    heatmap_legend_side = "bottom", 
    annotation_legend_side = "bottom",
    merge_legend = TRUE
  )
dev.off()

heatmap_matrix_mean <- mean_enrich_by_ct %>%
  select(ends_with("_mean")) %>%
  as.matrix()
rownames(heatmap_matrix_mean) <- mean_enrich_by_ct$celltype_fine
colnames(heatmap_matrix_mean) <- gsub("_mean", "", colnames(heatmap_matrix_mean))

quantile_limit <- 0.95
limit <- as.numeric(quantile(abs(as.vector(heatmap_matrix_mean)), quantile_limit, na.rm = TRUE))
mean_col_fun <- colorRamp2(c(-limit, 0, limit), c("#2166AC", "white", "#B2182B"))

ht_mean <- Heatmap(
  heatmap_matrix_mean,
  name = "PROGENy Score\n(Mean)",
  col = mean_col_fun,
  
  left_annotation = row_ha,

  show_row_names = TRUE,
  row_names_gp = gpar(fontsize = 6),

  cluster_columns = FALSE, 
  column_names_gp = gpar(fontsize = 7),
  row_split = mean_enrich_by_ct$celltype_broad, 
  cluster_row_slices = TRUE,
  cluster_rows = FALSE,
  row_title_rot = 0,
  row_title_gp = gpar(fontsize = 10)
)

svglite::svglite(file.path(pw_dir, "heatmap_by_cell_type_mean.svg"), width = 3.5, height = 6)
  draw(
    ht_mean, 
    heatmap_legend_side = "bottom", 
    annotation_legend_side = "bottom",
    merge_legend = TRUE
  )
dev.off()

png(file.path(pw_dir, "heatmap_by_cell_type_mean.png"), 
    width=4, height=8, res=350, units = "in", type = 'cairo')
  draw(
    ht_mean, 
    heatmap_legend_side = "bottom", 
    annotation_legend_side = "bottom",
    merge_legend = TRUE
  )
dev.off()
```

1

Set to FALSE to make it easier to compare the mean and the Z-score heatmaps. Set to TRUE to make it easier to group similar pathway signatures.

Mean
Z-score

Figure 7.29: Average pathway enrichment scores by cell type.

Figure 7.30: Average pathway enrichment scores (z-score) by cell type.

7.5.3
 Global: Per Domain

This follows a similar procedure as above but summarized across spatial domains.

R Code

```
df <- merge(df, py$nn_pwdata$obs %>% select(cell_ID, annotated_domain), by="cell_ID")
df <- filter(df, !is.na(annotated_domain))
min_obs = 50

# Calculate Mean Scores
mean_enrich_by_domain <- df %>%
  group_by(annotated_domain) %>%
  summarise(
    n = n(),
    across(all_of(pathway_cols), mean, .names = "{.col}_mean"),
    .groups = 'drop'
  ) %>% 
  filter(n >= min_obs, !is.na(annotated_domain)) %>%
  arrange(annotated_domain)

# Calculate Z-scores (Scale the means)
scaled_enrich_by_domain <- mean_enrich_by_domain %>%
  mutate(across(ends_with("_mean"), ~as.numeric(scale(.)))) %>%
  arrange(annotated_domain)

# Colors
domain_colors_df  <- results_list[['domain_colors']]
domain_colors <- domain_colors_df$domain_color
names(domain_colors) <- domain_colors_df$domain_description

# Common Row Annotation
row_ha <- HeatmapAnnotation(
  "Spatial Domain" = mean_enrich_by_domain$annotated_domain,
  col = list("Spatial Domain" = domain_colors),
  show_legend = c("Spatial Domain" = FALSE),
  which = "row"
)

# Color Functions
zscore_col_fun <- colorRamp2(c(-2, 0, 2), c("#2166AC", "white", "#B2182B"))

# Z-Score Heatmap
heatmap_matrix_z <- scaled_enrich_by_domain %>%
  select(ends_with("_mean")) %>%
  as.matrix()
rownames(heatmap_matrix_z) <- scaled_enrich_by_domain$annotated_domain
colnames(heatmap_matrix_z) <- gsub("_mean", "", colnames(heatmap_matrix_z))

ht_z <- Heatmap(
  heatmap_matrix_z,
  name = "Pathway Z-score\n(Relative)",
  col = zscore_col_fun,
  left_annotation = row_ha,
  show_row_names = TRUE,
  row_names_gp = gpar(fontsize = 5.5),
  cluster_columns = TRUE,
  column_names_gp = gpar(fontsize = 5.5),
  row_title_rot = 0,
  row_title_gp = gpar(fontsize = 8)
)

svglite::svglite(file.path(pw_dir, "heatmap_by_domain_zscore.svg"), width = 3.5, height = 3)
  draw(ht_z, heatmap_legend_side = "bottom", annotation_legend_side = "bottom", merge_legend = TRUE)
dev.off()

png(file.path(pw_dir, "heatmap_by_domain_zscore.png"), width=3.5, height=3.5, res=350, units = "in", type = 'cairo')
  draw(ht_z, heatmap_legend_side = "bottom", annotation_legend_side = "bottom", merge_legend = TRUE)
dev.off()

# Mean Score Heatmap
heatmap_matrix_mean <- mean_enrich_by_domain %>%
  select(ends_with("_mean")) %>%
  as.matrix()
rownames(heatmap_matrix_mean) <- mean_enrich_by_domain$annotated_domain
colnames(heatmap_matrix_mean) <- gsub("_mean", "", colnames(heatmap_matrix_mean))

quantile_limit <- 0.95
limit <- as.numeric(quantile(abs(as.vector(heatmap_matrix_mean)), quantile_limit, na.rm = TRUE))
mean_col_fun <- colorRamp2(c(-limit, 0, limit), c("#2166AC", "white", "#B2182B"))

ht_mean <- Heatmap(
  heatmap_matrix_mean,
  name = "PROGENy Score\n(Mean)",
  col = mean_col_fun,
  left_annotation = row_ha,
  show_row_names = TRUE,
  row_names_gp = gpar(fontsize = 5.5),
  cluster_columns = TRUE, 
  column_names_gp = gpar(fontsize = 5.5),
  row_title_rot = 0,
  row_title_gp = gpar(fontsize = 8)
)

svglite::svglite(file.path(pw_dir, "heatmap_by_domain_mean.svg"), width = 3.5, height = 3)
  draw(ht_mean, heatmap_legend_side = "bottom", annotation_legend_side = "bottom", merge_legend = TRUE)
dev.off()

png(file.path(pw_dir, "heatmap_by_domain_mean.png"), width=3.5, height=3.5, res=350, units = "in", type = 'cairo')
  draw(ht_mean, heatmap_legend_side = "bottom", annotation_legend_side = "bottom", merge_legend = TRUE)
dev.off()
```

Mean
Z-score

Figure 7.31: Average pathway enrichment scores by spatial domain. Colors correspond to domains in 
Figure 
6.8
. Note: columns were clustered and so will have a difference order than that found in 
Figure 
7.32
.

Figure 7.32: Average pathway enrichment scores (z-score) by spatial domain. Colors correspond to domains in 
Figure 
6.8
. Note: columns were clustered and so will have a difference order than that found in 
Figure 
7.31
.

Examining and comparing the spatial plots in 
Section 7.5.1
 with the global heatmaps 
Figure 
7.29
, 
Figure 
7.30
, 
Figure 
7.31
, and 
Figure 
7.32
 reveals several findings in this tissue.

For example:

In the tumor cells we see little enrichment of the pro-apoptotic TRAIL pathway (mean = 0.0; Z-score = -1.1) but high EGFR enrichment (mean = 2.6; Z-score = 3.7), a pattern associated with increased cell invasion and metastasis
5
.

Tumor cells are likely a “CMS4” or mesenchymal colon cancer phenotype. The three signatures of this phenotype are ‘prominent transforming growth factor–β activation, stromal invasion and angiogenesis’
6
. Looking at growth regulation, tumor cells themsevles show little enrichment of TGF-
\(\beta\)
 (mean = -2.3; Z-score = -0.85); however, the CAFs show the highest levels in the dataset (mean = 7.0; Z-score = 3.9). This pattern mirrors the TGF-
\(\beta\)
 exclusion phenotype described in the literature, where stromal activation drives poor prognosis in colon cancer
7
 
8
. For stromal invasion, we can see from the spatial plots both at the cell type-level 
Figure 
6.4
 and the domain-level (
Figure 
6.8
) that CAFs and tumors are found in interdigitated domains. And finally, we found a signature of angiogenesis in tumor cells and tumor and stromal domains with the enrichment of VEGF
9
.

There is a strong enrichment of TNF-
\(\alpha\)
 and NF-
\(\kappa\)
B on the left side of the tissue that is still unresolved. The left side of the tissue is part of the “Heterogeneous” spatial domain that is found throughout (
Chapter 5
) that contains a high proportion of undetermined cell types (
Figure 
6.7
). Perhaps a follow up analysis would include isolating the cells within this “sub-domain” to understand which cells might be driving the reduction of apoptosis and preventing an effective immune response. This could be done with lasso selecting the region (see our 
blog post on lasso selecting with napari
).

7.6
 Summary

In this chapter, we showed a simple nearest-neighbor smoothing technique and scored pathways using one of the available databases (PROGENy; for others see 
decoupler.op.show_resources()
). Then we showed a few ways to pivot the data and visualize the local scores or global aggregates these scores across cell types and spatial domains to guide our inference.

1. 
Schubert, M. 
et al.
 Perturbation-response genes reveal signaling footprints in cancer gene expression. 
Nature communications
 
9
, (2018).

2. 
Badia-i-Mompel, P. 
et al.
 decoupleR: Ensemble of computational methods to infer biological activities from omics data. 
Bioinformatics Advances
 https://doi.org/
https://doi.org/10.1093/bioadv/vbac016
 (2022) doi:
https://doi.org/10.1093/bioadv/vbac016
.

3. 
Dimitrov, D. 
et al.
 Comparison of methods and resources for cell-cell communication inference from single-cell 
RNA-Seq
 data. 
Nat. Commun.
 
13
, 3224 (2022).

4. 
Dimitrov, D. 
et al.
 
LIANA+
 provides an all-in-one framework for cell-cell communication inference. 
Nat. Cell Biol.
 
26
, 1613–1622 (2024).

5. 
Sasaki, T., Hiroki, K. & Yamashita, Y. The role of epidermal growth factor receptor in cancer metastasis and microenvironment. 
Biomed Res. Int.
 
2013
, 546318 (2013).

6. 
Guinney, J. 
et al.
 The consensus molecular subtypes of colorectal cancer. 
Nat. Med.
 
21
, 1350–1356 (2015).

7. 
Calon, A. 
et al.
 Stromal gene expression defines poor-prognosis subtypes in colorectal cancer. 
Nat. Genet.
 
47
, 320–329 (2015).

8. 
Ma, M. 
et al.
 
Prognostic implications and therapeutic opportunities related to CAF subtypes in CMS4 colorectal cancer: Insights from single-cell and bulk transcriptomics
. 
Apoptosis
 
30
, 826–841 (2025).

9. 
Duffy, A. M., Bouchier-Hayes, D. J. & Harmey, J. H. Vascular endothelial growth factor (
VEGF
) and its role in non-endothelial cells: Autocrine signalling by 
VEGF
. in 
VEGF
 and cancer
 133–144 (Springer US, Boston, MA, 2004).

To keep this primer clear and tractable, we’ll focus on a smaller pathway database at the single-cell level.
↩︎


====================
START OF FILE: processing.html
====================

R code

```
source("./preamble.R")
reticulate::source_python("./preamble.py")
analysis_dir <- file.path(getwd(), "analysis_results")
input_dir <- file.path(analysis_dir, "input_files")
output_dir <- file.path(analysis_dir, "output_files")
analysis_asset_dir <- "./assets/analysis_results"
qc_dir <- file.path(output_dir, "qc")
if(!dir.exists(qc_dir)){
  dir.create(qc_dir, recursive = TRUE)
}
pp_dir <- file.path(output_dir, "processing")
if(!dir.exists(pp_dir)){
  dir.create(pp_dir, recursive = TRUE)
}
results_list_file = file.path(analysis_dir, "results_list.rds")
if(!file.exists(results_list_file)){
  results_list <- list()
  saveRDS(results_list, results_list_file)
} else {
  results_list <- readRDS(results_list_file)  
}
source("./helpers.R") # contains the plotDots function
```

Our quality control steps in 
Chapter 3
 identified the analyzable cells, but these their raw counts need further processing to reveal biological patterns. This chapter covers the essential pre-processing steps to make the data interpretable.

First, normalization adjusts counts to account for technical factors like cell area (
i.e.
, larger cells typically have more counts), enabling fair comparisons between cells. Second, dimensionality reduction (using PCA and UMAP) helps reduce the total number of dimensions in the data (almost 19,000) to a manageable representation that captures key biological variation and allows visualization. Finally, clustering leverages this reduced space to group cells with similar expression profiles, which can be a foundation for downstream analyses like cell typing.

By the end of this chapter, we will have transformed the filtered count matrix into a clustered, low-dimensional dataset and classified cells into groups which, taken together, form our foundation for biological interpretation and spatial analysis. I often get asked “What is the best parameter combination for CosMx data?” and I hope by the end of this chapter you’re able to understand how parameter adjustments impact many of these processing steps.

Let’s begin by loading the data.

Python Code

```
adata = ad.read_h5ad(os.path.join(r.analysis_dir, "anndata-1-qc-filtered.h5ad"))
```

4.1
 Two pre-processing workflows

There are two different pre-processing workflows that I use. The first one is borrowed from spatially-unaware scRNA-seq. The main advantage of this approach is that it is fast, the normalization matrix can remain sparse, the values are easy to understand (
e.g.,
 counts of gene X per 10,000 or some transformation of such), and often times for WTX data provides the basis for good clustering of cells in downstream UMAP. Moreover, Scanpy and Seurat each have built-in methods for these steps which make it relatively low friction. However, there are cases were this standard workflow provides unexpected results. One reason is that total counts-based normalization might have unstable variance
1
 such that high-expressing housekeeping genes might have high variance and disproportionately effect downstream dimensional reduction and clustering.

The second, newer workflow that I have been using is based on normalization using Pearson Residuals (PR). The approach itself is not new and scanpy has a built-in method for it (
i.e.
, 
scanpy.experimental.pp.normalize_pearson_residuals
). Until recently the main disadvantage for using PR is that it doesn’t scale well to large number of cells that are typical in CosMx SMI
1
 and it creates a large, dense normalization matrix that can make analysis and read/writing slower. Fortunately, in many cases I do not need to compute and store such a dense matrix. For example, Dan McGuire recently created the R package 
scPearsonPCA
 that can estimate the Principle Components (PCs) of the PR normalized data without needing to convert and use very dense matrices (which we will show below). While this workflow involves converting data between python and R, I generally find the clusters that are derived from such data are comparable to the standard workflow or superior and so I recommend this workflow overall.

In this chapter, I’ll run both the standard and recommended workflows on the colon cancer dataset to provide code for both approaches. I will also do a deep-dive on the choice of UMAP parameters. This particular dataset is a case where the results are more-or-less comparable and I’ll pick the PR data to use throughout the rest of the colon analysis.

Let’s begin. Both options begin the same way: computing the highly variable genes (HVGs). I have found that the 
pearson_residulas
 method to detect HVGs (not to be confused with PR normalization) provides stable results for a variety of CosMx SMI WTX experiments.

Python Code

```
adata.layers["counts"] = adata.X.copy()

1sc.experimental.pp.highly_variable_genes(
    adata,
    flavor='pearson_residuals',
2    n_top_genes=4000,
    layer='counts'
)
```

1

the pearson_residuals ‘flavor’ implement in this function is not the same as the pearson residuals 
normalization method
 (see below).

2

generally 3000-5000 is a good starting point here.

Alternative Approach

The pre-processing workflow presented here can be considered a good overall starting point towards understanding the structure of the data. As such I have omitted more complex workflows and tasks such as integrating morphology-based and/or protein-based PCs into the analysis. For a more involved workflow, see our upcoming WTX paper.

The tabs below show both of these workflows. In each workflow, I set the umap parameters to be identical (40 PCs, 15 nearest neighbors, spread = 2 and minimum distance = 0.02). While these are fixed here, see the box 
Choosing UMAP Parameters
 below to see how these parameters effect the UMAP visual and the Leiden cluster assignments.

Total Counts Workflow
Pearson Residuals Workflow

Workflow: Total counts-based normalization > log transformation > PCA

The procedure below adapts a standard 
scanpy
 
pipeline
. We’ll first normalize each cell the median total counts and then log tranform the data. With this approach I find that scaling the log1p data tends to generate more distinct and biologically relevant clusters so I add that step. Thus, we’ll focus our analysis on the most variable genes found in the dataset. After subsetting down to only these 4000 HVGs, we’ll scale each gene, run PCA, and put these HVG-derivied PCs into the full annData object. On this dataset (466820 cells), this whole process took about a minute.

Python Code

```
sc.pp.normalize_total(adata)
sc.pp.log1p(adata) # -> adata.X
adata.layers['TC'] = adata.X.copy()

# Subset to HVGs and get PCs
adata_hvg = adata[:, adata.var.highly_variable].copy()
sc.pp.scale(adata_hvg) # -> adata.X
sc.tl.pca(adata_hvg, svd_solver='auto') 
adata.obsm['X_pca_TC'] = adata_hvg.obsm['X_pca']
```

Run UMAP and Leiden with the top 40 PCs.

Python Code

```
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40, metric = 'cosine',
  use_rep='X_pca_TC', key_added='neighbors_TC')

UMAP = sc.tl.umap(adata, min_dist=0.02, spread=2, neighbors_key='neighbors_TC', copy=True)

adata.obsm['umap_TC'] = UMAP.obsm['X_umap']
adata.uns['umap_TC_params'] = UMAP.uns['umap']

sc.tl.leiden(adata, resolution=0.5, 
  key_added='leiden_tc', flavor='igraph', 
  n_iterations=2, neighbors_key='neighbors_TC')
```

Workflow: Py to R > scPearsonPCA

The 
scPearsonPCA
 package estimates the PCs of the PR data without computing and storing a dense normalized matrix. Since it is written in R, we’ll add it to this workflow via 
reticulate
 after converting a few objects.

Python Code

```
total_counts_per_cell = adata.layers['counts'].sum(axis=1)
total_counts_per_cell = np.asarray(total_counts_per_cell).flatten()

total_counts_per_target = adata.layers['counts'].sum(axis=0)
total_counts_per_target = np.asarray(total_counts_per_target).flatten()

target_frequencies = total_counts_per_target / total_counts_per_target.sum()

adata_hvg = adata[:, adata.var.highly_variable].copy()
hvgs_counts = adata_hvg.layers['counts'].copy().astype(np.int64)
```

Convert relevant data to R.

R Code

```
library(Matrix)
hvgs_counts <- py$hvgs_counts
rownames(hvgs_counts) <- py$adata_hvg$obs_names$to_list()
colnames(hvgs_counts) <- py$adata_hvg$var_names$to_list()

# the approach we use below expects a sparse matrix with genes (rows) by cells (columns)
t_hvgs_counts <- Matrix::t(hvgs_counts)
t_hvgs_counts <- as(t_hvgs_counts, "CsparseMatrix")
```

Install the scPearsonPCA package (and remotes), if needed.

R Code

```
remotes::install_github("Nanostring-Biostats/CosMx-Analysis-Scratch-Space",
                         subdir = "_code/scPearsonPCA", ref = "Main")
```

Run Seurat-style PCA using scPearsonPCA.

R Code

```
library(scPearsonPCA)

total_counts_per_cell <- py$total_counts_per_cell

target_frequencies <- py$target_frequencies
names(target_frequencies) <- py$adata$var_names$to_list()

pcaobj <- sparse_quasipoisson_pca_seurat(
              x = t_hvgs_counts,
              totalcounts = total_counts_per_cell,
              grate = target_frequencies[rownames(t_hvgs_counts)],
              scale.max = 10,
              do.scale = TRUE,
              do.center = TRUE,
              ncores = 5
          )
pca <- pcaobj$reduction.data@cell.embeddings
```

Add these PCs to the annData object in Python. Run UMAP and Leiden with the top 40 PCs.

Python Code

```
adata.obsm["X_pca_pr"] = r.pca

sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40, metric = 'cosine',
  use_rep='X_pca_pr', key_added='neighbors_pr')

UMAP = sc.tl.umap(adata, min_dist=0.02, spread=2, neighbors_key='neighbors_pr', copy=True)
adata.obsm['umap_pr'] = UMAP.obsm['X_umap']
adata.uns['umap_pr_params'] = UMAP.uns['umap']

sc.tl.leiden(adata, resolution=0.5, 
  key_added='leiden_pr', flavor='igraph', 
  n_iterations=2, neighbors_key='neighbors_pr')
```

Save the annData object.

Python Code

```
adata.write_h5ad(
  os.path.join(r.analysis_dir, "anndata-2-leiden.h5ad"),
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

4.2
 Visualizations

Now that we have the UMAP embeddings and the Leiden cluster assignments in the annData object, we can plot the results of the two methods and compare. The easiest way to plot the Leiden clusters in UMAP space is with scnapy’s built-in method, 
sc.pl.umap
; however, since we have non-typical 
obsm
 keys, we’ll use the more generic 
sc.pl.embedding
 method.

Python Code

```
import matplotlib.pyplot as plt
sc.settings.figdir = r.pp_dir
save_dir = r.pp_dir

adata.obs['log10_nCount_RNA'] = np.log10(adata.obs['nCount_RNA'] + 1)
adata.obs['qcflag'] = adata.obs['qcflag'].astype('category')

fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(15, 10))

sc.pl.embedding(adata,
                basis='umap_TC',
                color='leiden_tc',
                title='Total Counts (leiden_tc)',
                palette=sc.pl.palettes.default_20,
                ax=ax1,
                show=False)

sc.pl.embedding(adata,
                basis='umap_pr',
                color='leiden_pr',
                title='Pearson Residuals (leiden_pr)',
                palette=sc.pl.palettes.default_20,
                ax=ax2,
                show=False)
                
sc.pl.embedding(adata,
                basis='umap_TC',
                color='log10_nCount_RNA',
                title='Total Counts (log10_nCount_RNA)',
                ax=ax3,
                show=False)

sc.pl.embedding(adata,
                basis='umap_pr',
                color='log10_nCount_RNA',
                title='Pearson Residuals (log10_nCount_RNA)',
                ax=ax4,
                show=False)

sc.pl.embedding(adata,
                basis='umap_TC',
                color='qcflag',
                title='Total Counts (FOV QC Flag)',
                palette=sc.pl.palettes.default_20,
                ax=ax5,
                show=False)

sc.pl.embedding(adata,
                basis='umap_pr',
                color='qcflag',
                title='Pearson Residuals (FOV QC Flag)',
                palette=sc.pl.palettes.default_20,
                ax=ax6,
                show=False)

plt.tight_layout()
filename = "umap_umap_compare.png"
save_path = os.path.join(save_dir, filename)
plt.savefig(save_path)          
```

Figure 4.1: UMAP with Leiden clusters from total counts normalization (left) and scPearsonPCA PCs (right). Note that a given cluster label in one plot is not the same as that label in the other plot. Top: Leiden clusters. Middle: cells colored by their total counts. Bottom: cells colored by their QC flag (0 = no flag; 32 = FOV flag; no other flaggeed cells were processed).

Both normalization methods demonstrate effective cluster separation (
Figure 
4.1
). When evaluating these visualizations, it is important to watch for artifacts, particularly sub-clustering driven primarily by total transcript counts, which can signal suboptimal normalization. Additionally, because we retained cells flagged by FOV QC (flag 32), we must verify that these cells do not aggregate into spurious “satellite” clusters which could indicate technical artifacts rather than biological signal. In this dataset, while FOV QC-flagged cells are present in the upper right cluster (Leiden 5 in the total counts workflow and Leiden 11 in the Pearson Residuals workflow), they do not form a distinct artifactual group. Instead, they appear integrated with the dominant cell population, suggesting their distribution is driven by the biology of that region – a hypothesis we will elucidate further in 
?sec-celltyping
.

We can compare which combination of Leiden clusters a given cell was assigned to:

```
import pandas as pd
import seaborn as sns

crosstab = pd.crosstab(
    adata.obs['leiden_tc'],
    adata.obs['leiden_pr']
)

crosstab_norm = crosstab.div(crosstab.sum(axis=1), axis=0)

plt.figure(figsize=(12, 10))
sns.heatmap(
    crosstab_norm,
    annot=True,
    fmt=".2f", cmap="viridis",
    linewidths=.5
)

plt.title("Comparison of Leiden clusters derived from TC or PR workflows", fontsize=16)
plt.ylabel("Total Counts (leiden_tc)", fontsize=12)
plt.xlabel("Pearson Residuals (leiden_pr)", fontsize=12)
filename = "leiden_compare_crosstab.png"
save_path = os.path.join(save_dir, filename)
plt.savefig(save_path)     
```

Figure 4.2: Proportion of cells classified with the pure scanpy-based approach compared to the scPearsonPCA-based appraoch.

Figure 
4.2
 shows a relationship between the clusters derived from our two normalization approaches. Most (15 of 16) Leiden clusters with the total counts approach have more than 85% of cells that are found in a single Leiden cluster for the Pearson Residuals method (e.g., 95% of tc_3 cells mapped to pr_1). One cluster in the total counts approach (tc_1) “split” amongst PR clusters (primarily clusters pr_5, pr_6, and pr_8).

So which is 
better
? With this particular dataset the two approaches are comparable. For the majority of my CosMx SMI WTX analyses I have found the Pearson Residual-based normalization to provide more meaningful biological clusters consistently across datasets so that might be a good overall recommendation – especially if you are working within the R ecosystem. If you are looking for a quick analysis, then the total counts-based approach may work in many cases.

Choosing UMAP Parameters

4.3
 Choosing UMAP Parameters

UMAP helps visualize how groups of cells relate to each other in high-dimensional space. While there isn’t one “correct” UMAP layout, some embeddings are more effective than others at revealing underlying biological structure. We have seen in this chapter how having choice in normalization alone (via PCA) can alter the shape of a UMAP plot even when all other parameters are identical (
Figure 
4.1
).

This section explores how commonly adjusted parameters and inputs other than the choice of normalization influence the resulting UMAP visualization, aiming to build intuition for how to tune these parameters effectively in your dataset.

Let’s systematically vary five key factors:

The quality filtering applied to the input cells.
 Using only high-quality cells often leads to clearer, tighter clusters representing core biological populations. If filtering was too stringent then entire cell populations might be unrepresented.

The number of Principal Components (PCs) used.
 Using a lower number will concetrate on the strongest axes of variation at the cost of reducing any distinction between cell subtypes if that distinction is found in higher PCs. Choosing a higher number of PCs can potentially resolve finer subtypes but also risks incorporating noise, which might slightly blur cluster boundaries or create small, potentially spurious groupings.

The number of nearest neighbors (n_neighbors).
 Lower 
n_neighbors
 tends to emphasize local cluster separation while higher 
n_neigbhors
 tends to form broader clusters.

The distance metric (metric).
 Defines the rule for calculating “closeness” between cells. Euclidean measures straight-line distance while cosine measures the angle between gene expression profiles. Since changing this alters which cells are considered “neighbors,” the parameter can have large impacts on the global shape. Euclidean is the default many packages but cosine often provides more biologically meaningful clusters for CosMx SMI data.

The minimum distance parameter (min_dist).
 Controls how tightly packed points are within a cluster. Higher values tend to make more diffuse clusters.

The spread parameter (spread).
 Controls the separation between clusters. Lower 
spread
 tends to bring clusters closer together.

This list isn’t exhaustive, but varying these while keeping others constant will illustrate their core effects. To make this exploration computationally feasible, we will use a representative subsample of 50,000 cells from our quality-flagged dataset. And to make visualization smooth, we’ll only plot at most 500 cells.

Click the radio buttons below to see what effect these parameter have on the UMAP visualization. Some of these changes are gradual while some dramatically alter the shape and configuration of the UMAP embeddings. You’ll note that filtering out the poor quality cells doesn’t merely remove the cells from the UMAP; instead, the inclusion of poorer-quality data can effect the entire UMAP topology. I have also included the Leiden clusters for these cells. The number of PCs and the number of neighbors effect Leiden cluster cell assignment while 
spread
 and 
min_dist
 do not.

Encouragingly, in this dataset there doesn’t appear to be any UMAP clusters that appear to be made up of cells that were flagged in our FOV QC analysis (
Section 3.1
). If this 
was
 the case, it would suggest that we would want to remove the cells in the effected FOVs.

```
viewof qc_level = Inputs.radio(["no QC filter", "include FOV QC cells", "filter all flags"], {label: "QC Level", value: "include FOV QC cells"})
viewof n_pcs = Inputs.radio([10, 20, 30, 40, 50], {label: "PCs", value: 30})
viewof n_neighbors = Inputs.radio([15, 30, 50], {label: "Neighbors", value: 30})
viewof metric = Inputs.radio(["euclidean", "cosine"], {label: "Metric", value: "cosine"})
viewof mdist = Inputs.radio([0.01, 0.05, 0.2, 0.5], {label: "Min. distance", value: 0.2})
viewof spread = Inputs.radio([0.5, 1.0, 2.0], {label: "Spread", value: 2.0})
viewof colorby = Inputs.radio(["QC", "Leiden"], {label: "Color by", value: "QC"})
```

```
qcMasks = ({
  LOW_COUNTS: 1 << 0, 
  HIGH_COUNTS: 1 << 1, 
  LOW_FEAT: 1 << 2,
  HIGH_FEAT: 1 << 3, 
  LOW_SPLIT: 1 << 4, 
  FOV_QC: 1 << 5, 
  LOW_SBR: 1 << 6
})

flagNames = Object.keys(qcMasks).sort((a, b) => qcMasks[a] - qcMasks[b]);
qcFlagMap = new Map(qc_flags_data.map(d => [d.cell_id, d.qcflag]));

flagColors = {
  const uniqueFlagsInData = Array.from(new Set(qc_flags_data.map(d => d.qcflag))).sort((a, b) => a - b);
  const uniqueFlagsWithZero = Array.from(new Set([0, ...uniqueFlagsInData])).sort((a,b)=> a-b);
  const colors = d3.schemeTableau10;
  const map = {};
  let colorIndex = 0;
  uniqueFlagsWithZero.forEach(flagValue => {
    if (flagValue === 0) { map[flagValue] = "black"; }
    else { map[flagValue] = colors[colorIndex++ % colors.length]; }
  });
  return map;
}

qcColorScale = (flagValue) => flagColors[flagValue ?? 0];
```

```
qcFlagLegend = {
  try {
    const uniqueFlagsWithZero = Object.keys(flagColors).map(Number).sort((a,b)=> a-b);
    const tableRows = uniqueFlagsWithZero.map(flagValue => {
      const flagColor = flagColors[flagValue]; // Use static map
      const circles = flagNames.map(name => {
         const mask = qcMasks[name];
         const isSet = (flagValue & mask) > 0;
         const circleFill = isSet ? flagColor : "#e0e0e0";
         const circleSvg = `<svg width="15" height="15"><circle cx="7.5" cy="7.5" r="6" fill="${circleFill}" stroke="${isSet ? 'black' : '#ccc'}" stroke-width="1"></circle></svg>`;
         return `<td style="text-align: center;">${circleSvg}</td>`;
      }).join('');
      const rowHeader = `<th scope="row" style="text-align: right; padding-right: 10px; white-space: nowrap;">
                           <span style="display: inline-block; width: 12px; height: 12px; background-color: ${flagColor}; border: 1px solid #555; margin-right: 5px; vertical-align: middle;"></span>
                           ${flagValue === 0 ? 'Passed' : flagValue}
                         </th>`;
      return `<tr>${rowHeader}${circles}</tr>`;
    }).join('');
    const headerCells = flagNames.map(name =>
      `<th style="height: 100px; text-align: center; vertical-align: bottom; padding-bottom: 5px; font-size: 0.8em; white-space: nowrap;">
         <span style="writing-mode: vertical-lr; transform: rotate(180deg);">${name.replace(/_/g, ' ')}</span>
       </th>`
    ).join('');
    const tableHeader = `<thead><tr><th style="vertical-align: bottom;">Flag Value</th>${headerCells}</tr></thead>`;
    return html`<table style="border-collapse: collapse; margin-top: 10px; font-size: 0.9em; table-layout: fixed;">
                   ${tableHeader}<tbody>${tableRows}</tbody>
                 </table>`;
   } catch (error) {
     console.error("Error generating QC Legend:", error);
     return html`<div>Error generating QC Legend</div>`;
   }
}
```

```
leidenScaleAndLegend = {
  let scale, legend;
  try { // Add try...catch
    // Check if query_data is ready and has 'leiden'
    if (!query_data || query_data.length === 0 || !query_data[0].hasOwnProperty('leiden')) {
        console.warn("Leiden data (query_data) not ready for legend/scale.");
        scale = d3.scaleOrdinal().domain(["0"]).range(["grey"]); // Placeholder scale
        legend = html`<div><ul style="list-style: none; padding-left: 0; margin-top: 10px; font-size: 0.9em;">
                        <li style="margin-bottom: 2px;"><span style="display: inline-block; width: 12px; height: 12px; background-color: grey; border: 1px solid #555; margin-right: 5px; vertical-align: middle;"></span> Cluster 0</li>
                      </ul>(Loading...)</div>`; // placeholder
    } else {
        const uniqueClusters = Array.from(new Set(query_data.map(d => d.leiden))).sort((a, b) => a - b);
        scale = d3.scaleOrdinal(d3.schemeTableau10).domain(uniqueClusters);

        const legendItems = uniqueClusters.map(cluster => {
           const color = scale(cluster);
           const clusterLabel = String(cluster);
           return `<li style="margin-bottom: 2px;"><span style="display: inline-block; width: 12px; height: 12px; background-color: ${color}; border: 1px solid #555; margin-right: 5px; vertical-align: middle;"></span> Cluster ${clusterLabel}</li>`;
        }).join('');
        legend = html`<ul style="list-style: none; padding-left: 0; margin-top: 10px; font-size: 0.9em;">${legendItems}</ul>`;
    }
  } catch(error) {
     console.error("Error generating Leiden Legend:", error);
     scale = () => 'grey';
     legend = html`<div>Error generating Leiden Legend</div>`;
  }
  return { scale, legend };
}

leidenColorScale = leidenScaleAndLegend.scale
leidenLegendHtml = leidenScaleAndLegend.legend
```

```
d3 = require("d3@7")

width = 500
height = 500
marginTop = 20
marginRight = 20
marginBottom = 30
marginLeft = 40

xScale = d3.scaleLinear().domain([0, 1]).range([marginLeft, width - marginRight])
yScale = d3.scaleLinear().domain([0, 1]).range([height - marginBottom, marginTop])

svg = d3.create("svg")
    .attr("width", width)
    .attr("height", height)
    .attr("viewBox", [0, 0, width, height])
    .attr("style", "max-width: 100%; height: auto;");

xAxis = d3.axisBottom(xScale)
    .ticks(width / 80)
    .tickSizeOuter(0)
    .tickSizeInner(-(height - marginTop - marginBottom));

yAxis = d3.axisLeft(yScale)
    .ticks(height / 40)
    .tickSizeOuter(0)
    .tickSizeInner(-(width - marginLeft - marginRight));

gx = svg.append("g")
    .attr("class", "x-axis")
    .attr("transform", `translate(0,${height - marginBottom})`)
    .call(xAxis);

gy = svg.append("g")
    .attr("class", "y-axis")
    .attr("transform", `translate(${marginLeft},0)`)
    .call(yAxis);

svg.selectAll(".tick line")
   .attr("stroke-opacity", 0.1);
```

```
svg.append("text")
    .attr("x", width - marginRight)
    .attr("y", height - marginBottom - 4)
    .attr("fill", "currentColor")
    .attr("text-anchor", "end")
    .text("UMAP 1 →");
```

```
svg.append("text")
    .attr("x", marginLeft + 4)
    .attr("y", marginTop)
    .attr("fill", "currentColor")
    .attr("text-anchor", "start")
    .attr("dominant-baseline", "hanging")
    .text("↑ UMAP 2");
```

```
-
svg.append("clipPath")
    .attr("id", "clip")
  .append("rect")
    .attr("x", marginLeft)
    .attr("y", marginTop)
    .attr("width", width - marginLeft - marginRight)
    .attr("height", height - marginTop - marginBottom);
```

```
pointGroup = svg.append("g")
    .attr("fill", "black")
    .attr("clip-path", "url(#clip)");
```

```
{ // Reactive block
  const updateVisualization = () => {
    const duration = 750;
    
    const currentScale = colorby === "QC" ? qcColorScale : leidenColorScale;

    if (!currentScale) { 
        console.error("Scale missing"); 
        return; 
    }
    
    if (!query_data || query_data.length === 0) {
       console.warn("No data available for plotting.");
       pointGroup.selectAll("circle").transition().duration(duration).attr("opacity", 0).remove();
       return; 
    }

    const xExtent = d3.extent(query_data, d => d.umap_1);
    const yExtent = d3.extent(query_data, d => d.umap_2);

    const xPad = (xExtent[1] - xExtent[0]) * 0.05;
    const yPad = (yExtent[1] - yExtent[0]) * 0.05;

    xScale.domain([xExtent[0] - xPad || -1, xExtent[1] + xPad || 1]);
    yScale.domain([yExtent[0] - yPad || -1, yExtent[1] + yPad || 1]);

    svg.select(".x-axis")
      .transition().duration(duration)
      .call(xAxis)
      .on("start", () => {
         svg.selectAll(".x-axis .tick line").attr("stroke-opacity", 0.1);
      });

    svg.select(".y-axis")
      .transition().duration(duration)
      .call(yAxis)
      .on("start", () => {
         svg.selectAll(".y-axis .tick line").attr("stroke-opacity", 0.1);
      });

    pointGroup.selectAll("circle")
      .data(query_data, d => d.cell_id)
      .join(
        enter => enter.append("circle")
            .attr("cx", d => xScale(d.umap_1)) 
            .attr("cy", d => yScale(d.umap_2))
            .attr("r", 2.5)
            .attr("fill", d => {
                try {
                    const valueToColor = colorby === "QC" ? qcFlagMap.get(d.cell_id) : d.leiden;
                    return currentScale(valueToColor) || 'grey';
                } catch(e) { return 'grey'; }
            }) 
            .attr("opacity", 0)
            .call(enter => enter.transition().duration(duration).attr("opacity", 0.8)),
        
        update => update
            .call(update => update.transition().duration(duration)
                .attr("cx", d => xScale(d.umap_1))
                .attr("cy", d => yScale(d.umap_2))
                .attr("fill", d => { 
                    try {
                        const valueToColor = colorby === "QC" ? qcFlagMap.get(d.cell_id) : d.leiden;
                        return currentScale(valueToColor) || 'grey';
                    } catch(e) { return 'grey'; }
                })
                .attr("opacity", 0.8)
             ),
        
        exit => exit
            .call(exit => exit.transition().duration(duration).attr("opacity", 0).remove())
      );
  };
  
  try { 
    updateVisualization();
  } catch(error) {
    console.error("Error during D3 updateVisualization:", error);
  }

  return svg.node(); 
}
```

In the dot plot on the bottom left provides a QC flag legend. For example, QC flag ‘5’ represents cells that were flagged for having low counts and low features whereas QC flag ‘96’ represents cells that wee flagged for FOV QC as wells as low SBR.

If you want to further explore this subset, you can examine the 
query_data
 and 
qc_flags_data
 dataframes below.

For the remainder of this chapter, I will focus on the PR-based method.

I find it’s helpful to:

Have more control of the plotting aesthetics and label multiple sub-clusters of a given Leiden cluster for clarity and

isolate the Leiden clusters and visualize them in both UMAP space and physical (XY) space to see if there are regions in the tissue that might provide clues about the cell types.

Instead of the default 
plotDots
 colors, let’s define our own.

R Code

```
# define colors semi-manually instead of using the default colors
column <- 'leiden_pr'
column_levels <- levels(py$adata$obs[[column]])
n_levels <- length(column_levels)

if(n_levels<27){
  colors_use <- pals::alphabet(n_levels)
} else if(n < 53){
  colors_use <- c(pals::alphabet(26), pals::alphabet2(n_levels-26))
} else {
  stop("consider fewer groups")
}

names(colors_use) <- column_levels

# saving colors for later
results_list[['leiden_global_names']] <- names(colors_use)
results_list[['leiden_global_colors']] <- as.character(colors_use)
saveRDS(results_list, results_list_file)
```

Plot the cells in XY space and UMAP space and color based on 
leiden_pr
.

R Code

```
1group_prefix <- "leiden"

pp_assets_dir <- file.path(analysis_asset_dir, "preprocessing")

# XY (global only)
plotDots(py$adata, color_by='leiden_pr',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = pp_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Leiden (PR)",
                  override.aes = list(size = 3) ) )
              )
              )

# XY (facets only)
plotDots(py$adata, color_by='leiden_pr',
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = pp_assets_dir,
                  fileType = "png",
                  dpi = 100,
                  width = 5,
                  height = 5,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Leiden (PR)",
                  override.aes = list(size = 3) ) )
              )
              )

# UMAP (global only)
plotDots(py$adata, 
              obsm_key = "umap_pr",
              color_by='leiden_pr',
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001, alpha=0.1
                  ),
                  geom_label_params = list(
                    size = 4
                  ),
                  labels_on_plot = data.frame(),
                  directory = pp_assets_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8,
                  height = 8,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("UMAP 1"),
                ylab("UMAP 2"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                # guides(color = guide_legend(
                #   title="Cell Type",
                #   override.aes = list(size = 3) ) ), 
                theme(legend.position = "none")
              )
            )

# UMAP (facets only)
plotDots(py$adata, 
              obsm_key = "umap_pr",
              color_by='leiden_pr',
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001, alpha=0.1
                  ),
                  geom_label_params = list(
                    size = 2
                  ),
                  labels_on_plot = data.frame(),
                  directory = pp_assets_dir,
                  fileType = "png",
                  dpi = 100,
                  width = 5,
                  height = 5,
                  prefix=group_prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("UMAP 1"),
                ylab("UMAP 2"), 
                coord_fixed(),
                scale_color_manual(values = colors_use),
                guides(color = guide_legend(
                  title="Cell Type",
                  override.aes = list(size = 3) ) )
              )
            )
```

1

in the plotting below, we will use this name to parse out files.

Here are the overall (global) plots.

Leiden - UMAP
Leiden - XY

Figure 4.3: UMAP with Leiden (PR-based) cells.

Figure 4.4: XY with Leiden (PR-based) cells.

Here are the individual plots
2
 we created organized by Leiden cluster. From these pairs of plots one can quickly see how some Leiden clusters are spatially restricted. For example, Leiden 0 consists of cells in the top part of the tissue (
i.e.
, the non-tumoral epithelium). Similarly, cluster 12 occupies the left-most region of the tissue.

0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

4.4
 Conclusion

And with that, we’ve navigated the essential pre-processing steps. Starting with our quality-controlled cell data, we applied normalization to account for technical variations, identified the most informative genes, and used PCA to reduce the data’s dimensionality. Building upon this foundation, we generated UMAP embeddings for visualization and performed Leiden clustering to partition the cells into distinct groups based on their expression profiles.

The interactive exploration highlighted a critical point: parameters matter. Choices made during normalization, dimensionality reduction, and clustering significantly influence the final UMAP layout and cluster assignments. There isn’t a single “correct” set of parameters, but understanding their effects allows you to tailor the analysis to best reveal the biological structures relevant to your specific questions.

The resulting AnnData object, now enriched with normalized data layers, PCA coordinates, UMAP embeddings, and Leiden cluster labels, is primed for the next crucial phase: assigning biological meaning to these patterns. In the following chapters we will delve into grouping cells based on their spatial domain and their cell types.

1. 
Hafemeister, C. & Satija, R. Normalization and variance stabilization of single-cell 
RNA-seq
 data using regularized negative binomial regression. 
Genome Biol.
 
20
, 296 (2019).

when I tried using the 
sc.experimental.pp.normalize_pearson_residuals
 method on this dataset, the OS crashed (>200 GBs of RAM).
↩︎

To see how to generate this type of output, click the 
</>
 icon on the top right of this chapter and then click 
view source
.
↩︎


====================
START OF FILE: quality-processing.html
====================

This section is critical in any data analysis. We’ll pass the data through a series of filters to ensure the downstream processing steps contain high-quality data. We do this by screening and flagging any FOVs that might have lower quality and running a counts-based filter.

R code

```
source("./preamble.R")
reticulate::source_python("./preamble.py")
analysis_dir <- file.path(getwd(), "analysis_results")
input_dir <- file.path(analysis_dir, "input_files")
output_dir <- file.path(analysis_dir, "output_files")
analysis_asset_dir <- "./assets/analysis_results"
qc_dir <- file.path(output_dir, "qc")
if(!dir.exists(qc_dir)){
  dir.create(qc_dir, recursive = TRUE)
}
results_list_file = file.path(analysis_dir, "results_list.rds")
if(!file.exists(results_list_file)){
  results_list <- list()
  saveRDS(results_list, results_list_file)
} else {
  results_list <- readRDS(results_list_file)  
}
```

Load the dataset we generated in 
Chapter 2
.

R Code

```
py$adata <- py$ad$read_h5ad(py$os$path$join(analysis_dir, "anndata-0-initial.h5ad"))
```

3.1
 FOV QC

Lower quality FOVs generally result in reduced overall gene expression or reduced signal from select genes. Potential causes for lower FOV quality (e.g. lower relative signal for all/select genes for a given FOV compared to majority of FOVs) include tissue/section quality, high autofluorescence, and inadequate fiducials. We can quantify this signal loss using the FOV QC method as described recently in this 
scratch space tool
. For a more detailed explanation of the the FOV QC functions, expand the box below.

Since the FOV QC code was written in R, convert relevant annData components to R objects.

Python Code

```
meta = adata.obs.copy()
expr = adata.X.astype('float64')
```

Run the 
runFOVQC
 routine. The 
source
 call below will load several functions into memory. Since this dataset is from WTX, we’ll use the barcode patterns from 
Hs_WTX
.

R Code

```
# source the necessary functions:
1source("https://raw.githubusercontent.com/Nanostring-Biostats/CosMx-Analysis-Scratch-Space/Main/_code/FOV%20QC/FOV%20QC%20utils.R")

allbarcodes <- readRDS(url("https://github.com/Nanostring-Biostats/CosMx-Analysis-Scratch-Space/raw/Main/_code/FOV%20QC/barcodes_by_panel.RDS"))

results_list[['barcodes']] <- allbarcodes['Hs_WTX']
saveRDS(results_list, results_list_file)
```

1

For historic reasons, the characters in the barcode string are duplicated.

Understanding the FOV QC parameters

This deep dive shows a how the two tuning parameters of the FOV QC function, 
max_prop_loss
 and 
max_totalcount_loss
), affect the results.

The parameter 
max_prop_loss
 sets a tolerance for the maximum allowable proportion of signal loss for any single barcode bit before an FOV is flagged. For example, if we set 
max_prop_loss
 to 0.3, it means we’d accept a given 
bit
 given if it has lost 30% of its original strength. While 
max_prop_loss
 focuses on the errors in a single specific barcode 
bit
, 
max_totalcounts_loss
 looks at the bigger picture. It asks, “Is this entire FOV significantly dimmer or less populated with transcripts than it should be?” This can help detect broader issues like poor tissue quality, focusing problems, or reagent failures in that specific area.

Let’s see what happens to the number of flagged FOVs when adjust these parameters.

```
viewof max_prop_loss = Inputs.range([0.1, 0.6], {
  step: 0.1,
  label: "Max Proportion Loss"
})
viewof max_totalcounts_loss = Inputs.range([0.1, 0.6], {
  step: 0.1,
  label: "Max Total Counts Loss"
})
```

This code below will plot the spatial distribution of failed FOVs. Feel free to adjust the code, if desired.

With the functions loaded, execute the 
runFOVQC
 function. For this example, I choose a less restrictive parameter set (
max_prop_loss
 = 0.4 and 
max_totalcounts_loss
 = 0.3).

Plot the flagged FOVs in R simply with 
mapFlaggedFOVs(res)
 function to get the spatial layout of any FOVs that were flagged. In this case (
Figure 
3.1
), you can see some FOVs that were flagged along the tissue perimeter.

Figure 3.1: Spatial location of the flagged FOVs.

For the targets that were flagged, plot how many FOVs they were flagged in.

R Code

```
flagged_genes <- res$flagged_fov_x_gene[,2]
1flagged_genes <- flagged_genes[!is.na(flagged_genes)]
flagged_genes <- as.data.frame(rev(sort(table(flagged_genes))))
colnames(flagged_genes)[1] <- 'target'

df <- data.frame(target=py$adata$var_names$to_list())
df <- merge(df, flagged_genes, by="target", all.x=TRUE, all.y=FALSE)
df$Freq[is.na(df$Freq)] <- 0L

py$adata$var['fov_qc_flagged'] <- as.integer(df$Freq)

p <- ggplot(flagged_genes, aes(x = factor(Freq), fill = factor(Freq))) +
  geom_bar() +
  geom_text(stat='count', aes(label=after_stat(count)), vjust=-0.5) +
  labs(x = "Number of FOVs", y = "Number of Flagged Genes") +
  theme_minimal() +
  scale_x_discrete(breaks = 1:13) + 
  theme(legend.position = "none")

ggsave(p, filename=file.path(qc_dir, "genes_impacted_in_flagged_fovs.png"),
       width=4, height=5, dpi=150, type="cairo")
```

1

A value of NA here means the gene in a given FOV was 
not
 flagged.

Figure 3.2: Number of targets impacted in a given number of FOVs.

In 
Figure 
3.2
, there are only a few genes (149) that were flagged in three FOVs. If we found a set of genes that were systematically flagged in many FOVs, we may consider removing the impacted FOVs. Alternatively we could remove the impacted genes from all FOVs. In this sample, it’s probably fine to ignore this result.

With the 
FOVSignalLossSpatialPlot
 function, we can gain a higher resolution perspective by plotting the 7x7 sub-FOV grids across space and coloring these sub-FOV grids by the change in our expected total counts. In 
Figure 
3.3
, our focus is on FOVs that are solidly blue which would suggestion fewer transcripts than other FOVs. In this example, eight of the FOVs flagged as low total counts occured along the tissue border and were not complete 7x7 grids. The other section in 
Figure 
3.3
 is contiguous and may suggest a domain or type of tissue with lower overall transcripts.

Figure 3.3: Number of genes impacted in a given number of FOVs.

To see details how these FOVs might have been impacted, we can use the function below to plot the signal lostt found for each cycle-by-reporter combination.

R Code

```
library(ComplexHeatmap)
library(circlize)

FOVEffectsHeatmap <- function(res, fovs=NULL,
                              cluster_rows = FALSE, 
                              cluster_columns = TRUE) {
  if(is.null(fovs)){
    fovs <- rownames(res$fovstats$bias)
  }

  transposed_matrix <- t(res$fovstats$bias[fovs,])
  col_fun = colorRamp2(
    breaks = c(min(transposed_matrix), 0, max(transposed_matrix)), 
    colors = c("magenta", "white", "cyan") 
  )
  
  ht_obj <- ComplexHeatmap::Heatmap(
      matrix = transposed_matrix,
      name = "FOV bias", 
      col = col_fun, 
      cluster_rows = cluster_rows, 
      cluster_columns = cluster_columns, 
      show_row_dend = TRUE, 
      show_column_dend = TRUE, 
      row_names_gp = gpar(fontsize = 7), 
      column_names_gp = gpar(fontsize = 8)
  )
  
  return(ht_obj)
}

png(file.path(qc_dir, "FOVEffectsHeatmap.png"), 
    width=10, height=15, res=350, units = "in", type = 'cairo')
  draw(FOVEffectsHeatmap(res, fovs=res$flaggedfovs))
dev.off()

results_list$flaggedfovs <- res$flaggedfovs
saveRDS(results_list, results_list_file)
```

Figure 3.4: Reporter-by-FOV combinations that were flagged.

What we are checking for in 
Figure 
3.4
 is:

Any report cycles that show systematically reduced signal across many FOVs

Any FOVs that show underperforming multiple reporter cycles.

While we do see two reporter cycles (19 and 27) with two flagged FOVs (155 and 239), each, there’s no evidence of a systemic signal lostt in any reporter cycle. If we did find strong evidence, one could conservatively filter out the genes that are present in that reporter cycle. This would be roughly 2,000 genes for a given reporter cycle. Looking from the perspective of the FOVs (#2), we see only a handful of FOVs showed one (or two) underperforming reporter cycles. These include FOVs 92, 113, 155, 160, and 239. At this point, one could remove all FOVs that were flagged (
length(res$flaggedfovs)
; 23 in this case), just the five that we found evidence of signal lostt in one or more reporter cycles, or flag the cells within the impacted FOVs and see if any downstream results are impacted. For this analysis, I’ll simply do the “flag and monitor” approach.

R Code

```
meta <- py$adata$obs
meta$fovqcflag <- ifelse(meta$fov %in% as.numeric(res$flaggedfovs), 1, 0)
py$adata$obs$fovqcflag <- meta$fovqcflag
```

3.2
 Cell-level QC

Where the previous section examined signal at the FOV level, this section examines target counts at the cell level. The purpose of this filter is simple: to remove 
low signal outliers
 while keeping the 
biology
. The cells in a given dataset comprise of a mix of:

viable, intact cells with high signal

damaged or dying cells. These may have leaky membranes and may have reduced cytoplasmic RNA

imperfect segmentation of cells – especially around FOV borders

and so our aim is to filter out cells from the latter two scenarios.

Counts-based filtering has a trade-off. While several downstream “tertiary” analyses account for low signal in a variety of ways (discussed later), many of the pre-processing steps are sensitive to the quality of cells that are feed into them. Setting a lenient cutoff can introduce low-quality cells in dimensional reductions like PCA and UMAP and can break up clustering patterns (creating spurious clusters or merging otherwise distinct clusters). On the other hand, a stringent cutoff can introduce unexpected signal lostt. This is because cell types vary in their transcript counts so removing cells based on counts will distort the composition of cells in your data.

Best practice for counts based filtering of CosMx data includes:

examining the distribution of transcript and gene counts

choosing an initial permissive or lenient cutoff

examining signal relative to background

plotting the spatial distribution of flagged cells in space

removing small cell artifacts around the FOV borders

including plots of total transcripts in your downstream pre-processing steps

Alternative Approach

There are many cell-level attributes that one can use as a bases for filtering and it is recommended to use metrics relevant to your tissue. For example, if you are analyzing brain, you many want to incorporate or evaluate cell area, eccentricity, or other morphological characteristics that are available in the metadata. For a list of cell metadata column definitions, you can see 
this Scratch Space blog post

3.2.1
 Counts and Features

For the distribution of transcript and gene counts, I like to look at the joint distribution in addition to the univariate distributions. In the code below I set a permissive, symmetrical threshold of 2.5 standard deviations (SDs) around the mean (in log10 space).

```
# meta <- py$adata$obs
counts_min_threshold <- round(10^(mean(log10(meta$nCount_RNA)) - 2.5*sd(log10(meta$nCount_RNA))))
features_min_threshold <- round(10^(mean(log10(meta$nFeature_RNA)) - 2.5*sd(log10(meta$nFeature_RNA))))
counts_max_threshold <- round(10^(mean(log10(meta$nCount_RNA)) + 2.5*sd(log10(meta$nCount_RNA))))
features_max_threshold <- round(10^(mean(log10(meta$nFeature_RNA)) + 2.5*sd(log10(meta$nFeature_RNA))))

results_list['counts_min_threshold'] = counts_min_threshold
results_list['features_min_threshold'] = features_min_threshold
results_list['counts_max_threshold'] = counts_max_threshold
results_list['features_max_threshold'] = features_max_threshold

meta$counts_filter <- ifelse(
  meta$nFeature_RNA >= features_min_threshold & 
         meta$nFeature_RNA <= features_max_threshold & 
         meta$nCount_RNA >= counts_min_threshold & 
         meta$nCount_RNA <= counts_max_threshold
  , "pass", "filtered")

results_list['prop_counts_based_filter'] <- sum(meta$counts_filter=="pass") / nrow(meta)
saveRDS(results_list, results_list_file)

library(scales)
p <- ggplot(
  data = meta,
  aes(x=nFeature_RNA, y=nCount_RNA, color=counts_filter)) + 
  geom_point(alpha=0.002, pch=".") +
  scale_color_manual(values=c("pass"="dodgerblue", "filtered"="darkorange")) +
  geom_vline(xintercept = c(features_min_threshold, features_max_threshold), lty="dotted") + 
  geom_hline(yintercept = c(counts_min_threshold, counts_max_threshold), lty="dotted") + 
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) +
  scale_y_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) + 
  theme_minimal() + 
  coord_fixed() + 
  theme(legend.position = "none")
  
p <- ggMarginal(p, type = "density")

ggsave(filename = file.path(qc_dir, "qc_joint_distribution.png"), p,
       width=8, height=8, type = 'cairo')

p1 <- ggplot(
      data=meta, 
      aes(x=nCount_RNA)) + 
      geom_density(alpha=0.01) + 
      # scale_x_log10() +
      theme_minimal() + 
      geom_vline(xintercept = c(counts_min_threshold, counts_max_threshold), lty="dotted") 

ggsave(filename = file.path(qc_dir, "qc_dist_counts.png"), p1,
       width=8, height=8, type = 'cairo')

p2 <- ggplot(
      data=meta, 
      aes(x=nFeature_RNA)) + 
      geom_density(alpha=0.01) + 
      # scale_x_log10() +
      theme_minimal() + 
      geom_vline(xintercept = c(features_min_threshold, features_max_threshold), lty="dotted") 

ggsave(filename = file.path(qc_dir, "qc_dist_features.png"), p2,
       width=8, height=8, type = 'cairo')

p3 <- ggplot(
        data=meta) +
      geom_point(
        aes(x=x_slide_mm, y=y_slide_mm, color=counts_filter),
        size=0.001, alpha=0.02) + 
      coord_fixed() + theme_bw() + 
      scale_color_manual(values=c("pass"="dodgerblue", "filtered"="darkorange")) + facet_wrap(~counts_filter) + 
      guides(color = guide_legend(override.aes = list(size = 7, alpha = 1)))

ggsave(filename = file.path(qc_dir, "qc_xy_flagged.png"), p3,
       width=8, height=8, type = 'cairo')
```

The tabs below show the summary plots. Based on the distributions, the following thresholds we derived from the data: min counts = 148, max counts = 9973, min features = 120, max features = 6016. This removes about 2% of the data. The spatial layout of these flagged cells shows some concentration along the perimeter and epithelial regions. No concentration within FOVs were observed (
Figure 
3.8
).

Transcripts per cell
Features per cell
Joint Distribution
Spatial Arrangement of flagged cells

```
render(file.path(analysis_asset_dir, "qc"), "qc_dist_counts.png", qc_dir)
```

Figure 3.5: Distribution of transcripts per cell.

Figure 3.6: Distribution of features per cell.

Figure 3.7: Joint distribution of targets (features vs counts).

Figure 3.8: Spatial arrangement of flagged cells.

3.2.2
 (Optional) Cells Near FOV Borders

In this particular dataset, 6.2% of the cells were located on the border of FOVs (
i.e.
, touching the FOV edge). This is a minority of cells that in the analysis as a whole shouldn’t affect downstream analyses. For this reason this step is optional.

Within the metadata there is a column named 
SplitRatioToLocal
. For cells that are adjacent to the FOV boundaries, the 
SplitRatioToLocal
 metric measures the cell area relative to the mean area of cells in the FOVs. For 
0 < SplitRatioToLocal < 1
, the cell is smaller than average and for 
SplitRatioToLocal > 1
 the cell is larger than average. A value of 0 means the cell is not along the border. Let’s plot the distribution of boarder abutting cells (
i.e.
, 
SplitRatioToLocal > 0
) and tentatively choose a cutoff of SplitRatioToLocal = 0.5 which translates to removing cells that are 0.5 (50%) the average cell size. Since this is a ratio, we’ll plot in log2 space (
log2(SplitRatioToLocal) < -1
).

R Code

```
results_list['SplitRatioToLocalThreshold'] <- 0.5
saveRDS(results_list, results_list_file)

# meta <- py$adata$obs

library(patchwork)
library(scales)

p_detail <- ggplot(
    data = meta %>% filter(SplitRatioToLocal != 0), 
    aes(x = log2(SplitRatioToLocal))) + 
    geom_histogram(bins = 100, fill = "steelblue") +
    labs(
      x = expression(log[2]("SplitRatioToLocal")),
      y = "Number of FOV border cells"
    ) + 
    theme_minimal() + 
    geom_vline(xintercept = log2(results_list[['SplitRatioToLocalThreshold']]), 
               color = "darkorange", lty = "dashed")
pie_data <- meta %>%
  mutate(Category = if_else(SplitRatioToLocal > 0, "Border cell", "Non-border cell")) %>%
  count(Category) %>%
  mutate(
    Percentage = (n / sum(n)) * 100,
    Label = paste0(Category, " (", round(Percentage, 1), "%)")
  )

p_pie <- ggplot(pie_data, aes(x = 2, y = n, fill = Category)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar("y", start = 0) +
  scale_fill_manual(values = c("Border cell" = "steelblue", "Non-border cell" = "gray90")) +
  geom_text(aes(label = Label), 
            position = position_stack(vjust = 0.5), 
            size = 3, 
            fontface = "bold") +
  theme_void() +
  xlim(0.5, 2.5) + 
  theme(legend.position = "none")

full_plot <- p_detail + 
  inset_element(
    p_pie, 
    left = 0.6, bottom = 0.6, 
    right = 1.0,
    top = 1.0
  )

ggsave(filename = file.path(qc_dir, "qc_splitratiotolocal.png"), full_plot,
       width=5, height=5, type = 'cairo')
```

Figure 3.9: Distribution of SplitRatioToLocal for cells abutting an FOV border. Overlay: proportion of border cells relative to all cells.

3.3
 Regional-level cell QC

It’s possible that some regions of the tissue might have high background. We can evaluate the total signal relative to the background. For this approach we are interested in the Signal to Background Ratio (SBR) in neighborhoods or tissue regions as opposed to cell-level measures or target-level measures. Since the number of targets is not comparable to the number of negative probes, we’ll consider the average target expression (S) divided by the average background expression.

\[sbr = \frac{S}{\mu_{B}}\]

When passing the data through this equation, you’ll likely find that many cells have an undefined SBR due to the sparse nature of background counts. To mitigate this effect, we can spatially smooth the transcript and background counts before applying this equation. To do this we’ll use the 
liana
 package that creates a connectivities matrix based on a Gaussian kerneland then multiple this matrix by the negative probe matrix and the expression matrix to get the spatially-weighted matrices for each. For more information on this spatial smoothing see 
Chapter 7
.

Python Code

```
import liana as li

li.ut.spatial_neighbors(
    adata,
1    bandwidth=0.010,
2    cutoff=0.080,
    kernel='gaussian',
    set_diag=True,
    key_added = 'liana',
    standardize=True
)

connectivities = adata.obsp['liana_connectivities']
adata.obsm['counts_neg_spatially_smooth'] = connectivities @ adata.obsm['counts_neg']
adata.obsm['counts_spatially_smooth'] = connectivities @ adata.X
smoothed_mean_neg = np.ravel(adata.obsm['counts_neg_spatially_smooth'].mean(axis=1))
smoothed_mean_target = np.ravel(adata.obsm['counts_spatially_smooth'].mean(axis=1))
epsilon = 1e-9
SBR = smoothed_mean_target / (smoothed_mean_neg + epsilon)
```

1

use 10 µm bandwidth (this tunable)

2

anything below this value is considered 0 (this is tunable)

Alternative Approach

While not entirely equivalent, if you run into memory issues with creating a spatially-weighted expression matrix, you can instead spatially smooth the total counts from the metadata column 
nCount_RNA
.

What we are looking for in SBR are larger tissue regions with low SBR – not necessarily individual cells with low SBR. Looking at 
Figure 
3.10
 we see a low SBR region on the top of the tissue just below the epithelium. This region corresponds to an area of smooth muscle and we’ll see in the next section that this region partially overlaps with an area flagged by the FOV-level QC. Since these low SBR cells (i.e., 
log2(SBR) < 0
) are concentrated spatially, we’ll choose to flag them for removal.

R Code

```
meta$SBR <- py$SBR

sbr_breaks <- c(-Inf, -1, 0, 1, 2, 3, Inf)

sbr_labels <- c("<= -1", "-1 to 0", "0 to 1", "1 to 2", 
                "2 to 3", "> 3")
sbr_labels <- paste0(sbr_labels,
                     paste0(" (", round(100 * table(cut(log2(meta$SBR), 
                                breaks = sbr_breaks)) / nrow(meta), 1), "%)"))

manual_colors <- c(
  "<= -1"   = "#D73027",  # 
  "-1 to 0" = "#F46D43",  # 
  "0 to 1"  = "#D9EF8B",  # 
  "1 to 2"  = "#A6D96A",  # 
  "2 to 3"  = "#1A9850",  # 
  "> 3"     = "#006837"   # 
)
names(manual_colors) <- sbr_labels

p <- ggplot(data = meta) +
  geom_point(
    aes(
      x = x_slide_mm,
      y = y_slide_mm,
      color = cut(log2(SBR), breaks = sbr_breaks, labels = sbr_labels)
    ),
    size = 0.001, alpha = 1
  ) +
  scale_color_manual(values = manual_colors) +
  guides(color = guide_legend(
    override.aes = list(size = 7, alpha = 1) # Sets legend points to size 5 and opaque
  )) +
  labs(color = "log2(SBR)") +
  coord_fixed() +
  theme_bw()

ggsave(filename = file.path(qc_dir, "qc_xy_sbr.png"), p,
       width=10, height=10, type = 'cairo')
```

Figure 3.10: Spatially-smoothed Signal to Background for each cell.

3.4
 Combining Flags

Taken together, what cells were flagged and why? 
Figure 
3.11
 shows the configuration of the flags.

R Code

```
library(UpSetR)
filter_list <- list(
  `Low SplitRatio` = meta %>%
    filter(SplitRatioToLocal > 0 & SplitRatioToLocal < results_list[['SplitRatioToLocalThreshold']]) %>%
    pull(cell_ID),
  
  `Low Counts` = meta %>%
    filter(nCount_RNA < results_list[['counts_min_threshold']]) %>%
    pull(cell_ID),
  
  `High Counts` = meta %>%
    filter(nCount_RNA > results_list[['counts_max_threshold']]) %>%
    pull(cell_ID),
  
  `Low Features` = meta %>%
    filter(nFeature_RNA < results_list[['features_min_threshold']]) %>%
    pull(cell_ID),
    
  `High Features` = meta %>%
    filter(nFeature_RNA > results_list[['features_max_threshold']]) %>%
    pull(cell_ID), 
  
  `Low SBR` = meta %>% 
    filter(log2(SBR) < 0) %>%
    pull(cell_ID),
  
  `FOV QC` = meta %>% 
    filter(fovqcflag == 1) %>%
    pull(cell_ID)
)

filter_list <- purrr::keep(filter_list, ~ length(.) > 0)

png(file.path(qc_dir, "flagged_cells.png"), 
    width=10, height=8, res=350, units = "in", type = "cairo")
  upset(
  fromList(filter_list),
  nintersects = 10,
  order.by = "freq",     
  nsets = length(filter_list), 
  text.scale = 1.5)
dev.off()
```

Figure 3.11: Combinations of quality filters flagged in this study. Only the 10 most frequent sets are shown for clarity.

3.5
 Filtering

Now that we have flagged the cells, this section does the actual filtering and saves data to disk so that we can use it in the pre-processing step.

In regular analyses, I simply filter the cells based on the chosen cutoffs and continue with the pre-processing step. In this case, I am interested in showing the downstream effects of leaving poor quality cells in versus filtering them. To that end, I’ll save two annData objects: unfiltered and filtered. In both datasets, I will add a qc flag column to keep track of what QC conditions were flagged in any given cell.

To be efficient I’ll make use of bitwise shifts to create the QC flag column.

R Code

```
qc_masks <- list(
  LOW_COUNTS = bitwShiftL(1, 0),  # 1
  HIGH_COUNTS = bitwShiftL(1, 1), # 2
  LOW_FEAT = bitwShiftL(1, 2),    # 4
  HIGH_FEAT = bitwShiftL(1, 3),   # 8
  LOW_SPLIT = bitwShiftL(1, 4),   # 16
  FOV_QC = bitwShiftL(1, 5),      # 32
  LOW_SBR = bitwShiftL(1, 6),     # 64 
  BLANK7 = bitwShiftL(1, 7)       # 128 (not used)
)

meta <- meta %>%
  mutate(
    qc_flag = (
      # Condition 1
      (nCount_RNA < results_list[['counts_min_threshold']]) * qc_masks$LOW_COUNTS +
      
      # Condition 2
      (nCount_RNA > results_list[['counts_max_threshold']]) * qc_masks$HIGH_COUNTS +
      
      # Condition 3
      (nFeature_RNA < results_list[['features_min_threshold']]) * qc_masks$LOW_FEAT +
      
      # Condition 4
      (nFeature_RNA > results_list[['features_max_threshold']]) * qc_masks$HIGH_FEAT +
      
      # Condition 5
      (SplitRatioToLocal > 0 & SplitRatioToLocal < results_list[['SplitRatioToLocalThreshold']]) * qc_masks$LOW_SPLIT + 
      
      # Condition 6
      (fovqcflag == 1) * qc_masks$FOV_QC +
      
      # Condition 7
      (log2(SBR) < 0) * qc_masks$LOW_SBR
      
    )
  )

py$adata$obs$qcflag <- meta$qc_flag
results_list['n_cells_before_qc'] = py$adata$n_obs
```

Remove some of the intermediate matrices and save the annData to disk.

Python Code

```
adata.obs['qcflag'] = adata.obs['qcflag'].astype('uint8')
del adata.obsp['liana_connectivities']
del adata.obsm['counts_neg_spatially_smooth']
del adata.obsm['counts_spatially_smooth']

filename = os.path.join(r.analysis_dir, "anndata-1-qc-flagged.h5ad")

adata.write_h5ad(
  filename,
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

In addition to saving a copy of flagged data, let’s filter out any cells with a QC flag that is not “32” and save that “filtered” dataset to disk.

Python Code

```
adata.obs['qcflag'] = adata.obs['qcflag'].astype('uint8')

adata = adata[adata.obs['qcflag'].isin([0, 32]), :].copy()

filename = os.path.join(r.analysis_dir, "anndata-1-qc-filtered.h5ad")
adata.write_h5ad(
  filename,
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

Save project-level results.

R Code

```
results_list['n_cells_after_qc'] = py$adata$n_obs
saveRDS(results_list, results_list_file)
```

After filtering, we have 466820 (94.5 %) that are ready to analyze. Note that we did not do any gene-level filtering. My primary reason for leaving all genes in the data at this point is primarily because – while we do not expect every gene to be highly expressed in every cell – there are rare cells that may express genes that would considered “below background” in the rest of the data. My general approach is to keep all targets in the data and identify which of these are highly variable and use those genes when appropriate (
e.g.
, PCA, UMAP, Leiden).


====================
START OF FILE: references.html
====================

1. 
Dimitrov, D. 
et al.

LIANA+
 provides an all-in-one framework for cell-cell
communication inference. 
Nat. Cell Biol.
 
26
,
1613–1622 (2024).

2. 
Dimitrov, D. 
et al.
 Comparison of
methods and resources for cell-cell communication inference from
single-cell 
RNA-Seq
 data. 
Nat. Commun.

13
, 3224 (2022).

3. 
Guinney, J. 
et al.
 The consensus
molecular subtypes of colorectal cancer. 
Nat. Med.

21
, 1350–1356 (2015).

4. 
Calon, A. 
et al.
 Stromal gene
expression defines poor-prognosis subtypes in colorectal cancer.

Nat. Genet.
 
47
, 320–329 (2015).

5. 
Sasaki, T., Hiroki, K. & Yamashita, Y. The
role of epidermal growth factor receptor in cancer metastasis and
microenvironment. 
Biomed Res. Int.
 
2013
,
546318 (2013).

6. 
Ma,
M. 
et al.
 
Prognostic
implications and therapeutic opportunities related to CAF subtypes in
CMS4 colorectal cancer: Insights from single-cell and bulk
transcriptomics
. 
Apoptosis
 
30
, 826–841
(2025).

7. 
Hafemeister, C. & Satija, R. Normalization
and variance stabilization of single-cell 
RNA-seq
 data using regularized negative binomial
regression. 
Genome Biol.
 
20
, 296 (2019).

8. 
Blampey, Q., Benkirane, H., Bercovici, N.,
Andre, F. & Cournede, P.-H. Novae: A graph-based foundation model
for spatial transcriptomics data. 2024.09.09.612009 (2024) doi:
10.1101/2024.09.09.612009
.

9. 
Duffy, A. M., Bouchier-Hayes, D. J. &
Harmey, J. H. Vascular endothelial growth factor (
VEGF
) and
its role in non-endothelial cells: Autocrine signalling by

VEGF
. in 
VEGF
 and cancer
 133–144
(Springer US, Boston, MA, 2004).

10. 
Marconato, L. 
et al.

SpatialData
: An open and universal data framework for
spatial omics. 
Nat. Methods
 
22
, 58–62
(2025).

11. 
Palla, G. 
et al.
 Squidpy: A scalable
framework for spatial omics analysis. 
Nat. Methods

19
, 171–178 (2022).

12. 
Hao, Y. 
et al.
 Dictionary learning for
integrative, multimodal and scalable single-cell analysis. 
Nat.
Biotechnol.
 
42
, 293–304 (2024).

13. 
Barrett, T. 
et al.
 
Data.table:
Extension of ‘Data.frame‘
. (2025).

14. 
Ushey, K. & Wickham, H. 
Renv: Project
Environments
. (2024). doi:
10.32614/CRAN.package.renv
.

15. 
Lander, E. S. 
et al.
 Initial
sequencing and analysis of the human genome. 
Nature

409
, 860–921 (2001).

16. 
Ushey, K., Allaire, J. & Tang, Y. 
Reticulate:
Interface to ’Python’
. (2025).

17. 
Virshup, I., Rybakov, S., Theis, F. J.,
Angerer, P. & Wolf, F. A. 
Anndata: Access and store
annotated data matrices
. 
Journal of Open Source Software

9
, 4371 (2024).

18. 
Wolf, F. A., Angerer, P. & Theis, F. J.

SCANPY
: Large-scale single-cell gene expression data
analysis. 
Genome Biol.
 
19
, (2018).

19. 
Wickham, H. 
et al.
 
Welcome to the 
tidyverse
. 
Journal of Open Source
Software
 
4
, 1686 (2019).

20. 
He,
S. 
et al.
 High-plex imaging of 
RNA
 and proteins at
subcellular resolution in fixed tissue by spatial molecular imaging.

Nat. Biotechnol.
 
40
, 1794–1806 (2022).

21. 
The
R-WASM Team. 
quarto-live: WebAssembly powered code blocks and
exercises for R and Python in Quarto
. (2024).

22. 
Schubert, M. 
et al.

Perturbation-response genes reveal signaling footprints in cancer gene
expression. 
Nature communications
 
9
,
(2018).

23. 
Badia-i-Mompel, P. 
et al.
 decoupleR:
Ensemble of computational methods to infer biological activities from
omics data. 
Bioinformatics Advances
 https://doi.org/
https://doi.org/10.1093/bioadv/vbac016

(2022) doi:
https://doi.org/10.1093/bioadv/vbac016
.


====================
START OF FILE: resources.html
====================

Information from Posit on how to use python within Rstudio: 
https://posit.co/blog/three-ways-to-program-in-python-with-rstudio/

To learn about using R and python in Quarto: 
https://www.r-bloggers.com/2023/01/combining-r-and-python-with-reticulate-and-quarto/

The specific version of python I used was 3.10.18 using 
pyenv
.


====================
START OF FILE: spatial-domains.html
====================

While cell typing is one of the most useful cell-level labels we can use to organize our data, it can be illuminating to identifying the function regions within the sample based on the local composition of cells. This chapter uses novae
1
 to identify function regions within the tissue. Note that this approach does not rely on pre-existing cell type labels.

R code

```
source("./preamble.R")
reticulate::source_python("./preamble.py")
analysis_dir <- file.path(getwd(), "analysis_results")
input_dir <- file.path(analysis_dir, "input_files")
output_dir <- file.path(analysis_dir, "output_files")
analysis_asset_dir <- "./assets/analysis_results"
qc_dir <- file.path(output_dir, "qc")
if(!dir.exists(qc_dir)){
  dir.create(qc_dir, recursive = TRUE)
}

dom_dir = file.path(output_dir, "domains")
if(!dir.exists(dom_dir)){
  dir.create(dom_dir, recursive = TRUE)
}

results_list_file = file.path(analysis_dir, "results_list.rds")
if(!file.exists(results_list_file)){
  results_list <- list()
  saveRDS(results_list, results_list_file)
} else {
  results_list <- readRDS(results_list_file)  
}

py$analysis_dir <- analysis_dir
py$dom_dir <- dom_dir

source("./helpers.R")
```

5.1
 Model tuning

In the code below, the anndata object is loaded and spatial coordinates are converted. Then a Delaunay graph is generated. Since the pre-trained model is from a composite of platforms, we’ll run the optional fine-tuning procedure. To make this computation more efficient, we’ll specify the 
fine_tune
 method to use GPU instead of CPU. After tuning, we’ll computing the representations on the data and assign spatial domains. Finally, we’ll save the results and the tuned model to disk for later.

Note

While most of this analysis uses Pearson Residuals-based normalization results, we do not have the normalization matrix and novae works best with total counts-based normalization. Thus, we’ll let novae run the preprocessing steps.

Python Code

```
import torch
import novae
import igraph
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

sc.settings.figdir = r.dom_dir
torch.set_float32_matmul_precision('high')
novae.settings.auto_preprocessing = True
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

if 'adata' not in dir():
  adata = ad.read_h5ad(os.path.join(analysis_dir, "anndata-2-leiden.h5ad"))

adata.X = adata.layers['counts'].copy()

# convert spatial from mm to microns
adata.obsm['spatial_mm'] = adata.obsm['spatial'].copy()
adata.obsm['spatial_um'] = adata.obsm['spatial_mm']*1000
adata.obsm['spatial'] = adata.obsm['spatial_um']

# Create a Delaunay graph of the data. 
novae.spatial_neighbors(adata, radius=100, coord_type='generic')

novae.plot.connectivities(adata)
plt.gca().invert_yaxis()
plt.savefig(os.path.join(dom_dir, "connectivity_plot.png"), dpi=300, bbox_inches='tight')
plt.close()

model1 = novae.Novae.from_pretrained("MICS-Lab/novae-human-0")
```

Figure 
5.1
 confirms that a radius of 100 µm produces relatively few isolated cells. If there were many isolated cells within regions, we might consider increasing the radius.

Figure 5.1: Cells with low connectivity (in red).

If you want to fine-tune the model based on your current data, you can run the 
fine_tune
 method like so.

Python Code

```
import time
start_time = time.time()  # Record the start time
model1.fine_tune(adata, max_epochs=50, logger=True, accelerator='cuda', num_workers=4)
end_time = time.time()    # Record the end time
elapsed_time = end_time - start_time
print(f"Execution time: {elapsed_time:.4f} seconds")

novae_cells = adata.shape[0]
novae_fine_tune_seconds = elapsed_time
```

From the data and the model, we can compute the representations and assign cells on of a varying number of domain levels. When saving domain levels, I like to increment from one or two to a relatively high number and visualize on the tissue where domains split. Let’s save the model in case we ever want to use it later and plot the domain hierarchy.

Python Code

```
start_time = time.time()
model1.compute_representations(adata, zero_shot=False, accelerator='cuda', num_workers=4)
end_time = time.time()
elapsed_time = end_time - start_time
print(f"Execution time: {elapsed_time:.4f} seconds")

novae_compute_representations_seconds = elapsed_time

for i in range(1, 12):
  model1.assign_domains(adata, i)

model1_dir = os.path.join(dom_dir, "novae_model_one")
model1.save_pretrained(save_directory=model1_dir)

dh = model1.plot_domains_hierarchy()
plt.savefig(os.path.join(dom_dir, "novae_model1_hierarchy.png"), dpi=300, bbox_inches='tight')
plt.close()

adata.write_h5ad(
  os.path.join(analysis_dir, "anndata-3-novae.h5ad"),
  compression=hdf5plugin.FILTERS["zstd"],
  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options
)
```

R Code

```
results_list[['novae_cells']] = py$novae_cells
results_list[['novae_fine_tune_seconds']] = py$novae_fine_tune_seconds
results_list[['novae_compute_representations_seconds']] = py$novae_compute_representations_seconds
saveRDS(results_list, results_list_file)
```

If you find that running the above code in CPU-only mode takes a long time and you have GPUs available with cuda configured, I recommend trying 
accelerator='cuda'
. For this dataset with 4.6682^{5} cells using a single L4 GPU, it took 16 minutes to run the fine tuning procedure and 4 minutes to compute representations.

5.2
 Model Visuals

We assigned 11 domain levels. 
Figure 
5.2
 shows the hierarchical relationship between them.

Figure 5.2: Hierarchical relationships among novae domains.

Plot these novae clusters in XY and UMAP space. As with 
?sec-processing
, we’ll make use of the 
plotDots
 function after defining colors.

R Code

```
df <- py$adata$obs %>% 
  select(starts_with("novae_domains_"))

domain_names <- c()
for(i in 1:ncol(df)){
  pick <- which(colnames(df)==paste0('novae_domains_', i))
  print(pick)
  domain_names <- c(domain_names, sort(unique(as.character(df[,pick]))))
}
domain_names <- unique(domain_names)

set.seed(98103)
domain_colors <- sample(pals::alphabet2(length(domain_names)))
names(domain_colors) <- domain_names
results_list[['novae_model_1_domain_names']] <- names(domain_colors)
results_list[['novae_model_1_domain_colors']] <- as.character(domain_colors)
saveRDS(results_list, results_list_file)
```

R Code

```
source("./helpers.R")
for(prefix in colnames(df)){
  plotDots(py$adata, color_by=prefix,
              plot_global = TRUE,
              facet_by_group = FALSE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = dom_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = domain_colors),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Spatial Domains",
                  override.aes = list(size = 3) ) )
              )
              )
}
```

Domains: 1
Domains: 2
Domains: 3
Domains: 4
Domains: 5
Domains: 6
Domains: 7
Domains: 8
Domains: 9
Domains: 10
Domains: 11

The choice of domain resolution depends on the types of biological questions that are used. For example, if you wanted finer resolution of the micro-niches within the epithelium (top part of the tissue, you may increase the number of domains). For the purpose of this chapter, let’s pick seven domains.

Focusing on six domain solution, plot individual XY plots to see the spatial layout of each domain.

R Code

```
prefix <- "novae_domains_6"
plotDots(py$adata, color_by=prefix,
              plot_global = FALSE,
              facet_by_group = TRUE,
              additional_plot_parameters = list(
                  geom_point_params = list(
                    size=0.001
                  ),
                  scale_bar_params = list(
                    location = c(5, 0),
                    width = 2,
                    n = 3,
                    height = 0.1,
                    scale_colors = c("black", "grey30"),
                    label_nudge_y = -0.3
                  ),
                  directory = dom_dir,
                  fileType = "png",
                  dpi = 200,
                  width = 8, 
                  height = 8,
                  prefix=prefix
                ),
              additional_ggplot_layers = list(
                theme_bw(),
                xlab("X (mm)"),
                ylab("Y (mm)"), 
                coord_fixed(),
                scale_color_manual(values = domain_colors),
                theme(legend.position = c(0.8, 0.4)),
                guides(color = guide_legend(
                  title="Spatial Domains",
                  override.aes = list(size = 3) ) )
              )
              )
```

Domain: D1000
Domain: D1003
Domain: D1011
Domain: D1015
Domain: D1016
Domain: D1017

5.3
 Conclusions

Now that we have the spatial domain assignments, the next step is to assign functional names to these assignments. To aid in this effort, we’ll first look at the composition of cell types within these domains which is the topic of the next chapter.

1. 
Blampey, Q., Benkirane, H., Bercovici, N., Andre, F. & Cournede, P.-H. Novae: A graph-based foundation model for spatial transcriptomics data. 2024.09.09.612009 (2024) doi:
10.1101/2024.09.09.612009
.